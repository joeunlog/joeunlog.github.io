{"0": {
    "doc": "Setting environment",
    "title": "Setting environment",
    "content": "Summary () {: .text-delta } 1. TOC {:toc} # Anaconda 설치 1. [https://www.anaconda.com/download/](https://www.anaconda.com/download/) 접속 2. Individual Edition 선택 3. 각자 OS에 맞는 Installer 다운로드 > ex. Anaconda3-2020.07-Windows-x86_64.exe 4. Installer 실행 > Install location(설치 경로)는 필요에 따라 변경 가능 ex. d:/영문이름/anaconda > **❗ PATH environment variable은 꼭 체크 상태로** # Jupyter notebook 실행 1. Anaconda Prompt 실행 2. 프롬프트에 아래 명령 입력 ``` jypyter notebook \"소스코드 디렉토리\" ``` ## Jupyter notebook 주요 단축키 * 셀 선택 모드 (Command Mode) | 기능 | 단축키 |:---------------------------------|:--------------------------| 위로 셀 추가 | [a] | 아래로 셀 추가 | [b] | 선택 셀 삭제 | [d][d] (d를 두번 누름) | 선택 셀 잘라내기 | [x] | 선택 셀 복사하기 | [c] | 선택 셀 아래에 붙여넣기 | [p] | 선택 셀과 아래 셀과 합치기 | [shift] + [m] | 실행결과 열기/닫기 | [o] | Markdown으로 변경 | [m] | Code로 변경 | [y] | 파일 저장 | [cmd] + [s] 또는 [s] | 선택 셀의 코드 입력 모드로 돌아가기 | [enter] | * 코드 입력 모드 (Edit Mode) | 기능 | 단축키 |:---------------------------------|:--------------------------| 선택 셀의 코드 전체 선택 | [ctrl] + [a] | 선택 셀 내 실행 취소 | [ctrl] + [z] | 선택 셀 내 다시 실행 | [ctrl] + [y] | 커서 위치 라인 주석처리 | [ctrl] + [/] | 선택 셀 코드 실행 | [ctrl] + [enter] | 선택 셀 코드 실행 후 다음 Cell로 이동 (없으면 새로 추가) | [shift] + [enter] | 커서 위치에서 셀 둘로 나누기 | [shift] + [ctrl] + [-] | 셀 선택 모드로 돌아가기 | [esc] 또는 [ctrl] + [m] | # Python 설치 1. [www.python.org/downloads](www.python.org/downloads) 접속 2. 원하는 버전의 Python installer 다운로드 3. Installer 실행 > Add Python 3.x to PATH 설정을 선택 : 파이썬이 어느 곳에서든지 실행될 수 있도록 ",
    "url": "/docs/python-study/01-set-environment.html",
    "relUrl": "/docs/python-study/01-set-environment.html"
  },"1": {
    "doc": "Data type",
    "title": "Data type",
    "content": "Summary () {: .text-delta } 1. TOC {:toc} 코드 예시는 script와 run 결과물 형식 # 숫자형 1. 정수형 (Integer) 2. 실수형 (Floating-point) 3. 8진수 (Octal) 4. 16진수 (Hexadecimal) * 숫자형 연산 1. \\+ : 더하기 2. \\- : 빼기 3. \\* : 곱하기 4. ** : 제곱 5. / : 나누기(실수반환) 6. // : 몫 (정수반환) 7. % : 나머지 # 문자열 자료형 1. 문자 2. 단어 3. 문장 ## 문자열 활용 1. \" \" : 큰따옴표 2. ' ' : 작은따옴표 3. \"\"\" \"\"\" : 큰따옴표 3개 4. ''' ''' : 작은따옴표 3개 * 문자열 특별한 활용 1. 큰따옴표나 작은따옴표를 문자열에 넣고 싶은 경우 ```py astr = \"Python's favorite food is perl\" bstr = '\"Python is very easy.\" he says.' cstr = 'Python\\'s favorite food is perl' dstr = \"\\\"Python is very easy.\\\" he says.\" ``` 2. 여러 줄 ```py astr = \"Life is too short\\nYou need python\" bstr = '''Life is too short You need python''' cstr = \"\"\"Life is too short You need python\"\"\" ``` ## 문자열 연산 1. \\+ : 문자열 더하기 (연결하기) ```py astr = \"Python\" bstr = \" is fun!\" print(astr + bstr) >>\"Python is fun!\" ``` 2. \\* : 문자열 곱하기 ```py astr = \"Python\" print(astr * 2) >>\"PythonPython\" ``` 3. len() : 문자열 길이 구하기 ```py astr = \"Life is too short\" print(len(astr)) >>17 ``` * 문자열 인덱싱 특징 1. 문자열[인덱스] 방식으로 사용 * 첫번째 인덱스는 0 2. 인덱스에 마이너스(-)를 사용하면 뒤에서부터의 인덱싱을 나타냄 * 뒤에서부터 첫번째 인덱스는 -1 ```py astr = \"abcde\" print(a[0]) >>'a' print(a[3]) >>'d' print(a[-1]) >>'e' ``` * 문자열 슬라이싱 특징 1. 문자열[시작인덱스:끝인덱스] 방식으로 사용 2. 끝인덱스에 해당하는 것은 포함하지 않음 3. 인덱스를 생략하면 '맨앞'이나 '맨끝'까지를 의미 ```py astr = \"abcde\" print(a[1:3]) >>'bc' print(a[:3]) >>'abc' print(a[3:]) >>'de' ``` ## 문자열 포매팅 | 코드 | 설명 |:-----------|:---------------------------| %s | 문자열(String) | %c | 문자 1개(Character) | %d | 정수(Integer) | %f | 부동 소수(Floating-point) | %o | 8진수 | %x | 16진수 | %% | 문자 '%' 자체 | * 문자열 포매팅 특징 1. \"포매팅문자열\" % 방식으로 대입 2. 여러 개의 경우에는 \"포매팅문자열\" % (값1,값2,···) 3. %숫자s를 이용하여 정렬, 공백 표현 (오른쪽 정렬은 숫자 앞에 마이너스[-]) ```py print(\"%10shello\" % \"hi\") >>'hi hello' #공백 8개 print(\"%-10shello\" % \"hi\") >>' hihello' #공백 8개 ``` 4. %숫자.숫자f를 이용하여 정렬, 소수점 표현 ```py print(\"%10.4f\" % 3.12345678) >>' 3.1234' #공백 4개 ``` 5. f 문자열 포매팅 기능 ```py name = 'jack' age = 30 print( f'name={name}, age={age}, age+1={age+1}') >>'name=jack, age=30, age+1=31' ``` ## 문자열 관련 함수 1. count() : 문자열 안에 해당 문자의 개수 반환 ```py astr = 'hobby' print( astr.count('b') ) >>2 ``` 2. find() : 찾는 문자열이 처음 나온 위치 반환, 없으면 -1 반환 ```py astr = 'ho bby' print( astr.find('b') ) >>3 ``` 3. index() : 찾는 문자열이 처음 나온 위치 반환, 없으면 에러 ```py astr = 'ho bby' print( astr.index('b') ) >>3 ``` 4. join() : 문자열 삽입 ```py print(\",\".join('abcd')) >>'a,b,c,d' ``` 5. upper() : 소문자를 대문자로 변환 ```py astr = 'hi' print( astr.upper() ) >>'HI' ``` 6. lower() : 대문자를 소문자로 변환 ```py astr = 'HI' print( astr.lower() ) >>'hi' ``` 7. lstrip() : 가장 왼쪽에 있는 연속된 공백 삭제 ```py astr = ' hi ' print( astr.lstrip() ) >>'hi ' ``` 8. rstrip() : 가장 오른쪽에 있는 연속된 공백 삭제 ```py astr = ' hi ' print( astr.rstrip() ) >>' hi' ``` 9. strip() : 양쪽에 있는 연속된 공백 삭제 ```py astr = ' hi ' print( astr.strip() ) >>'hi' ``` 10. replace() : 문자열 치환 ; 기존문자열, 바꿀문자열 순으로 함수에 전달 ```py astr = 'Life is too short' print( astr.replace(\"Life\",\"Your leg\")) >>'Your leg is too short' ``` 11. split() : 특정 문자열을 구분자로 해서 문자열 분리 ; 문자열 지정 안할 시 공백을 기준으로 문자열 분리 ```py astr = \"Life is too short\" print( astr.split() ) >>['Life', 'is', 'too', 'short'] bstr = \"a:b:c:d\" print( bstr.split(':') ) >>['a','b','c','d'] ``` # 리스트 자료형 ",
    "url": "/docs/python-study/02-data-type.html",
    "relUrl": "/docs/python-study/02-data-type.html"
  },"2": {
    "doc": "2021-01-27",
    "title": "2021-01-27",
    "content": "1교시 - AWS_RDS - OLTP(online transaction processing)성 DB와 DW (Dataware house) - Amazon Redshift는 DW - DW는 대량 Read가 많이 일어남, 수정이 자주 일어나지 않음, 실시간 작업이 아님 - OLTP는 소량 Read로 많이 일어남 - DW랑 OLTP랑 너무 달라서 따로 씀 : 오라클을 쓴다고 해도 각 DB를 구성해놓고 씀 2교시 - 네트워크 계층 : VPC를 만들어 볼 예정 - VPN : 가상의 사설 네트워크 : 네트워크 용어임 - VPC : 가상의 사설 클라우드 - VPC 안에 서브넷 두 개를 만들어 볼 예정 - 서브넷 관련 : 255는 이진수로 11111111이다. 이진수로 1인 부분이 주소로 쓰는 부분이라는 뜻 : ex. 255.255.255.128 = 11111111.11111111.11111111.10000000 - 일반적으로 외부에서 RDS로 직접 연결은 불가능 : 실습시간에 강사님 서버에 들어간 것은 모든 것을 다 열어놨기 때문 : 주로 인스턴스에 DB를 관리하는 프로그램을 넣어놓고 이 인스턴스에 DB관련 요청을 통해 뭔가 작업이 이루어지는 것 3교시 - 4교시 - 서브넷 권장 사항 5교시 - DBMS마다 사용하는 포트가 다름 - 개인 실습 시작 (VPC) 6교시 - 개인 실습 계속 ",
    "url": "/docs/daily-learning-log/20210127.html",
    "relUrl": "/docs/daily-learning-log/20210127.html"
  },"3": {
    "doc": "2021-01-28",
    "title": "2021-01-28",
    "content": "1교시 - 아키텍처에서 NAT게이트웨이, EC2인스턴스 그 쪽 관련 - 다이어그램에서 자물쇠 표시는 private network를 의미 - 외부 네트워크는 일부 url만 열어줌 - EC2에서 외부 네트워크에 뭔가를 요청하는거고 NAT 게이트웨이를 통해 외부 네트워크로 나가게 된다 - 서브넷마다 라우팅테이블이 있는데, NAT로 나가게 되는 주소를 제한하는것임 - 클라우드에서 라우터가 따로 존재하지 않고, 라우팅 테이블은 서브넷마다 존재 - 결과적으로, 인터넷 게이트웨이와 연결돼야 외부 네트워크와 통신 가능 - VPC는 어떤 리전 안에 만드는 것으로 여러 개의 리전에 걸쳐서 만들 수 없음 - 단일 VPC 패턴 , 다중 VPC 패턴, 복수 계정 패턴은 규모 차이 (첨부된 문서 참고) - 계정당 VPC 5개 - AWS에는 Hard limit, Soft limit 서비스가 있는데 이거는 Soft limit으로, 요청하면 제한조건 바꿔줌 (늘릴 수 있다는 얘기) - IP 한 칸당 8bit로, CIDR/16인 VPC는 앞의 2칸이 네트워크 주소 - 즉 CIDR /숫자 는 네트워크 주소가 어디까지인지를 알려줌 : 호스트 주소로 어디까지 쓸 수 있는지를 나타냄 : CIDR /32면 4칸 모두 네트워크 주소이므로 호스트 주소는 1개인 것 - 이 숫자를 8의배수가 아닌 숫자로 쓸 수도 있음 : bit단위로 생각하면 됨 : 즉, 10진수로 생각하면 IP주소는 총 4칸이지만, 2진수로 하면 8개씩 4세트의 숫자임 : 앞에서부터 해당 숫자의 비트 수 만큼이 네트워크 주소 - 퍼블릭 서브넷, 프라이빗 서브넷을 각각 만들 때 CIDR를 지정해서 네트워크 주소와 호스트 주소를 나눔 - CIDR랑 서브넷마스크는 다른 점이 존재 : 용도 - 서브넷 마스크는 호스트 주소를 갈라서 쓰고 싶어서 쓰는 것, 서브넷 마스크로 원래 호스트주소 영역도 네트워크 주소로 지정해서 네트워크 영역을 갈라서 쓰는 거 - 즉 서브넷 마스크를 하나 쓰면 네트워크가 둘로 갈라짐 - CIDR은 내 네트워크 주소가 어디까지인지를 알려주는 용도 2교시 - VPC 계속 - 어제 실습한 내용 복습 3교시 - 어제 실습한 내용 복습 계속 - Windows server EC2 생성 - 원격연결 - anaconda 설치 4교시 - Django 설치 - 윈도우 방화벽 해제 5교시 - Django - 아키텍처 : 시스템 전체 기본 설계, 규칙 : 시스템 아키텍처 : hw아키텍처 + sw아키텍처 - 아키텍처 패턴/스타일 : 설계노하우 : 문제영역, 이름 : (시스템전체-비기능품질) : ex. sw 아키텍처 패턴 2가지 : MVC, Layer - 디자인 패턴 : 설계노하우 : 문제영역, 이름 : (시스템전체-비기능품질) : ex. singleton, proxy - Django에서는 MVC(Model, View, Controller)가 아니라 MVT(Model, View, Template)로 씀 6교시 - MVC에서 View는 화면 : HTML문서 - model은 C.R.U.D : DB연결 - Controller는 모든 제어 : 고객 요청 받고 model에 DB 조회 요청하고 답 받은거를 View에 화면출력하라고 명령 - 개발 프레임워크 : sw 개발의 뼈대를 구현해 놓은 것 : python에서는 Django, Flask 등이 있음 : 주로 범용적인 것을 구성해놓음 : 코드를 구현해놓으면 프레임워크가 그 코드를 가져다가 씀 - 라이브러리나 패키지는 미리 개발해놓은 코드들의 묶음으로, 사용자가 패키지에 있는 것들을 호출해서 씀 : 라이브러리나 패키지가 사용자의 코드를 가져다가 쓰지는 않는다는 것이 프레임워크와의 차이점 - Django의 MTV는 화면에 표시된 버튼을 누르는게 사용자 요청같은거니까, 사용자 요청을 받는 부분을 View로 표기 - Template은 MVC의 View와 같음 - 개인 컴퓨터에 Django 설치 - 파이참에서 터미널을 작동시키는 이유 : 프로젝트를 새로 만들면 가상 실행환경이 생김(venv) : Django를 이 실행환경에 설치하기 위함 - Base 실행환경은 Django 설치 안된 상태가 됨 : 이런 식으로 여러 버전의 python을 쓸 수도 있음(참고) - Django를 설치하면 SQLite3이라는 DB도 같이 설치됨 + DBMS, WebServer, WAS, PythonMVC Framework 7교시 - 프로젝트 회의 ",
    "url": "/docs/daily-learning-log/20210128.html",
    "relUrl": "/docs/daily-learning-log/20210128.html"
  },"4": {
    "doc": "2021-01-29",
    "title": "2021-01-29",
    "content": "1교시 . - 어제 복습 . 2교시 . - 프로젝트는 2월 9일 발표 예정 . - 2월 2, 3, 4, 8일은 온전히 프로젝트하고 5일에는 수업 (고가연성 아키텍처) . - 2월 1일에는 게시판 만들기 실습 예정 . - Django 웹 어플리케이션 개발 실습 시작 . - Python Class로 SQL의 테이블이 자동 생성하기 . : models.py 파일에 클래스 정의, models.Model을 상속하는 클래스를 작성 . : ex. from django.db import models class Quetion(models.Model): . - Class와 테이블이 맵핑이 되고, class로 생성한 객체가 테이블의 ............ ORM(Object Relational Mapping 객체관계맵핑) . 3교시 - myDjangoSite 실습 : Question class 생성, admin 설정 . : admin.py 파일에 에러가 3개 뜨는데, 이건 로컬상태에서 해당 코드가 내용을 못찾아서 그러는거고 실행 잘 됐으면 문제 없음 . - 교재에서의 View(Django MVT)는 MVC에서는 Controller를 의미 . 4교시 . - View, Template 개발 . 5교시 . - 127.0.0.1 : 현재 컴퓨터 라는 의미 . - 그 뒤의 8000은 현재 Django가 쓰는 서버의 포트넘버 . 6교시 . - choice 데이터 추가하기 . 7교시 . - 자습 . ",
    "url": "/docs/daily-learning-log/20210129.html",
    "relUrl": "/docs/daily-learning-log/20210129.html"
  },"5": {
    "doc": "2021-02-01",
    "title": "2021-02-01",
    "content": "1교시 - 복습 - SW 개발 프레임워크(MVC) : 장고, 스프링 등등 : 스프링은 ORM 포함하지 않아서 따로 MyDa뭐시기를 씀 2교시 - 파이썬 쉘로 데이터 조작 실습 - Question.objects.filter : 모델명(테이블에 매핑), 객체들(데이터들), filter(WHERE와같음) - 컬럼명__조건 : 해당 컬럼에서 조건에 해당하는 것들 찾음 : ex. question_text__startswith='What' , pub_date__year=2005 - 객체.delete() : 레코드 삭제 함수 - 객체.save() : 새로운 데이터 생성 혹은 데이터 수정 함수 - 새로운 프로젝트 생성 : MyDjangoSite2 : 게시판 만들기 - 클래스 선언(테이블 생성)에서 : null = False : NOYNULL : primary_key = True : 기본키로 설정 : on_delete = CASCADE : 부모데이터가 삭제되면 포린키의 자식데이터도 삭제 : on_delete = SET_DEFAULT, default=\"\" : 부모데이터 삭제시 자식데이터 default값으로 바뀜 : on_delete = SET_NULL : 부모데이터 삭제시 자식데이터 NULL 3교시 - 게시판 만들기 계속 4교시 - 폼 클래스 활용 장점 - 폼 클래스를 form.py에 생성 - templates/login.html을 생성하여 form이 들어가는 로그인화면 생성 : {{form}}으로 쓰면 클래스로 선언했던 것에 맞게 html태그가 생성됨 : ex. 변수명 => name, 라벨 => 라벨 - view.py에서 login 함수 수정 : form = LoginForm(), return에 {'form':form} - session : 논리적 연결 : 카톡 서버가 있고, 내 컴퓨터에 카톡채팅 2개 띄워놨을 때, 물리적 연결은 1개, 논리적 연결은 2개 5교시 - 세션을 이어갈 때, 일종의 토큰을 발급받아서 토큰 아이디를 기준으로 내용을 저장, 통신을 이어갈 때 토큰 아이디를 전달하여 세션 진행되도록 - summit을 눌렀을 때 어디로 가야할 지 알려주는게 action : templates/login.html에서 아래의 input type summit을 클릭하면 form이 위의 url따라서 가는것임 - redirect : 요청 받은 주소 말고 다른 주소로 바뀌는 것 6교시 - 게시판 만들기 실습 계속 - 최종프로젝트 팀 선정 관련 : 최종 프로젝트는 현업분들이 멘토링해줌 : 멘토링은 기획 같은 부분 위주 - 개인적으로 주제에 대해 좀 생각해보고 - 2월 8~9일 쯤에 주제 관련, 예상 주제에 대해 알려줄 것(멘토 의견) - 그 후에 주제 좀 더 생각해보면서 팀 구성 시작해보기 - 2/16까지 팀 확정 : 총 5팀 - 2월 20일 이후에 멘토와 얘기해볼 수 있을 듯 - 3월 초부터 프로젝트 기획부터 시작할 듯 - 멘토링은 수업시간 이외의 시간으로 과정 끝날 때까지 : 총 40시간 - 6월 21일에 과정 종료인데, 이 날은 발표날이고 6월 18일까지 프로젝트 진행한다고 생각하면 됨 ",
    "url": "/docs/daily-learning-log/20210201.html",
    "relUrl": "/docs/daily-learning-log/20210201.html"
  },"6": {
    "doc": "2021-02-05",
    "title": "2021-02-05",
    "content": "1교시 - AWS 고가용성 아키텍처 - RDB는 완전 관리형 : 알아서 2중화 되어있는 서비스 - 고가용성 아키텍처는 중복이 기본, 가용영역은 두 개 써야함(같은 리전에서 다른 가용 영역) - 가용영역별로 서브넷을 구축, 서버 배치, DB 등을 중복시킨다 - 사실은 한 쪽의 시스템만 사용하고 있음 - load balancer가 중간에서 부하를 조정 (ALB) - 평상시에는 부하를 조정하다가 장애가 발생되면 헬스 체크로 인해 정상적인 쪽만 구동 됨 - 로드밸런스는 온프레미스에도 있는 기능 - 오토스케일링은 온프레미스에는 없음 - 24시간 돌리는 프로그램, 서버는 3~4개를 중복해서 씀 - 고가용성 아키텍처 사례2의 경우에는 아마존라우트S3가 리전 밖에 있음. - 따라서 부하에 따른 로드밸런스를 다른 리전에 보내줄 수도 있음 - 이번 프로젝트에서 오토스케일링은 안쓰는걸로 2교시 - 네트워크 구성 실습 - VPC 마법사로 만들면 라우팅 테이블도 자동으로 만들어짐 : 새로 만든 서브넷들에 연결 필요 - 라우팅 테이블에 가서 새로 생긴 vpc와 연결된 것이 2개 생성된 것 확인 - 상세를 봤을 때 , 라우팅에 NAT가 있는 것이 Private : private과 public 잘 구분해서 이름 써주기 3교시 - 네트워크 구성 실습 계속 4교시 - 네트워크 구성 간략 설명 - EC2는 원래 private subnet 안에 만드는게 일반적인데, 그렇게 하면 파일 올리는게 힘들어서 우리는 public에 생성할 것 5교시 - 6교시 - NAT랑 EIP는 만들어놓고 사용하지 않으면 요금이 나감? 7교시 - NAT(시간당 0.059USD, 처리 데이터비용별도), 탄력적IP는 비용이 나오므로 사용하지 않으면 바로 삭제하는 것이 좋다. ",
    "url": "/docs/daily-learning-log/20210205.html",
    "relUrl": "/docs/daily-learning-log/20210205.html"
  },"7": {
    "doc": "2021-03-29",
    "title": "2021-03-29",
    "content": "쉘 스크립트 . - 쉘 스크립트 : 쉘 프로그래밍을 할 때, 원하는 명령어를 sh파일에 작성하여 저장 - 실행방법 //반드시 파일의 실행권한 필요 절대경로를 명령어로 써서 실행 (ex. /home/user/hello.sh) 다만, /usr/bin 폴더에 넣어놓는 경우에는 파일명만 써서 실행 가능 (ex. Hello.sh) - 실행 프로그램 지정해서 실행하는 방법 두 가지 : shebang, 프로그램에서 스크립트파일이름 - shebang(셔뱅) : 쉘 스크립트 가장 윗 줄에 '#!' 기호로 표기, 이 스크립트를 실행할 프로그램 지정 (ex. #! /bin/python, #! /bin/perl, #! /bin/bash) : #! 뒤는 띄어도 되고 안띄어도 됨 특정 실행 프로그램을 사용하여 실행하는 경우에는 무시됨 - shebang이 없는 경우, 현재 쉘을 사용하여 실행하게 됨 - 스크립트파일이름 : 실행권한이 없는 스크립트도 실행 가능 - # : 주석, 실행 시 무시 . - 공백 자유롭게 사용 가능 - 디버그 옵션 사용 : 프로그램에서 -옵션 스크립트파일이름 -x : 실행할 코드가 아닌 실행할 내용을 출력 -v : 디버그 상태에서 스크립트 내 실행할 코드를 그대로 표시 -f : 스크립트 내 메타문자의 효력을 정지 - 스크립트 내 디버그 옵션 set -[옵션] : 해당 디버그 옵션 활성화 set +[옵션] : 해당 디버그 옵션 비활성화 Exit Status . - 종료 상태를 의미 - 명령어 실행 결과를 숫자로 표기 - 일반적으로 0이 정상 종료를 의미하지만 예외도 있음 - $? : 명렁어 실행시 종료 상태를 저장, 새로운 명령어 실행시 새로운 값으로 덮어 씀 변수 - Variable, 변경 가능한 데이터가 저장되는 공간 - 쉘 프로그래밍에서의 변수는 특정 유형이 없음 - 쉘 내에서 자유롭게 선언 및 사용이 가능 (ex. 변수이름=변수값. 변수이름=$변수이름) - 모든 입력값을 문자열로 인식 - 특별한 용도의 변수 $$ : 현재 실행중인 쉘의 PID $? : 이전 작업의 Exit Status $! : 백그라운드로 실행된 프로세스의 PID - 스크립트 내에서 선언된 변수는 스크립트 내에서만 유효 (지역변수) - 전역변수 : env로 조회되는 변수는 쉘 내에서 호출한 쉘에서도 접근 가능 - export : 해당 변수를 전역변수로 변경, env에 소속됨 - export = : 변수 생성과 전역변수로 변경을 동시에 산술연산 - expr : 산술연산 수식을 인자로 받아서 처리, 소수점 처리 불가능 ex. Expr 10+3 - bc : 산술연산 수식을 입력으로 받아서 처리(대화형), 소수점 처리 가능(scale 활용) ex. bc (대화형 시작) ex. echo 10/3 | bc ex. echo \"scale=3;10/3\" | bc - let 조건부실행 (Exit Status 관련) - 앞 명령의 실행 결과에 따라 뒤 명령의 실행 여부 결정 - && : 앞 명령이 정상적으로 실행될 경우에만 뒤 명령을 실행 - || : 앞 명령이 정상적으로 실행되지 않을 경우에만 뒤 명령을 실행 . 위치 매개변수(Positional Parameter) (c나 python에서 함수에 변수 넣는거랑 같은 의미) - 명령어 내에서의 위치 (인자, Argument) - $0 : 현재 실행중인 쉘 스크립트의 이름 - $1~ : 현재 스크립트 실행 시 사용된 인자(1번, 2번, 3번, … ) 10이 넘어가는 경우에는 ${10} 이런 식으로 사용해야함 - $# : 전체 위치매개변수의 개수 - $*, $@ : 위치매개변수 전체 - 예를 들어 cp 명령어의 경우, 맨 뒤 변수만 목적지고 앞에 몇 개의 변수가 들어가던 복사하려는 인자가 됨 - 가장 마지막 위치매개변수 접근 : eval echo \\$$# echo $$# : $$가 해석되어 사용 불가 echo \\$$# : \\에 의해 $는 일반 문자로 인식되고, $#값이 붙게 됨 eval echo \\$$# : eval에 의해 뒤쪽 $ 기호가 다시 인식되어 마지막 매개변수 값을 가져올 수 있게 됨 - set을 이용하여 현재 사용중인 쉘에서 사용할 위치매개변수를 지정할 수 있음 (ex. set a b c e d) grep (Globally Regular Expression Print) . - 파일 내에서 사용자가 지정한 내용을 검색 - 검색 내용 부분에는 정규화표현식(Regular Expression)을 사용 - 검색된 내용을 화면에 출력 - 일부 옵션의 경우 검색된 내용이 출력되지 않음 - 검색 실행시 검색 대상 파일에는 영향을 미치지 않음 - ASCII, 즉 텍스트 데이터를 대상으로만 사용 가능 - strings 명령어를 이용하여 문자열로 치환해서 사용 가능 - 옵션 -c : 패턴을 찾고, 찾은 패턴이 들어있는 '줄 수'를 출력 (패턴 개수 아님!!!) -I : 대소문자 구분하지 않음 -l : 패턴을 찾고, 출력은 하지 않으며, 패턴이 들어있는 파일의 목록만 출력 -n : 패턴을 찾은 후 출력되는 라인 앞에 줄 수를 표시 -v : 찾고자 하는 패턴이 들어있지 않은 줄만 표기 -w : 단어 단위로 찾기 (온전하게, 앞 뒤로 공백, 특수문자 등이 위치) 정규화표현식 - 검색에 사용되는 패턴 - vi, grep, sed, awk 등 텍스트를 다루는 다양한 도구에서 사용 - /RE/ : vi, sed, awk - 'RE' : grep 정규화표현식 주요 패턴 - ^[pattern] : 패턴의 모양으로 시작하는 라인만 검색 (ex. '^root') - [pattern]$ : 패턴의 모양으로 줄이 끝나는 라인만 검색 (ex. 'root$') - \\ : 단어 단위의 시작과 끝을 나타내는 패턴 (ex. '\\<hello') ",
    "url": "/docs/daily-learning-log/20210329.html",
    "relUrl": "/docs/daily-learning-log/20210329.html"
  },"8": {
    "doc": "2021-03-30",
    "title": "정규화표현식 주요 패턴",
    "content": "- . : 한 글자, 영문자(대/소), 숫자, 특수문자, 공백(스페이스, 탭) (ex. '…….' : 어떤 글자든지 총 7글자 - [pattern]* : 패턴이 0번 이상 반복 - a* : '', 'a', 'aa', 'aaa', 'aaaaaaaaa', … - .* : '', '.', '..', '…', …. : 아무거나, 모든 문자들 (ex. semanage fcontext -a -t [타입] '/wwwroot(/.*)?' ) - [문자들의 집합] : 집합에 포함된 글자들 중 한글자 - [abc] : a, b, c 중 한 글자 - [a-z] : 소문자 중 한 글자 - [0-9] : 숫자 중 한 글자 - [a-z0-9] : 소문자, 숫자 중 한 글자 - [Nn]ice : Nice 혹은 nice - [^문자들의 집합] : 집합에 포함되지 않은 글자들 중 한 글자 - [^abc] : a, b, c를 제외한 글자들 중 한 글자 - [^0-9] : 숫자가 아닌 한 글자 - \\ : Escape Sequence. 메타문자를 일반특수문자로 변환 ",
    "url": "/docs/daily-learning-log/20210330.html",
    "relUrl": "/docs/daily-learning-log/20210330.html"
  },"9": {
    "doc": "2021-03-30",
    "title": "grep 연습",
    "content": "- n 글자로 시작하는 라인을 찾기 - grep '^n' datafile - 4로 끝나는 라인을 찾기 - grep '4$' datafile - grep TB Savage datafile 해보기 - TB를 Savage 파일과 datafile 파일에서 검색한다는 의미 - grep 'TB Savage' datafile 해보기 - TB Savage를 datafile 파일에서 검색한다는 의미 - 숫자 5 뒤에 점(.)이 들어있는 라인을 찾기 - grep '5\\.' datafile - 점 뒤에 숫자 5가 들어있는 라인을 찾기 - grep '\\.5' datafile - w 또는 e로 시작하는 라인을 찾기 - grep '^[we]' datafile - M이 포함되어 있지 않은 라인을 찾기 - grep -v 'M' datafile - grep '^[^M]*$' dafafile - 참고로, grep '[^M]' datafile 은 M이 아닌 한 글자가 포함되어 있는 라인을 찾는다는 의미라서 부적합 - 대문자 두 글자 뒤 공백 한 글자. 다시 대문자 한 글자가 들어있는 라인을 찾기 - grep '[A-Z][A-Z] [A-Z]' datafile : 공백 한 글자를 스페이스로만 인식함 (탭은 해당되지 않음) - grep '[[:upper:]][[:upper:]][::space:]][[:upper:]]' datafile - [[::]]와 같은 특수 정규표현식은 아래 링크 참조 - https://support.google.com/a/answer/1371415?hl=ko - s가 한 글자 이상 반복되는 라인을 찾기 - grep 'ss*' datafile ",
    "url": "/docs/daily-learning-log/20210330.html",
    "relUrl": "/docs/daily-learning-log/20210330.html"
  },"10": {
    "doc": "2021-03-30",
    "title": "확장 정규화 표현식\t",
    "content": "- 확장 정규화 표현식은 grep에서는 사용불가하며, egrep에서 사용 가능!! - egrep : 확장 정규화 표현식 사용, grep -E와 동일 - fgrep : 정규화 표현식을 사용하지 않음 (fixed grep), 패턴을 일반 특수문자로 처리, grep -F와 동일 - ( ) : 패턴이 적용되는 부분을 묶어주기 - [pattern]+ : 패턴이 1번 이상 반복 (ex. ss* = s+ ) - [pattern]? : 패턴이 없거나, 1번 포함 - abc? : ab, abc (c에만 ?가 적용됨) - (abc)? : abc, 아무것도 없음 - ex. semanage fcontext -a -t [타입] '/wwwroot(/.*)?' - [pattern1]\\|[pattern2] : or, 즉, 패턴 1 또는 패턴 2 (ex. [Nn]ice = (N\\|n)ice ) - [pattern]{ } : 패턴의 반복 횟수 지정 - [pattern]{n} : 패턴 n번 반복 - [pattern]{n,m} : 패턴이 n번 이상 m번 이하 반복 - [pattern]{n,} : 패턴이 n번 이상 반복 - [pattern]{,m} : 패턴이 m번 이하 반복 ",
    "url": "/docs/daily-learning-log/20210330.html",
    "relUrl": "/docs/daily-learning-log/20210330.html"
  },"11": {
    "doc": "2021-03-30",
    "title": "egrep 연습\t",
    "content": "- NW 또는 EA 패턴을 검색 - egrep '(NW\\|EA)' datafile - 숫자 3이 1번 이상 반복 - egrep '3+' datafile - 2.x 또는 2x 패턴이 들어있는 라인 - egrep '2\\.?[0-9]' datafile - no 패턴이 1번 이상 반복되는 라인 - egrep '(no)+' datafile - Sh 또는 Su 라는 패턴이 들어있는 라인 - grep 'S[hu]' datafile - egrep 'S(h\\|u)' datafile - egrep '(Sh\\|Su)' datafile ",
    "url": "/docs/daily-learning-log/20210330.html",
    "relUrl": "/docs/daily-learning-log/20210330.html"
  },"12": {
    "doc": "2021-03-30",
    "title": "정규화표현식 개인실습\t",
    "content": "- San을 포함하고 있는 모든 줄을 출력하시오 - grep 'San' databook - 사람의 이름이 J로 시작하는 모든 줄을 출력하시오 - grep '^J' databook - 700으로 끝나는 모든 줄을 출력하시오 - grep '700$' databook - 834를 포함하지 않는 모든 줄을 출력하시오 - grep -v '834' databook - 생일이 12월인 모든 줄을 출력하시오 - grep ':12/' databook - 전화번호의 지역코드가 408인 모든 줄을 출력하시오 - grep ':408-' databook - 대문자 하나, 이어서 4개의 소문자, 콤마, 스페이스에 하나의 대문자를 초함하는 줄을 출력하시오 - grep '[A-Z][a-z]{4}, [A-Z]' databook - 성이 K나 k로 시작하는 모든 줄을 출력하시오 - grep ' [Kk][a-z]*:' databook - 급여가 6자리인 줄을 줄 번호와 함께 출력하시오 - grep ':[0-9]{6}$' databook - Lincoln이나 lincoln을 포함하고 있는 줄을 출력하시오 - grep '[Ll]incoln' databook - ID@도메인 형태로 이루어진 e-mail을 검색할 수 있는 정규식을 작성하시오 (corg) - egrep '[a-z][a-z0-9]*@[a-z][a-z0-9]*\\.(com\\|net\\|org)' test.txt - 핸드폰 번호를 검색할 수 있는 정규식을 작성하시오 - egrep '^01[016789]-[1-9][0-9]{2,3}-[0-9]{4}$' test.txt - IP주소를 검색할 수 있는 정규식을 작성하시오 - egrep '^[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}$' test.txt ",
    "url": "/docs/daily-learning-log/20210330.html",
    "relUrl": "/docs/daily-learning-log/20210330.html"
  },"13": {
    "doc": "2021-03-30",
    "title": "2021-03-30",
    "content": " ",
    "url": "/docs/daily-learning-log/20210330.html",
    "relUrl": "/docs/daily-learning-log/20210330.html"
  },"14": {
    "doc": "2021-03-31",
    "title": "sed (Stream Editor)\t\t",
    "content": "- vi, gedit, nano : file editor // sed는 stream editor로 file editor와는 다름 - interactive 기능이 없음 : 비대화형 에디터 - 파일을 수정해도 수정 내용이 반영되지 않음 : -I 옵션을 사용해야 파일에 저장 - 쉘 프로그래밍에서 많이 사용 - line 단위 처리 - vi 편집기와 유사 ",
    "url": "/docs/daily-learning-log/20210331.html",
    "relUrl": "/docs/daily-learning-log/20210331.html"
  },"15": {
    "doc": "2021-03-31",
    "title": "pattern space\t\t",
    "content": "- sed는 텍스트를 라인 단위로 처리 - 처리를 하기 위해 텍스트 데이터를 가져와서 가공하는 공간 - 처리가 끝난 텍스트 데이터는 화면으로 출력 - 처리가 완료된 텍스트 데이터를 패턴 스페이스에서 제거됨 ",
    "url": "/docs/daily-learning-log/20210331.html",
    "relUrl": "/docs/daily-learning-log/20210331.html"
  },"16": {
    "doc": "2021-03-31",
    "title": "sed 실행 형식\t\t",
    "content": "- sed [옵션] '명령어' 대상 : 특정 범위를 지정하지 않고 전체 라인에 적용 - sed [옵션] '패턴 명령어' 대상 : 패턴 명령어 = /패턴/ - ex. Sed -n '/1/p' number.txt : 1이 들어가는 곳을 출력 - sed [옵션] '범위 명령어' 대상 : 범위 명령어 = 라인(주소) : ~부터 ~까지 - 범위 예 : 라인 ; 라인, 라인 ; /패턴/,/패턴/ ; /패턴/,주소 ; 주소,/패턴/ - ex. sed '5q' number.txt : 5번째 줄까지 출력 - ex. sed -n '3,5p' number.txt : 3번째 줄부터 5번째 줄까지 출력 - ex. sed -n '/3/,/5/p' number.txt : 3이 나오는 곳부터 5가 나오는 곳까지 출력 - ex. sed -n '3,/5/p' number.txt : 3번째 줄부터 5가 나오는 곳까지 출력 - 참고 : $는 마지막 줄을 의미 (ex. Sed '6,$d' number.txt : 6번째줄부터 마지막 줄까지 삭제 ; 1~5출력) ",
    "url": "/docs/daily-learning-log/20210331.html",
    "relUrl": "/docs/daily-learning-log/20210331.html"
  },"17": {
    "doc": "2021-03-31",
    "title": "sed 명령어\t\t",
    "content": "- p : print 출력 - d : delete 삭제 - s : substitute 교체. 텍스트 데이터 바꾸기. Vi 편집기에서 사용하는 방식과 동일 - s/찾을패턴/바꿀내용/ : 라인에서 첫 번째 확인된 패턴만 교체 - s/찾을패턴/바꿀내용/g : 라인 내 패턴을 전체 교체 - append기능으로 쓰기 : 바꿀내용 맨 앞에 &를 추가 ; 현재 라인의 내용 뒤에 추가 - q : quit 종료 - a : 대상 아래줄에 라인 추가, 여러 줄 가능 - ex. sed '3 a\\\\(enter누르고)Hello World' number.txt : 3번째 줄 아래에 Hello World 추가 - ex. sed '3 aHello World' number.txt도 가능하지만 가독성이 떨어짐 - I : 대상 윗 줄에 라인 추가, 여러 줄 가능 - ex. sed '3,5 i\\\\(enter)Hello World' number.txt : 3번째부터 5번째줄 각각 위에 Hello World 추가 - c : change 지정된 라인을 변경 : 지정된 범위를 모두 삭제하고 새 내용으로 대체 됨 - ex. sed '3,5 c\\\\(enter)me' number.txt : 3번째부터 5번째줄 삭제되고 새로운 3번째 줄로 me가 들어감 ; me 다음 6이 나오게 됨 - ex. sed '3,5 c\\\\(enter)me\\\\(enter)me\\\\(enter)me' number.txt : 3번째부터 5번째 줄 삭제되고 me가 3줄 추가됨 - r : 파일에 있는 내용을 읽어와서 a 형태로 추가 - ex. sed '3r title.txt' number.txt : 3번째 줄 밑에 title.txt 내용 추가 - w : 파일에 기록 - ex. sed '3,5w text.txt' number.txt : 3번째줄부터 5번째 줄까지를 text.txt파일에 기록(파일 없을 시 생성됨) - ex. sed '1w number.txt' number.txt : number 파일에 첫 번째 줄만 남기라는 뜻 같지만, 동작 특성상 그냥 빈 파일이 됨 - w 동작 특성 상 기록되는 파일이 빈파일이 되는 듯 ",
    "url": "/docs/daily-learning-log/20210331.html",
    "relUrl": "/docs/daily-learning-log/20210331.html"
  },"18": {
    "doc": "2021-03-31",
    "title": "sed 옵션\t\t",
    "content": "- -n : 패턴스페이스에서 처리한 라인의 기본 출력 억제, 보통 p와 함께 사용 - /p만 쓰면 데이터 처리가 진행된 라인은 두 번, 처리 안 한 라인은 한 번 출력함 - -e : 다중 편집 실행 : ex. sed -e -e ... - 앞부터 순서대로 실행내용 하나를 전부 수행하고 다음 실행내용을 전부 수행하는 방식 - 따라서 앞 단계의 실행내용이 뒷 단계의 실행내용에 영향을 줄 수 있음 - -f : 스크립트 형태로 편집할 내용을 불러오기 - sed 명령어에서 ' ' 내부에 들어가는 내용을 스크립트에 작성 - 여러 명령을 한꺼번에 집어넣기 가능 - 스크립트 내부에 내용 작성시 ' ' 기호는 제외 - 스크립트 끝부분에 불필요한 공백이 있을 경우 에러가 날 수 있음 - 한 줄에 여러 명령어를 함께 사용할 수 있음 ( ; 기호 사용) - 주석 사용 가능 : # 기호가 맨 앞에 있을 경우 주석 처리 - -r : 확장 정규화 표현식 사용 ",
    "url": "/docs/daily-learning-log/20210331.html",
    "relUrl": "/docs/daily-learning-log/20210331.html"
  },"19": {
    "doc": "2021-03-31",
    "title": "sed 종합실습 (databook)\t\t",
    "content": "```js - Jon의 이름을 Jonathan으로 교체하시오 - sed -n 's/^Jon/Jonathan/p' databook - 처음 세 행을 삭제하시오 - sed '1,3d' databook - Lane이 포함된 행을 삭제하시오 - sed '/Lane/d' databook - 생일이 November나 December인 사람들의 행을 출력하시오 - sed -n '/:1[12]\\//p' databook - sed -n -e '/:11\\//p' -n -e '/:12\\//p' databook - Fred로 시작하는 행의 끝에 세 개의 별표(*)를 붙이시오 - sed -n '/Fred/s/.*$/&***/p' databook - sed -n '/Fred/p' databook \\| sed 's/.*$/&***/' - Popeye의 생일을 11/14/46으로 교체하시오 - sed -n '/Popeye/ s/:[0-9]*\\/[0-9]*\\/[0-9]*:/:11\\/14\\/46:/p' databook - sed -r -n ‘/Popeye/ s/:1?[0-9]\\/[123]?[0-9]\\/[0-9][0-9]:/:11\\/14\\/46:/p’ databook : 검색 쪽 월 표현에 0이 나올 수 있음 - 빈 행을 삭제하시오 - sed '/^$/d' databook - sed '/^[[:space:]]$/d' databook - 아래와 같은 sed 스크립트를 작성하시오 - 첫 줄에 Personal File 제목 삽입 - San Francisco에 거주하는 사람을 제거 - 마지막 줄에 THE END 추가 - sedscript 작성 # This is sed script 1i\\ Personal File /San Francisco/d $a\\ THE END - sed -f sedscript databook ``` ------------------------------------------------------- ",
    "url": "/docs/daily-learning-log/20210331.html",
    "relUrl": "/docs/daily-learning-log/20210331.html"
  },"20": {
    "doc": "2021-03-31",
    "title": "awk programing\t",
    "content": "구분자(Delimiter) : 텍스트 데이터에서 필드(Field)를 나누는 기호 ",
    "url": "/docs/daily-learning-log/20210331.html",
    "relUrl": "/docs/daily-learning-log/20210331.html"
  },"21": {
    "doc": "2021-03-31",
    "title": "awk\t",
    "content": "- 만든 사람들의 이름 첫 글자를 따서 awk - awk 도구는 유닉스 용으로 만들어진 도구 - awk는 이후 new awk로 발전 - gawk : GNU awk = nawk (GNU : GNU's Not Unix) - 데이터 조작, 리포트 생성 등을 지원하는 도구 - awk 명령어 내에서 프로그래밍 기능 지원 - 레코드 단위의 처리를 수행 ; 기본적으로 각 줄을 한 레코드로 처리 - 즉, 레코드를 구분하는 구분자가 개행문자라는 뜻 - 구분자 변경 가능 - 레코드 내의 데이터는 필드 단위로 처리 가능 - 정규화 표현식 등을 사용할 수 있음 - grep, sed 등과 사용법이 유사하며 비슷한 기능을 가지고 있음 ",
    "url": "/docs/daily-learning-log/20210331.html",
    "relUrl": "/docs/daily-learning-log/20210331.html"
  },"22": {
    "doc": "2021-03-31",
    "title": "용어\t",
    "content": "- 레코드 : 한 번에 처리되는 데이터의 단위. 기본적으로 한 줄 단위 - 필드 : 레코드 내의 데이터를 구분하는 단위 : 기본적으로 공백을 구분자로 사용 - 레코드 구분자 : RS(Record Separator), awk 내에서 RS 변수가 레코드 구분자를 저장 - 필드 구분자 : FS(Field Separator), awk 내에서 FS 변수가 필드 구분자를 저장 - ORS : Output RS ; 출력시 레코드 사이에 삽입되는 값 ; 기본으로 개행, 변수값을 변경하여 수정 - OFS : Output FS ; 출력 형식 지정시 ',' 기호를 통해 사용 가능 ; 기본으로 공백, 변수값을 변경하여 수정 - NF : Number of Field, 레코드를 읽어올 때 필드 구분자에 의해 분리된 필드의 개수 - NR : Number of Record, 현재 처리중인 레코드의 번호 - $0 : 전체 필드 데이터, 각 필드 사이에 OFS를 삽입하여 출력 - $1~ : 각 위치의 필드 ",
    "url": "/docs/daily-learning-log/20210331.html",
    "relUrl": "/docs/daily-learning-log/20210331.html"
  },"23": {
    "doc": "2021-03-31",
    "title": "실행 형식\t",
    "content": "- awk [옵션] '/패턴/' : grep과 동일한 동작 - awk [옵션] '{ 명령 }' : 대상 파일의 각 레코드 별로 명령 실행 - awk [옵션] '/패턴/ {명령}' : 패턴에 해당하는 레코드에 대해 명령 실행 ",
    "url": "/docs/daily-learning-log/20210331.html",
    "relUrl": "/docs/daily-learning-log/20210331.html"
  },"24": {
    "doc": "2021-03-31",
    "title": "명령\t",
    "content": "- print : 데이터를 사용자가 지정한 형식으로 출력 옵션 - -F : FS 지정 - ex. awk -F: '{print $1}' sample.txt ; -F 뒤에 공백 있어도 되고 없어도 됨 - awk -F : '/nologin/ {print $1}' sample.txt ",
    "url": "/docs/daily-learning-log/20210331.html",
    "relUrl": "/docs/daily-learning-log/20210331.html"
  },"25": {
    "doc": "2021-03-31",
    "title": "2021-03-31",
    "content": " ",
    "url": "/docs/daily-learning-log/20210331.html",
    "relUrl": "/docs/daily-learning-log/20210331.html"
  },"26": {
    "doc": "2021-04-01",
    "title": " awk 계속 ",
    "content": " ",
    "url": "/docs/daily-learning-log/20210401.html",
    "relUrl": "/docs/daily-learning-log/20210401.html"
  },"27": {
    "doc": "2021-04-01",
    "title": "옵션",
    "content": "- -F : FS 지정 - ex. awk -F: '{print $1}' sample.txt ; -F 뒤에 공백 있어도 되고 없어도 됨 - awk -F : '/nologin/ {print $1}' sample.txt - 구분자가 여러가지인 경우 : -F'[구분자기호들]' (ex. awk -F'[:,]' '{print $1,$2,$3}' test.txt) ",
    "url": "/docs/daily-learning-log/20210401.html",
    "relUrl": "/docs/daily-learning-log/20210401.html"
  },"28": {
    "doc": "2021-04-01",
    "title": "명령",
    "content": "- print : 데이터를 사용자가 지정한 형식으로 출력 - 사용자가 입력한 모양대로 출력 생성 - $1, $2 등 필드를 지정하여 출력 가능 - 문자열 삽입 : \" \" - 내부에서 ',' 기호 사용시 자동으로 OFS 삽입 - 일부 특수한 용도의 문자 사용 가능 - \\b : 백스페이스 ; 커서를 앞으로 한 칸 이동 - \\n : new line ; 개행 - \\r : Carriage Return ; 커서가 라인의 맨 앞으로 이동 - \\a : Beep ; 소리 발생 - \\t : Tab 삽입 - \\047 : ' 기호 ; 숫자 변경시 다른 특수문자(코드값기준) - printf : print + format(출력형식) ",
    "url": "/docs/daily-learning-log/20210401.html",
    "relUrl": "/docs/daily-learning-log/20210401.html"
  },"29": {
    "doc": "2021-04-01",
    "title": "패턴 활용",
    "content": "- Match 연산자 : ~ - ~ : 특정 필드가 정규화 표현식을 만족하는지 확인 - awk -F: '$1 ~ /root/' /etc/passwd - !~ : 특정 필드가 정규화 표현식을 만족하지 않을 경우 - 비교연산자 >, =, 80 {print $1}' test.txt - awk -F: '$1 == \"root\"' /etc/passwd : 1번 필드가 root인 경우 - awk -F: '$1 ~ /root/' /etc/passwd : 1번 필드에 root 패턴이 있는 경우 - awk -F: '$1 ~ /^root$/' /etc/passwd : 1번 필드가 ^root$를 만족하는 경우 (==와 같은 의미로 해석됨) - 논리연산자 : &&, || ",
    "url": "/docs/daily-learning-log/20210401.html",
    "relUrl": "/docs/daily-learning-log/20210401.html"
  },"30": {
    "doc": "2021-04-01",
    "title": "출력시 데이터 변경\t",
    "content": "- 사칙연산 : +, -, *, /, % - awk -F'[:,]' '$2>80 {print $1, $2+10}' test.txt - awk -F'[:,]' '$2>80 {print $1, $2-10}' test.txt - awk -F'[:,]' '$2>80 {print $1, $2*10}' test.txt - awk -F'[:,]' '$2>80 {print $1, $2/10}' test.txt - awk -F'[:,]' '$2>80 {print $1, $2%3}' test.txt - 가산, 감산 : +=, -= - awk -F'[:,]' '$2>80 {print $1, $2+=10}' test.txt - awk -F'[:,]' '$2>80 {print $1, $2-=10}' test.txt - awk -F'[:,]' '$2>80 {$2+=10; print $1, $2}' test.txt - 문자열 값 변경 : = - awk -F'[:,]' '$2>80 {print $1=\"me\", $2}' test.txt - 선택적 데이터 출력 : '{print ( A ? B : C )}' : A를 검사해서 참이면 B 거짓이면 C 출력 - awk -F'[:,]' '{ print $1, ( $2>80?\"Pass\":\"Not Pass\")}' test.txt ",
    "url": "/docs/daily-learning-log/20210401.html",
    "relUrl": "/docs/daily-learning-log/20210401.html"
  },"31": {
    "doc": "2021-04-01",
    "title": "실습 (donors 파일)\t",
    "content": "- 전화번호를 모두 출력하세요 - awk -F: '{ print $2}' donors - Dan의 전화번호를 출력하세요 - awk -F: '/Dan/ { print $2}' donors - awk -F: '$1 ~ /Dan/ { print $2}' donors - Susan의 성(family name)과 전화번호를 출력하세요 - awk -F'[: ]' '$1==\"Susan\" { print $2,$3,$4 }' donors - awk -F'[: ]' '$1 ~ /Susan/ { print $2,$3,$4}' donors - C나 E로 시작하는 이름을 출력하세요 - awk -F'[: ]' '$1 ~ /^[CE]/ { print $1}' donors - 지역번호가 916인 사람들의 이름을 출력하세요 - awk -F'[: ]' '$3 ~ /^\\(916\\)$/ { print $1}' donors - Mike의 기부금을 출력하세요. 액수는 달러 기호($)로 시작해야 합니다. (예: $250, $100) - awk -F: '$1 ~ /Mike/ { print \"$\"$3\", $\"$4\", $\"$5}' donors 변수의 초기화 : 변수를 선언할 때 기본값 입력 - awk에서는 변수를 사용하면 즉시 생성되고 초기화 ; 수치는 0 ; 문자는 \"\" ",
    "url": "/docs/daily-learning-log/20210401.html",
    "relUrl": "/docs/daily-learning-log/20210401.html"
  },"32": {
    "doc": "2021-04-01",
    "title": "BEGIN\t\t\t\t",
    "content": "- awk 명령어 시작 시 한 번만 수행되는 내용 - 블록 형태로 작성 - 변수의 선언 및 초기화 - 기본 내장 변수(FS, OFS, RS, ORS)값을 변경할 때 사용 - 헤더, 타이틀 등을 출력할 때 사용 ",
    "url": "/docs/daily-learning-log/20210401.html",
    "relUrl": "/docs/daily-learning-log/20210401.html"
  },"33": {
    "doc": "2021-04-01",
    "title": "END",
    "content": "- 모든 레코드에 대한 처리가 완료된 이후 1번만 실행 - 결과치를 출력하기 위한 용도로 사용 - 푸터(footer) 아래쪽에 들어갈 내용 출력 시 사용 ",
    "url": "/docs/daily-learning-log/20210401.html",
    "relUrl": "/docs/daily-learning-log/20210401.html"
  },"34": {
    "doc": "2021-04-01",
    "title": "BEGIN, END 사용 예시\t",
    "content": "- awk 'BEGIN{ FS=\"[:,]\"; OFS=\"\\t\"; KOR=100; print \"KOR Score\\n=========\"}{ KOR+=$2; print $1,$2 } END{print \"========\\nKOR total: \"KOR\"\\n=========\"}' test.txt ",
    "url": "/docs/daily-learning-log/20210401.html",
    "relUrl": "/docs/daily-learning-log/20210401.html"
  },"35": {
    "doc": "2021-04-01",
    "title": "awk script\t\t\t\t",
    "content": "- 실행할 내용 중 ' ' 안에 들어갈 내용을 스크립트로 작성 (sed와 동일) - BEGIN, ACTION, END를 각 줄로 구분하여 처리 - 세미콜론 부분은 줄 바꿈으로 치환 가능 - 예시 스크립트 ```js BEGIN{ FS=\"[:,]\"        OFS=\"\\t\"        KOR=100        print \"KOR Score\\n=========\"} { KOR+=$2; print NR, $1,$2 } END{ print \"========\\nKOR total: \"KOR\"\\n=========\"} ``` - 예시 스크립트 사용 : awk -f awkscript test.txt ",
    "url": "/docs/daily-learning-log/20210401.html",
    "relUrl": "/docs/daily-learning-log/20210401.html"
  },"36": {
    "doc": "2021-04-01",
    "title": "awk script 실습 예제\t\t",
    "content": "```js - 다음과 같은 형식으로 출력하시오 Donor List ------------------------------------------------------------------------- Name Phone Jan Feb Mar AVG ------------------------------------------------------------------------- Mike Harrington (510) 548-1278 250 100 175 175.00 Christian Dobbins (408) 538-2358 155 90 201 148.67 Susan Dalsass (206) 654-6279 250 60 50 120.00 .... ------------------------------------------------------------------------- Summary ------------------------------------------------------------------------- Total donate : $6137 Avg : $511 ------------------------------------------------------------------------- ``` - print만 사용 ( 이름이 긴 사람들 때문에 칸이 어긋남 ) ```js BEGIN{ FS=\":\" OFS=\"\\t\" TOTAL=0 PERTOTAL=0 print \" Donor List\" print \"-------------------------------------------------------------------------\" print \"Name Phone Jan Feb Mar\" print \"-------------------------------------------------------------------------\" } { PERTOTAL=$3+$4+$5 TOTAL+=PERTOTAL print $1\"\\t\"$2,$3,$4,$5,PERTOTAL/3 } END{ print \"-------------------------------------------------------------------------\" print \"Summary\" print \"-------------------------------------------------------------------------\" print \"Total donate : $\"TOTAL print \"Avg : $\"TOTAL/NR print \"-------------------------------------------------------------------------\" } ``` - printf 사용 ```js BEGIN{ FS=\":\" OFS=\"\\t\" TOTAL=0 PERTOTAL=0 print \" Donor List\" print \"-------------------------------------------------------------------------\" printf \"%-20sPhone Jan Feb Mar AVG\\n\",\"Name\" print \"-------------------------------------------------------------------------\" } { PERTOTAL=$3+$4+$5 TOTAL+=PERTOTAL printf \"%-20s%s\\t%3d\\t%3d\\t%3d\\t%.2f\\n\",$1,$2,$3,$4,$5,PERTOTAL/3 } END{ print \"-------------------------------------------------------------------------\" print \"Summary\" print \"-------------------------------------------------------------------------\" print \"Total donate : $\"TOTAL print \"Avg : $\"TOTAL/NR print \"-------------------------------------------------------------------------\" } ``` ",
    "url": "/docs/daily-learning-log/20210401.html",
    "relUrl": "/docs/daily-learning-log/20210401.html"
  },"37": {
    "doc": "2021-04-01",
    "title": "조건문과 반복문",
    "content": " ",
    "url": "/docs/daily-learning-log/20210401.html",
    "relUrl": "/docs/daily-learning-log/20210401.html"
  },"38": {
    "doc": "2021-04-01",
    "title": "조건문 개요\t\t\t",
    "content": "- 조건에 따라 수행할 동작을 지정 - if : 조건이 맞으면 실행, 아니면 패스 - if~else : 조건이 맞으면 if 아래를 실행, 조건이 틀리면 else 아래를 실행 - if~else if~else : 조건이 여러 개, if, else if, else임 ",
    "url": "/docs/daily-learning-log/20210401.html",
    "relUrl": "/docs/daily-learning-log/20210401.html"
  },"39": {
    "doc": "2021-04-01",
    "title": "조건문의 문법 : if, then, fi\t\t\t",
    "content": "- 유형 1 ```js if (조건) then (if 실행할 내용) fi ``` - 유형 2 ```js if (조건) then (if 실행할 내용) else (else 실행할 내용) fi ``` - 유형 3 ```js if (조건1) then (if 조건1에 따라 실행할 내용) elif (조건2) then (elif 조건2에 따라 실행할 내용) elif (조건3) then (elif 조건3에 따라 실행할 내용) … else (모든 조건을 만족하지 않을 경우 실행할 내용) fi ``` - case = if~elif~else와 유사한 동작 ```js case 변수명 in 값1) 실행내용1 ;; 값2) 실행내용2 ;; 값3) 실행내용3 ;; *) 실행내용4 esac ``` ",
    "url": "/docs/daily-learning-log/20210401.html",
    "relUrl": "/docs/daily-learning-log/20210401.html"
  },"40": {
    "doc": "2021-04-01",
    "title": "쉘 프로그래밍의 조건문에서의 '조건'\t\t\t",
    "content": "- 명령의 실행 결과가 if의 조건으로 사용됨 : 종료상태 (Exit Status) - 정상종료 : 0 (true) - 비정상종료 : 0이 아닌 모든 값 (false) - /usr/bin/true, /usr/bin/false : 다른 역할은 하지 않으면서 종료상태만 변경 - ‘ : ’ : true 와 같은 역할 - 수치비교, 문자, 문자열비교 : test - 수치비교 - == : equal; INT1 -eq INT2 - != : not equal; INT1 -ne INT2 - > : greater than ; INT1 -gt INT2 - = : greater or equal ; INT1 -ge INT2 - 문자열2 ]] : 문자열1이 문자열2보다 ASCII 값이 크면 참 - 마찬가지로, let을 사용하여 수치비교 가능 : (( )) - (( 변수1 > 숫자 )) : 변수1이 숫자보다 크면 참 - (( 변수1 = 변수2 + 변수3 )) : 변수를 사용한 계산 가능 - 파일관련 조건 확인 : [옵션] [파일명] - -b : 블록 장치인지 - -c : 캐릭터 장치인지 - -d : 디렉토리인지 - -e : 파일이 존재하는지 - -f : 일반 파일인지 - -r : test를 수행하는 사용자가 파일의 읽기 권한이 있는지 - -w : test를 수행하는 사용자가 파일의 쓰기 권한이 있는지 - -x : test를 수행하는 사용자가 파일의 실행 권한이 있는지 - -u : SetUID가 설정되어 있는지 - -g : SetGID가 설정되어 있는지 - -k : StickyBit가 설정되어 있는지 - test 사용시 조건의 논리합/논리곱 - and : [ 조건1 -a 조건2 ] 혹은 [[ 조건1 && 조건2 ]] - or : [ 조건1 -o 조건2 ] 혹은 [[ 조건1 \\|\\| 조건2 ]] ",
    "url": "/docs/daily-learning-log/20210401.html",
    "relUrl": "/docs/daily-learning-log/20210401.html"
  },"41": {
    "doc": "2021-04-01",
    "title": "2021-04-01",
    "content": " ",
    "url": "/docs/daily-learning-log/20210401.html",
    "relUrl": "/docs/daily-learning-log/20210401.html"
  },"42": {
    "doc": "2021-04-05",
    "title": "Ansible",
    "content": " ",
    "url": "/docs/daily-learning-log/20210405.html",
    "relUrl": "/docs/daily-learning-log/20210405.html"
  },"43": {
    "doc": "2021-04-05",
    "title": "Ansible 실습 환경",
    "content": "- Control Node : CentOS 7.8 ova IP : 192.168.100.10/24 gateway : 192.168.100.2 dns : 192.168.100.2 ```js # nmcli connection add con-name static ifname ens33 type ethernet ipv4.addresses 192.168.100.10/24 ipv4.gateway 192.168.100.2 ipv4.dns 192.168.100.2 ipv4.method manual # nmcli connection up static # nmcli connection show # nmcli connection delete ens33 # ip a s ens33 # ping 192.168.100.21 # ping 192.168.100.22 # hostnamectl set-hostname control.example.local ``` - Managed hosts : CentOS 7.8 ova ; multi-user.target, 메모리, CPU 확인 IP : 192.168.100.21,22/24 gateway : 192.168.100.2 dns : 192.168.100.2 ```js # nmcli connection add con-name static ifname ens33 type ethernet ipv4.addresses 192.168.100.21/24 ipv4.gateway 192.168.100.2 ipv4.dns 192.168.100.2 ipv4.method manual # nmcli connection up static # nmcli connection delete ens33 # systemctl set-default multi-user.target # reboot ``` ---------------------------------------- ",
    "url": "/docs/daily-learning-log/20210405.html",
    "relUrl": "/docs/daily-learning-log/20210405.html"
  },"44": {
    "doc": "2021-04-05",
    "title": "기존 시스템 관리 방식",
    "content": "- 수동관리. 직접 콘솔을 통해서 관리. 네트워크를 통한 접근 - 직접 관리 방식은 사용자에 의한 오류 발생 등의 가능성이 높음 - 수행 결과에 대한 검증 - 각자 다른 환경에 대한 일괄적인 구성이 어려움 - 유지관리 어려움 - 자동화된 관리의 필요성 : IaC ",
    "url": "/docs/daily-learning-log/20210405.html",
    "relUrl": "/docs/daily-learning-log/20210405.html"
  },"45": {
    "doc": "2021-04-05",
    "title": "IaC 개요",
    "content": "- Infrastructure as Code : 코드형 인프라 - 코드에 의하여 자동적으로 인프라를 구성하도록 하는 방식 - 인프라 자체에 대한 배포 - 구성 설정을 관리 - 클라우드 등과 결합하여 더 강력한 힘을 가지게 됨 ",
    "url": "/docs/daily-learning-log/20210405.html",
    "relUrl": "/docs/daily-learning-log/20210405.html"
  },"46": {
    "doc": "2021-04-05",
    "title": "IaC 특징",
    "content": "- 시스템이 자동으로 읽어서 처리할 수 있는 언어(Code)를 사용 - 상태에 대하여 이해를 하고, 변경사항을 반영할 수 있도록 구성 - 텍스트 형태의 파일로 구성되어 버전 관리가 용이 - 인적 오류 완화 ",
    "url": "/docs/daily-learning-log/20210405.html",
    "relUrl": "/docs/daily-learning-log/20210405.html"
  },"47": {
    "doc": "2021-04-05",
    "title": "Ansible",
    "content": "- 오픈소스 자동화 관리도구 플랫폼 - 상용화된 기능도 제공 : Ansible Tower - 구성관리의 포지션을 담당 - 일회성 명령, 플레이북(Playbook) 사용 - 플레이북은 YAML(YAML Ain't Markup Language) 문법을 사용 - Agentless(에이전트가 없음) ; SSH, Python이 필요 ; 관리하는 역할이 필요 없다는 얘기는 아님 - Idempotency : 멱등성 (연산을 여러 번 적용하더라도 결과가 달라지지 않는 성질) 반복적으로 작업을 실행해도 이미 실행한 작업은 다시 수행하지 않음 ",
    "url": "/docs/daily-learning-log/20210405.html",
    "relUrl": "/docs/daily-learning-log/20210405.html"
  },"48": {
    "doc": "2021-04-05",
    "title": "Redhat 리눅스 관련 자격증",
    "content": "- RHCSA(RedHat Certified System Administrator) : 리눅스 기본 - RHCE(RedHat Certified Engineer) : 리눅스 고급관리 → Ansible로 바뀜 ",
    "url": "/docs/daily-learning-log/20210405.html",
    "relUrl": "/docs/daily-learning-log/20210405.html"
  },"49": {
    "doc": "2021-04-05",
    "title": "Ansible 아키텍처",
    "content": "- 제어 노드 (Control Node) - Ansible을 사용하여 Managed hosts를 관리하는 역할 - Ansible이 실제 설치되어야 하는 위치 - 프로젝트 파일 작성, 보관 - 관리 호스트 (Managed Host) - Ansible을 통해 관리되는 인프라 - 인벤토리(Inventory)를 사용하여 관리 호스트 목록을 제어 - 개별 호스트, 그룹 지정 가능 - 정적 인벤토리 / 동적 인벤토리 사용 가능 - 플레이북 - YAML 형태의 언어로 구성된 텍스트 파일 - 플레이북은 하나 이상의 플레이로 구성 - 플레이는 하나 이상의 작업(Tasks)로 구성 - 작업 - 모듈(Module)을 실행 - 거의 대부분의 모듈은 멱등성을 지원 (command, shell, raw 등은 제외) - 플레이북 내에서 작업 실행 중 실패시 나머지 작업이 중단 ",
    "url": "/docs/daily-learning-log/20210405.html",
    "relUrl": "/docs/daily-learning-log/20210405.html"
  },"50": {
    "doc": "2021-04-05",
    "title": "Ansible 권장 사용방식",
    "content": "- 복잡하지 않게 - 가독성을 좋게 - 선언적인 사고 : 모듈 내에서는 해당 모듈을 통해 갖추어야 할 상태를 정의 ------------------------------------------ ",
    "url": "/docs/daily-learning-log/20210405.html",
    "relUrl": "/docs/daily-learning-log/20210405.html"
  },"51": {
    "doc": "2021-04-05",
    "title": "Ansible 설치 (제어 노드)",
    "content": "- 제어노드는 유닉스/리눅스만 가능 (Windows는 안됨) - 파이썬 2.6 이상 또는 3버전 이상 필요 - ssh 명령 사용 가능 - CentOS 에서는 EPEL 레포지토리가 활성화되어 있어야 설치 가능 ```js # yum install epel-release # yum install ansible ``` ",
    "url": "/docs/daily-learning-log/20210405.html",
    "relUrl": "/docs/daily-learning-log/20210405.html"
  },"52": {
    "doc": "2021-04-05",
    "title": "관리노드 설정 확인",
    "content": "- 리눅스/유닉스/Windows/네트워크 장비 등을 사용 가능 - 리눅스/유닉스/네트워크장비 : SSH 연결 + Python (2.6 이상) - Windows : WinRM (Windows Remote Management) + PowerShell - SSH 연결 : 키 기반 인증 설정 ; key-gen을 이용해서 키를 호스트에 복사해서 ssh연결을 암호없이 사용 - 모듈 실행 시 암호 입력하는 식으로 하고싶으면 명령 맨 끝에 --ask-pass ",
    "url": "/docs/daily-learning-log/20210405.html",
    "relUrl": "/docs/daily-learning-log/20210405.html"
  },"53": {
    "doc": "2021-04-05",
    "title": "인벤토리 생성",
    "content": "- 인벤토리 파일은 INI 파일 형식 또는 YAML 형식으로 작성 (주로 INI) - [항목] 형태나 [키]=[값] 형태로 작성 - 호스트 그룹 사용시 [그룹이름] - 기본적으로 지정되어 있는 그룹 - all : 인벤토리 내의 모든 호스트들을 중복을 제거하고 출력 - ungrouped : 특정 그룹에 속하지 않은 호스트 - 인벤토리 확인 : --list-hosts - ansible -i [인벤토리] --list-hosts - 인벤토리에 호스트 지정시 범위 사용 가능 - server1.example.local ~ server10.example.local 호스트 등록시 : server[1:10].example.local - 숫자는 [시작:마지막:iteration]으로 지정하며 [01:10]과 같은 형식도 가능 - 알파벳도 가능 [a:f] ",
    "url": "/docs/daily-learning-log/20210405.html",
    "relUrl": "/docs/daily-learning-log/20210405.html"
  },"54": {
    "doc": "2021-04-05",
    "title": "Ad-hoc 명령 실행",
    "content": "- ansible 명령을 사용하여 단일 모듈을 대상에 대하여 실행 - 명령어 : ansible -m [사용할 모듈] -a [모듈 사용시 필요한 argument] -i [인벤토리] ```js # ansible -m ping -i inventory managed1.example.local #ping모듈은 argument 필요 없음 # ansible -i inventory --list-hosts all #all 그룹에게 실행하기 ``` ",
    "url": "/docs/daily-learning-log/20210405.html",
    "relUrl": "/docs/daily-learning-log/20210405.html"
  },"55": {
    "doc": "2021-04-05",
    "title": "Ansible 주요 파일",
    "content": "- /etc/ansible/hosts : 기본 Ansible 인벤토리 파일 - /etc/ansible/ansible.cfg : 기본 Ansible 설정 파일 (config) ; 이 파일은 우선 순위가 높지 않음 - Ansible 설정파일 우선순위 - ANSIBLE_CONFIG : 환경변수로 지정한 경로의 파일 사용. 유연한 관리 - ./ansible.cfg : ansible 명령을 실행하고 있는 working directory 내 설정파일 - ~/.ansible.cfg : 사용자에게 적용되는 Ansible 설정 파일 - /etc/ansible/ansible.cfg - 사용중인 설정파일 확인 방법 - ansible --version : 현재 위치에서 ansible 명령 사용시 쓰는 설정파일 확인 - ansible-config - view : 설정파일 내용 출력 - dump : 전체 설정항목 값 출력 (노란색 : 설정파일에 의해 변경된 값) - Ansible 설정 파일 내 주요 항목 - [defaults] : Ansible 동작의 기본 설정. ex) 인벤토리 등 - inventory : 인벤토리 파일/디렉토리의 경로 - 기본값 : /etc/ansible/hosts - remote_user : 관리 호스트(managed host)가 접근시 사용할 계정 ; root는 권장하지 않음 - 기본값 : 사용자이름 - ask_pass : ansible 실행 시 패스워드를 물어볼지 여부 (yes/no/true/false) ; 연결을 위함 - 기본값 : False - [privilege_escalation] : 권한 상승 - become : 관리자 권한 상승 여부 (Y/N/T/F) - 기본값 : False - become_method : 관리자 권한 상승 방법 (sudo/su) - 기본값 : sudo - become_user : 권한 상승시 변경할 사용자 (root) - 기본값 : root - become_ask_pass : 권한 상승시 필요한 암호 입력 여부 (Y/N/T/F) - 기본값 : False ```js - 샘플 cfg (/home/user/ansible/ansible.cfg) [defaults] inventory = ./inventory remote_user = user ask_pass = false [privilege_escalation] become = true become_method = sudo become_user = root become_ask_pass = true ``` ",
    "url": "/docs/daily-learning-log/20210405.html",
    "relUrl": "/docs/daily-learning-log/20210405.html"
  },"56": {
    "doc": "2021-04-05",
    "title": "테스트 명령",
    "content": "- testuser 존재하게 만들기 ```js $ ansible -m user -a 'name=testuser state=present' all BECOME password: managed1.example.local | CHANGED => { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": true, \"comment\": \"\", \"create_home\": true, \"group\": 1001, \"home\": \"/home/testuser\", \"name\": \"testuser\", \"shell\": \"/bin/bash\", \"state\": \"present\", \"system\": false, \"uid\": 1001 } managed2.example.local | CHANGED => { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": true, \"comment\": \"\", \"create_home\": true, \"group\": 1001, \"home\": \"/home/testuser\", \"name\": \"testuser\", \"shell\": \"/bin/bash\", \"state\": \"present\", \"system\": false, \"uid\": 1001 } $ ansible -m user -a 'name=testuser state=present' all BECOME password: managed2.example.local | SUCCESS => { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"append\": false, \"changed\": false, \"comment\": \"\", \"group\": 1001, \"home\": \"/home/testuser\", \"move_home\": false, \"name\": \"testuser\", \"shell\": \"/bin/bash\", \"state\": \"present\", \"uid\": 1001 } managed1.example.local | SUCCESS => { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"append\": false, \"changed\": false, \"comment\": \"\", \"group\": 1001, \"home\": \"/home/testuser\", \"move_home\": false, \"name\": \"testuser\", \"shell\": \"/bin/bash\", \"state\": \"present\", \"uid\": 1001 } ``` - 다시 실행하면 changed=false가 됨 (이미 한 번 실행한 상태에서 또 실행해봤자 바뀌는 것이 없기 때문) - testuser 존재하지 않도록 만들기 ```js $ ansible -m user -a 'name=testuser state=absent' all BECOME password: managed2.example.local | CHANGED => { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": true, \"force\": false, \"name\": \"testuser\", \"remove\": false, \"state\": \"absent\" } managed1.example.local | CHANGED => { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/bin/python\" }, \"changed\": true, \"force\": false, \"name\": \"testuser\", \"remove\": false, \"state\": \"absent\" } ``` ",
    "url": "/docs/daily-learning-log/20210405.html",
    "relUrl": "/docs/daily-learning-log/20210405.html"
  },"57": {
    "doc": "2021-04-05",
    "title": "Tip!!! 자동완성 (root계정으로 해야함!)",
    "content": "- ansible은 자동완성 기능이 없음 - 구글에서 ansible bash completion이라고 검색, 오픈 소스를 찾음 - .bash파일을 서버의 /etc/bash_completion.d 폴더에 저장 - 변경 적용하려면 # exec bash (현재 터미널에서 bash 재시작 명령) ",
    "url": "/docs/daily-learning-log/20210405.html",
    "relUrl": "/docs/daily-learning-log/20210405.html"
  },"58": {
    "doc": "2021-04-05",
    "title": "실습 환경 구성 내용 정리 - 강사님 ",
    "content": "Control node 1개, Managed host 2개를 import 기본 네트워크 및 호스트이름 설정 - Control node ```js $ sudo -i # nmcli connection add con-name static ifname ens33 type ethernet ipv4.addresses 192.168.100.10/24 ipv4.gateway 192.168.100.2 ipv4.dns 192.168.100.2 ipv4.method manual # nmcli connection up static # nmcli connection delete ens33 # hostnamectl set-hostname control.example.local ``` - Managed host 1 ```js $ sudo -i # nmcli connection add con-name static ifname ens33 type ethernet ipv4.addresses 192.168.100.21/24 ipv4.gateway 192.168.100.2 ipv4.dns 192.168.100.2 ipv4.method manual # nmcli connection up static # nmcli connection delete ens33 # systemctl set-default multi-user.target # hostnamectl set-hostname managed1.example.local # reboot ``` - Managed host 2 ```js $ sudo -i # nmcli connection add con-name static ifname ens33 type ethernet ipv4.addresses 192.168.100.22/24 ipv4.gateway 192.168.100.2 ipv4.dns 192.168.100.2 ipv4.method manual # nmcli connection up static # nmcli connection delete ens33 # systemctl set-default multi-user.target # hostnamectl set-hostname managed2.example.local # reboot ``` Control node의 /etc/hosts 파일을 수정 ```js 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 192.168.100.21 managed1 managed1.example.local 192.168.100.22 managed2 managed2.example.local ``` Managed host에 SSH 키 기반인증을 하기 위하여 필요한 키 생성 (반드시 Control node에서 실행) ```js user@control $ ssh-keygen 입력항목은 전부 기본값으로 설정 user@control $ ssh-copy-id user@managed1.example.local user@control $ ssh-copy-id user@managed2.example.local ``` 각 호스트에 키 기반 인증이 연결되는지 확인 ```js user@control $ ssh user@managed1.example.local user@control $ ssh user@managed2.example.local ``` Control node에 ansible 설치 (Managed 에는 설치할 필요 없음) ```js user@control $ sudo yum -y install epel-release user@control $ sudo yum -y install ansible ``` Ansible 설치 확인 ```js user@control $ ansible --version ``` (옵션) ansible bash completion 설치 ```js user@control $ sudo -i root@control # cd /etc/bash_completion.d/ root@control # wget https://raw.githubusercontent.com/dysosmus/ansible-completion/master/ansible-completion.bash root@control # exit user@control $ exec bash ``` ansible 실습용 디렉토리 작성 ```js user@control $ cd user@control $ mkdir ansible user@control $ cd ansible ``` 기본 인벤토리 파일 생성 ```js user@control $ cat > inventory managed1.example.local managed2.example.local ``` 기본 환경설정 파일 생성 ```js user@control $ cat > ansible.cfg [defaults] inventory = ./inventory remote_user = user ask_pass = false [privilege_escalation] become = true become_method = sudo become_user = root become_ask_pass =true ``` ansible 명령 동작 확인 ```js user@control $ ansible -m user -a ‘name=testuser state=present’ all ``` ",
    "url": "/docs/daily-learning-log/20210405.html",
    "relUrl": "/docs/daily-learning-log/20210405.html"
  },"59": {
    "doc": "2021-04-05",
    "title": "2021-04-05",
    "content": " ",
    "url": "/docs/daily-learning-log/20210405.html",
    "relUrl": "/docs/daily-learning-log/20210405.html"
  },"60": {
    "doc": "2021-04-06",
    "title": "Ansible 계속",
    "content": " ",
    "url": "/docs/daily-learning-log/20210406.html",
    "relUrl": "/docs/daily-learning-log/20210406.html"
  },"61": {
    "doc": "2021-04-06",
    "title": "Ansible을 통해 관리자 권한 사용",
    "content": "- sudo 패스워드 입력 없이 sudo 사용 가능 - sudoers 설정의 NOPASSWD 설정 - /etc/sudoers.d/ 파일에 - ALL=(ALL) NOPASSWD: ALL ",
    "url": "/docs/daily-learning-log/20210406.html",
    "relUrl": "/docs/daily-learning-log/20210406.html"
  },"62": {
    "doc": "2021-04-06",
    "title": "명령어에서 ansible.cfg 파일의 설정과 다른 설정을 사용",
    "content": "- 명령어 맨 끝에 원하는 설정 표기 - --inventory, -i : 인벤토리 재지정 - --user, -u : remote user 재지정 - --ask-pass, -k : ask_pass 활성화 - --become, -b : become 활성화 - --become-method : become_method 재지정 - --become-user : become_user 재지정 - --ask-become-pass, -K : become_ask_pass 재지정 ",
    "url": "/docs/daily-learning-log/20210406.html",
    "relUrl": "/docs/daily-learning-log/20210406.html"
  },"63": {
    "doc": "2021-04-06",
    "title": "Ansible 모듈 검색",
    "content": "- ansible docs 검색 - https://docs.ansible.com/ansible/2.9/ 내 module index 항목 참고 - ansible-doc 명령 사용 - ansible-doc -l : 전체 모듈 목록 확인 - ansible-doc [모듈이름] : 개별 모듈 확인 - options : 모듈 사용시 필요한 argument - = : 필수 항목 - - : 선택 항목 (일부 선택항목은 기본값이 지정되어 있으며 ansible-doc에 표기되어있음) - example 참고 - ansible-doc -l | grep [키워드] : 특정 키워드와 관련된 ansible 모듈 검색 ",
    "url": "/docs/daily-learning-log/20210406.html",
    "relUrl": "/docs/daily-learning-log/20210406.html"
  },"64": {
    "doc": "2021-04-06",
    "title": "command, shell, raw 모듈",
    "content": "- 대상 시스템에서 단순 명령 실행 형태로 동작 - raw - python이 없어도 사용 가능 - 일반적으로는 사용하지 않음 - python이 깔려있지 않은 managed host에 python 설치 등을 하기 위한 목적 정도로만 사용 - command - 쉘을 실행하지 않고 명령 수행 - shell - 쉘을 실행하고 쉘 내에서 명령 수행 - 비교 - 파일로 존재하는 명령어 실행시는 차이가 없음 - ansible -m shell -a hostname managed1.example.local - ansible -m command -a hostname managed1.example.local - 쉘 내장 명렁어, 또는 쉘 기능 사용시는 차이가 발생 - ansible -m shell -a set managed1.example.local - ansible -m command -a set managed1.example.local ",
    "url": "/docs/daily-learning-log/20210406.html",
    "relUrl": "/docs/daily-learning-log/20210406.html"
  },"65": {
    "doc": "2021-04-06",
    "title": "Playbook",
    "content": " ",
    "url": "/docs/daily-learning-log/20210406.html",
    "relUrl": "/docs/daily-learning-log/20210406.html"
  },"66": {
    "doc": "2021-04-06",
    "title": "Playbook",
    "content": "- Ansible로 실행할 내용을 작성하는 문서 = Code - ad-hoc 명령과 달리 여러 가지 수행할 내용을 하나의 플레이북에 저장 - 구조 ```js - 플레이북 파일 - 플레이(1개 이상) - 작업 - 모듈(1개 이상) ``` - YAML 문법을 사용하여 작성하여야 함 - 확장자를 .yaml 또는 .yml - --- : 문서의 시작을 의미하는 마커 - … : 문서의 마지막을 의미하는 마커 - 들여쓰기 구조로 작성 : Ansible에서는 일반적으로 공백 2칸으로 한 단계를 지정 - vi 편집기에서 yaml을 작성할 때 공백 기본값을 변경하여 편리하게 코드 작성하는 방법 - ~/.vimrc 파일 작성하기 ```js syntax on autocmd FileType yaml setlocal ts=2 sts=2 sw=2 et ai nu # et: expand tab. 탭 입력시 공백으로 변환 # ai : auto indent. 자동 들여쓰기 # nu : 줄 수 표시 ``` - 목록 사용 가능(리스트) - 목록의 아이템의 하나의 대시, 공백 뒤에 아이템 목록을 표시 - 목록의 아이템1 - 목록의 아이템2 - 목록의 아이템3 - ... - 각 항목의 값을 입력할 경우 ':' 뒤에 입력 - 반드시 항목의 이름 뒤에 붙여서 : 작성 - : 뒤에 공백 한 칸 추가 - 기본적으로 플레이북에 포함되는 항목 - play의 이름(설명): name 항목으로 플레이의 이름을 표시 - hosts: 플레이를 적용할 대상 - tasks: 이 플레이를 통해 실행할 작업의 목록 - 내부에는 작업의 목록이 표시 - name으로 작업에 대한 설명 추가 - 샘플 파일 (test.yaml) ```js --- - name: My first play hosts: managed1.example.local tasks: - name: user testuser must exist user: name: testuser state: present - name: ping test ping: ... ``` ",
    "url": "/docs/daily-learning-log/20210406.html",
    "relUrl": "/docs/daily-learning-log/20210406.html"
  },"67": {
    "doc": "2021-04-06",
    "title": "플레이북 실행",
    "content": "- ansible-playbook [옵션] - ansible 명령과 동일한 옵션 사용가능 : --become 등 - 플레이북 실행 시 구체적인 실행내용 확인 - -v : v의 개수를 1~4개 사용하여 구체적인 정도를 지정 - Gathering Facts : 플레이북 실행 시 자동으로 처음에 실행되는 대상 시스템 정보 수집단계 - Play Recap : 실행 통계. ok(정상), changed(변경), failed(실패) - --syntax-check : 플레이북 파일 내 구조적인 오류 탐지. 내용상의 결함은 찾지 못함 - -C, --check : 예행연습. 실제 대상에 변경을 가하지 않으면서 동작 여부 확인 ",
    "url": "/docs/daily-learning-log/20210406.html",
    "relUrl": "/docs/daily-learning-log/20210406.html"
  },"68": {
    "doc": "2021-04-06",
    "title": "다중 플레이",
    "content": "- 하나의 플레이북 내에 두 개 이상의 플레이를 지정 - 각 플레이는 동일한 들여쓰기 단계를 준수하여 작성 - 각 플레이의 구조는 동일하며, 플레이마다 각각 대상을 지정할 수 있음 (hosts) - 샘플 파일 (test.yaml) ```js --- - name: My first play hosts: managed1.example.local tasks: - name: user testuser must exist user: name: testuser state: present - name: My second play hosts: managed2.example.local tasks: - name: user testuser2 must exist user: name: testuser2 state: present ... ``` ",
    "url": "/docs/daily-learning-log/20210406.html",
    "relUrl": "/docs/daily-learning-log/20210406.html"
  },"69": {
    "doc": "2021-04-06",
    "title": "플레이북 내에서 플레이 별 설정",
    "content": "- 플레이 별로 개별적인 옵션을 지정 가능 (become, become_method, become_user, remote_user…) - 샘플 파일 (test.yaml) ```js --- - name: My first play hosts: managed1.example.local become: true tasks: - name: user testuser must exist user: name: testuser state: present - name: My second play hosts: managed2.example.local become: false tasks: - name: ping test ping: ... ``` ```js --- - name: My first play hosts: managed1.example.local tasks: - name: user testuser must exist user: name: testuser state: present become: true - name: user testuser must exist user: name: testuser2 state: present - name: My second play hosts: managed2.example.local become: false tasks: - name: ping test ping: ... ``` ",
    "url": "/docs/daily-learning-log/20210406.html",
    "relUrl": "/docs/daily-learning-log/20210406.html"
  },"70": {
    "doc": "2021-04-06",
    "title": "연습 - 웹서버 구성",
    "content": "- managed1, managed2 서버를 각각 웹 서버, DB 서버로 구성해 보자 - 각 서버에 필요한 패키지를 설치 - 서비스 구동 - 방화벽 설정 - inventory 구성 (/home/user/practice/inventory) ```js [webservers] managed1.example.local [dbservers] managed2.example.local [allservers:children] webservers dbservers ``` - ansible.cfg 구성 (/home/user/practice/ansible.cfg) ```js [defaults] inventory = ./inventory remote_user = user ask_pass = false [privilege_escalation] become = false become_method = sudo become_user = root become_ask_pass = false ``` - webservice.yaml 구성 ; prototype (/home/user/practice/webservice.yaml) ```js --- - name: webserver is ready hosts: webservers become: true tasks: - name: httpd package is installed yum: name: httpd state: latest - name: httpd service is enabled and started - name: firewall is opened - name: dbserver is ready hosts: dbserver become: true tasks: - name: mariadb package is installed yum: name: mariadb-server state: latest - name: mariadb service is enabled and started - name: firewall is opened ... ``` ",
    "url": "/docs/daily-learning-log/20210406.html",
    "relUrl": "/docs/daily-learning-log/20210406.html"
  },"71": {
    "doc": "2021-04-06",
    "title": "2021-04-06",
    "content": " ",
    "url": "/docs/daily-learning-log/20210406.html",
    "relUrl": "/docs/daily-learning-log/20210406.html"
  },"72": {
    "doc": "2021-04-07",
    "title": "Playbook",
    "content": "연습 - 웹서버 구성 - managed1, managed2 서버를 각각 웹 서버, DB 서버로 구성해 보자 - 각 서버에 필요한 패키지를 설치 - 서비스 구동 - 방화벽 설정 - inventory 구성 (/home/user/practice/inventory) ```js [webservers] managed1.example.local [dbservers] managed2.example.local [allservers:children] webservers dbservers ``` - ansible.cfg 구성 (/home/user/practice/ansible.cfg) ```js [defaults] inventory = ./inventory remote_user = user ask_pass = false [privilege_escalation] become = false become_method = sudo become_user = root become_ask_pass = false ``` - webservice.yaml 구성 ; prototype (/home/user/practice/webservice.yaml) ```js --- - name: webserver is ready hosts: webservers become: true tasks: - name: httpd package is installed yum: name: httpd state: latest - name: httpd service is enabled and started service: name: httpd enabled: true state: started - name: firewall is opened firewalld: service: http state: enabled permanent: true - name: dbserver is ready hosts: dbservers become: true tasks: - name: mariadb package is installed yum: name: mariadb-server state: latest - name: mariadb service is enabled and started service: name: mariadb state: started enabled: yes - name: firewall is opened firewalld: service: mysql state: enabled permanent: yes ... ``` - 실행 전 테스트 ```js $ ansible-playbook webservice.yaml --syntax-check $ ansible-playbook webservice.yaml --check ``` - 실행 후 확인 ```js $ ansible-playbook webservice.yaml ``` 변수(Variables) - 재사용 할 수 있는 값을 저장하기 위하여 사용 - ex. 설치할 패키지의 이름, 서비스의 이름, 추가할 파일의 경로, 인터넷 경로 주소 ... - 변수 이름 규칙 - 사용할 수 있는 글자 : 영문자(대소문자), 숫자, 밑줄 - 문자로 시작해야함 변수 적용 범위에 따른 변수의 위치 - 전역 범위 : 명령줄, Ansible 설정에서 변수를 지정 - ex. ansible-playbook -e “변수이름=변수값” - 플레이 : 플레이북의 구조에서 선언 - 플레이의 vars 예약어를 사용하여 변수 지정 ```js $ cat webservice.yaml --- - name: webserver is ready hosts: webservers become: true vars: package: httpd service: httpd firewall_svc: http ... ``` - 별도의 파일을 사용하여 변수 지정 : yaml 포맷으로 작성 ```js $ cat http.yaml package: httpd service: httpd firewall_svc: http ``` - 파일을 불러올 때에는 vars_files 예약어를 사용하여 변수가 들어있는 파일을 지정 ```js $ cat webservice.yaml --- - name: webserver is ready hosts: webservers become: true vars_files: - http.yml ... ``` - 호스트/그룹 : 인벤토리 내의 특정 호스트/그룹 - 인벤토리 내 특정 호스트에 대한 변수 설정 : 인벤토리 내 호스트 목록 뒤 ```js $ cat inventory [webservers] managed1.example.local service=httpd, package=httpd, firewall_svc=http ``` - 인벤토리 내 특정 그룹에 대한 변수 설정 : [그룹이름:vars] 항목에 표기 ```js $ cat inventory [webservers] managed1.example.local [webservers:vars] service=httpd package=httpd firewall_svc=http ``` - 각 호스트에 대한 변수를 별도의 디렉토리(host_vars)에 파일로 저장 - 각 호스트에 대한 변수를 별도의 디렉토리(group_vars)에 파일로 저장 - 이러한 파일은 포맷을 yaml형식(변수: 값)으로 작성하며 확장자는 필요 없음 ```js . ├── ansible.cfg ├── group_vars │ └── webservers ├── host_vars │ └── managed1.example.local ├── http.yml ├── inventory └── webservice.yaml $ cat ./group_vars/webservers package: httpd service: httpd firewall_svc: http ``` 변수 호출 - \\{\\{ 변수명 }} : 어느 위치에 들어가느냐에 따라 \"\" 추가 위치가 달라짐 - string이 들어가는 라인의 맨 앞 : 전체 string의 맨 앞과 맨 뒤에 \" ; ex. \"{{ package }} package is installed\" - string이 들어가는 라인의 중간 : \" 추가하지 않음 ; ex. firewall {{ firewall_svc }} service is opened - 변수 하나만 들어가는 라인 : 변수 앞뒤로 \" ; ex. \"{{ service }}\" - 플레이범위에서 변수 선언 ```js $ cat webservice2.yaml --- - name: webserver is ready hosts: webservers become: true vars: package: httpd service: httpd firewall_svc: http tasks: - name: \"{{ package }} package is installed\" yum: name: \"{{ package }}\" state: latest - name: \"{{ service }} service is enabled and started\" service: name: \"{{ service }}\" enabled: true state: started - name: firewall {{ firewall_svc }} service is opened firewalld: service: \"{{ firewall_svc }}\" state: enabled permanent: true ... ``` - 플레이범위에서 변수 파일 선언 ```js $ cat http.yaml package: httpd service: httpd firewall_svc: http $ cat webservice2.yaml --- - name: webserver is ready hosts: webservers become: true vars_files: - http.yml tasks: - name: \"{{ package }} package is installed\" yum: name: \"{{ package }}\" state: latest - name: \"{{ service }} service is enabled and started\" service: name: \"{{ service }}\" enabled: true state: started - name: firewall {{ firewall_svc }} service is opened firewalld: service: \"{{ firewall_svc }}\" state: enabled permanent: true ... ``` - 인벤토리에서 호스트범위, 그룹범위에 변수 선언 - 아래 예시의 경우, dbservers그룹에 managed3이 있었다면 service 변수 호출이 되지 않아서 오류가 발생했을 것 ```js $ cat inventory [webservers] managed1.example.local [dbservers] managed2.example.local service=mariadb #호스트범위 변수 선언 : 해당 호스트 호출시 사용 [dbservers:vars] #그룹범위 변수 선언 : 해당 그룹에 속하는 호스트 호출시 사용 package=mariadb-server firewall_svc=mysql [allservers:children] webservers dbservers $ cat webservice2.yaml --- - name: dbserver is ready hosts: dbservers become: true tasks: - name: \"{{ package }} package is installed\" yum: name: \"{{ package }}\" state: latest - name: \"{{ service }} service is enabled and started\" service: name: \"{{ service }}\" state: started enabled: yes - name: firewall {{ firewall_svc }} service is opened firewalld: service: \"{{ firewall_svc }}\" state: enabled permanent: yes ... ``` - 특정 디렉토리에 호스트범위, 그룹범위 변수 파일 선언 - 아래 예시를 사용하면 webservers와 dbservers 따로 플레이 작성하던 것을 하나로 통합 가능 ```js $ mkdir group_vars $ cat > group_vars/webservers service: httpd package: httpd firewall_svc: http $ cat > group_vars/dbservers service: mariadb package: mariadb-server firewall_svc: mysql $ cat webservice2.yaml --- - name: webservers and dbservers are ready hosts: webservers, dbservers become: true tasks: - name: \"{{ package }} package is installed\" yum: name: \"{{ package }}\" state: latest - name: \"{{ service }} service is enabled and started\" service: name: \"{{ service }}\" enabled: true state: started - name: firewall {{ firewall_svc }} service is opened firewalld: service: \"{{ firewall_svc }}\" state: enabled permanent: true ... ``` 변수의 배열 - ex. 사용자 추가를 위한 변수 선언 - 단순 변수 형태 ```js user1_id user1_uid user1_homedir user1_login_shell user2_id user2_uid user2_homedir user2_login_shell ``` - 배열 형태 ```js user1 id uid homedir login_shell user2 id uid homedir login_shell ``` - 사용자들이 저장된 배열 ```js users user1 id uid homedir login_shell user2 id uid homedir login_shell ``` 변수 호출방식 - users.user1.id - users['user1']['id'] 명령 출력 캡쳐 - register : 모듈 실행시 실행 결과를 지정한 이름의 변수에 저장하는 기능 (모듈 내에서 작동하는 기능임) - debug : 변수의 값 등을 출력할 수 있는 모듈 ```js $ cat test.yaml --- - name: register and debug test hosts: webservers become: true tasks: - name: install package yum: name: tree state: latest register: result - name: print result debug: var: result ... ``` 변수의 배열 출력 - 목록이나 사전을 사용하지 않는 유형 ```js $ cat vartest.yaml --- - name: variable test hosts: webservers vars: user1_id: alice user1_uid: 10000 user1_homedir: /home/alice user2_id: bob user2_uid: 10001 user2_homedir: /home/bob tasks: - name: print username debug: var: user1_id - name: print user uid debug: var: user1_uid - name: print user home directory debug: var: user1_homedir ... ``` - 목록 형태의 변수 유형 ```js $ cat vartest.yaml --- - name: variable test hosts: webservers vars: user1: - alice - 10000 - /home/alice user2: - bob - 10001 - /home/bob tasks: - name: print username debug: var: user1[0] - name: print user uid debug: var: user1[1] - name: print user home directory debug: var: user1[2] - name: print user debug: var: user1 ... ``` - 사전 형태의 변수 유형 ```js $ cat vartest.yaml --- - name: variable test hosts: webservers vars: user1: id: alice uid: 10000 homedir: /home/alice user2: id: bob uid: 10001 homedir: /home/bob tasks: - name: print username debug: var: user1['id'] - name: print user uid debug: var: user1.uid - name: print user home directory debug: var: user1.homedir - name: print user debug: var: user1 ... ``` ```js $ cat vartest.yaml --- - name: variable test hosts: webservers vars: users: user1: id: alice uid: 10000 homedir: /home/alice user2: id: bob uid: 10001 homedir: /home/bob tasks: - name: print username debug: var: users['user1']['id'] - name: print user uid debug: var: users.user1.uid - name: print user home directory debug: var: users.user1.homedir - name: print users debug: var: users ... ``` 팩트 (Ansible Facts) Ansible Facts - Ansible이 대상 시스템으로부터 자동으로 수집한 정보 - 수집한 정보를 변수 형태로 저장 - 대상 시스템의 상태를 확인하고 상태에 따라 조치하도록 하기 위하여 사용 - 플레이북을 작성하고 실행 시 기본적으로 각 플레이 시작 단계에서 수행 - 필요에 따라 팩트 수집을 해제할 수 있음 - gather_facts 항목을 플레이에 설정 ```js --- - name: variable test hosts: webservers gather_facts: no tasks: ... ``` - 필요에 따라 직접 팩트 수집을 수행할 수 있음 : setup (모듈) - ex. ansible -m setup webservers - 기본적으로 setup 모듈에 수집할 항목들이 지정되어 있음 - ansible_facts : setup 모듈에 의해 수집된 팩트 정보가 저장되는 변수 - ansible_facts.[팩트항목] 혹은 ansible_fact['팩트항목'] 형태로 각 팩트에 접근 - hostname : 짧은 호스트 이름 (도메인 이름 제외) - fqdn : 전체 호스트 이름 (도메인 이름 포함) - default_ipv4.address : 대상의 IP주소 정보 - interfaces : 네트워크 인터페이스 정보 - kernel : 커널 정보 (버전) - devices.sda.partitions.sda1.size : 장치 정보 ```js --- - name: Ansible Facts test hosts: webservers tasks: - name: print fact variable value debug: var: ansible_facts.hostname - name: Ansible Facts test2 hosts: webservers tasks: - name: print fact variable value debug: var: ansible_facts['hostname'] ... ``` - setup 모듈을 ad-hoc 방식으로 실행할 경우, ansible_facts 변수의 하위 항목이 구식 표기방법으로 표시됨 - ex. ansible_hostname, ansible_fqdn 사용자 지정 Facts - 기본 Ansible Facts와 같이 setup에 의해서 수집되는 데이터를 사용자가 직접 지정 - 팩트로 제공할 내용을 managed host에 파일 형태로 미리 작성해놓아야 함 - /etc/ansible/facts.d 디렉토리 내에 .fact로 끝나는 이름으로 작성 ```js [root@managed1 ~]# cat /etc/ansible/facts.d/test.tact [users] user1=alice user2=bob [webservice] package=httpd service=httpd firewall_svc=httpd ``` - control node에서 확인 방법 - ansible -m setup webservers \\| less - /ansible_local 을 입력하면 검색됨 ",
    "url": "/docs/daily-learning-log/20210407.html",
    "relUrl": "/docs/daily-learning-log/20210407.html"
  },"73": {
    "doc": "2021-04-07",
    "title": "2021-04-07",
    "content": " ",
    "url": "/docs/daily-learning-log/20210407.html",
    "relUrl": "/docs/daily-learning-log/20210407.html"
  },"74": {
    "doc": "2021-04-08",
    "title": "파일 다루기",
    "content": "파일 관리 관련 모듈 - file - copy - fetch - lineinfile - blockinfile - stat file module - 다른 파일 관리 모듈들의 기본 동작 - 파일 자체에 대한 속성 설정 - 소유권 - 권한 - SELinux 컨텍스트 - Timestamp - 기본적인 파일 생성/제거 용도로 사용 ```js --- - name: File module test hosts: webservers gather_facts: no tasks: - name: file module test - /tmp/test file: path: /tmp/test state: touch ``` ```js --- - name: File module test hosts: webservers gather_facts: no tasks: - name: file module test - /tmp/test file: path: /tmp/test2 state: touch owner: user group: wheel mode: 0640 ``` ```js --- - name: File module test hosts: webservers gather_facts: no tasks: - name: file module test - /tmp/test file: path: /tmp/test3 state: touch owner: root group: root mode: 0600 setype: default_t ``` 참고 : SELinux 컨텍스트 규칙 변경 모듈 - sefcontext - file 모듈의 setype은 chcon과 같이 파일의 컨텍스트 타입을 직접 지정 - 규칙을 지정할 경우 sefcontext 모듈 사용 - 규칙이 지정되어도, 즉시 반영되지는 않음 - 규칙을 반영하기 위해서는 command, shell 등의 모듈을 사용하여 restorecon 명령을 직접 수행하여야 함 ```js EXAMPLES: - name: Allow apache to modify files in /srv/git_repos sefcontext: target: '/srv/git_repos(/.*)?' setype: httpd_git_rw_content_t state: present - name: Apply new SELinux file context to filesystem command: restorecon -irv /srv/git_repos ``` 파일 복사 모듈 : copy, fetch - copy - ansible이 실행되는 control node의 파일을 managed host에게 복사 - src로 특정 파일을 지정하거나, content로 파일 내용을 작성 ```js --- - name: File module test hosts: webservers gather_facts: no become: true tasks: - name: copy module test - /etc/hosts copy: src: /etc/hosts dest: /etc/hosts ``` ```js --- - name: File module test hosts: webservers gather_facts: no become: true tasks: - name: copy module test - /etc/motd copy: dest: /etc/motd content: \"Hello my Server!!!\" ``` - fetch - copy와 반대로 각 managed host에 있는 파일을 control node로 복사 ```js --- - name: File module test hosts: webservers gather_facts: no become: true tasks: - name: fetch module test fetch: src: /etc/passwd dest: /tmp ``` 내용 추가 모듈 : lineinfile, blockinfile - lineinfile : 지정한 파일에 입력한 텍스트 라인을 추가 ```js --- - name: File module test hosts: all gather_facts: no become: true tasks: - name: lineinfile test lineinfile: path: /etc/hosts line: '192.168.100.23 managed3 managed3.example.local' state: present ``` - blockinfile : 지정한 파일에 입력한 텍스트 블록을 추가 ```js --- - name: File module test hosts: all gather_facts: no become: true tasks: - name: blockinfile test blockinfile: path: /etc/hosts block: | 192.168.100.24 managed4 managed4.example.local 192.168.100.25 managed5 managed5.example.local 192.168.100.26 managed6 managed6.example.local state: present ``` 파일 상태 정보 조회 모듈 : stat (= 리눅스 명령어 stat) ```js --- - name: File module test hosts: all gather_facts: no become: true tasks: - name: stat module test stat: path: /tmp/test register: result - name: print file stat debug: var: result['stat']['checksum'] ``` template - 모든 값이 fix 되어 있지 않고, 일부 항목을 변경할 수 있는 파일 - jinja2: template에서 사용하는 유형 - \\{\\{ 변수명 }} : 변수의 값을 입력하여 템플릿 생성 - {# 주석 #} : 템플릿 내에 주석 사용 - {\\% 논리구조 등 %} : jinja2 템플릿의 고급 사용 - 템플릿에서 사용 가능한 변수 : ansible 내부 변수, 팩트 변수 ```js $ cat template.j2 System name : {{ ansible_facts.fqdn }} System OS : {{ ansible_distribution }} System version : {{ ansible_facts['distribution_version'] }} System administrator : {{ system_admin }} ``` ```js --- - name: create motd file hosts: all become: true tasks: - name: create motd file using template template: src: ./template.j2 dest: /etc/motd owner: root group: root mode: 0644 ``` ```js $ mkdir host_vars $ cat > host_vars/managed1.example.local system_admin: admin1@example.local $ cat > host_vars/managed2.example.local system_admin: admin2@example.local ``` 암호화 기능 - Playbook, vars_files 등 평문 형태로 되어 있는 파일들을 보호하기 위한 방법 - Secret = Ansible Vault - AES256 방식 암호화 수행 - 서브커맨드 종류 (ansible-vault --help로 확인 가능) - create : 새로운 암호화 파일 생성 - view : 암호화 된 파일 보기 - edit : 암호화 된 파일 수정 - encrypt : 기존 파일을 암호화 - decrypt : 암호화 된 파일을 해제 - rekey : 암호 키 변경 ```js $ ansible-vault create secret_file.yml New Vault password: Confirm New Vault password: --- - name: secret file hosts: all tasks: - name: echo hello debug: msg: \"Hello\" ... ``` - 암호화 된 파일을 ansible-playbook 명령으로 사용할 경우 - --ask-vault-pass : 암호 직접 입력 - --vault-id @prompt : 압호 직접 입력 - --vault-password-file : 파일 형태로 저장되어 있는 암호를 사용 - 암호 파일만 chmod 600처럼 소유자만 읽고 쓰기 가능하도록 설정하여 보안 강화 가능 참고!!! 항상 명령어 관련 설명은 --help나 man 명령어 써서 확인하기! - ex. ansible-vault --help ",
    "url": "/docs/daily-learning-log/20210408.html",
    "relUrl": "/docs/daily-learning-log/20210408.html"
  },"75": {
    "doc": "2021-04-08",
    "title": "2021-04-08",
    "content": " ",
    "url": "/docs/daily-learning-log/20210408.html",
    "relUrl": "/docs/daily-learning-log/20210408.html"
  },"76": {
    "doc": "2021-04-09",
    "title": "작업 제어",
    "content": "작업 제어 - 반복문 - 조건문 - 핸들러 - 오류 처리 반복문 (Loop) - loop에서 쓸 항목들은 {{ item }}이라는 변수로 쓴다. - loop에서 쓸 항목들은 배열 형태여야 한다. - 아래 예시들은 모두 같은 task를 진행한다. ```js # 기본 실행 --- - name: service start hosts: webservers become: true tasks: - name: install service httpd, mariadb-server yum: name: - httpd - mariadb-server state: latest - name: start service httpd service: name: httpd state: started - name: start service mariadb service: name: mariadb state: started ``` ```js # loop: 밑에 항목을 나열한다. --- - name: service start hosts: webservers become: true tasks: - name: install service httpd, mariadb-server yum: name: - httpd - mariadb-server state: latest - name: start service httpd service: name: \"{{ item }}\" state: started loop: - httpd - mariadb ``` ```js # loop: 밑에 나열할 항목들은 다시 playbook 초반에 vars: 를 이용하여 변수로 만들 수 있다. --- - name: service start hosts: webservers become: true vars: services: - httpd - mariadb tasks: - name: install service httpd, mariadb-server yum: name: - httpd - mariadb-server state: latest - name: start service httpd service: name: \"{{ item }}\" state: started loop: \"{{ services }}\" ``` ```js # vars: 에 딕셔너리형의 배열 형태로 선언하여 모든 task를 아래와 같이 일관성있게 작성할 수 있다. --- - name: service start hosts: webservers become: true vars: svcpkg: - service: httpd package: httpd - service: mariadb package: mariadb-server tasks: - name: install service httpd, mariadb-server yum: name: \"{{ item.package }}\" state: latest loop: \"{{ svcpkg }}\" - name: start service httpd service: name: \"{{ item.service }}\" state: started loop: \"{{ svcpkg }}\" ``` 반복문 + register - 반복문을 사용하여 register로 결과 저장시 결과물 또한 배열 형태로 모두 저장됨 ```js --- - name: loop register test hosts: webservers tasks: - name: Echo with loop shell: \"echo Hello {{ item }}!\" loop: - Kim - Park - Lee register: result - name: print result debug: var: result ``` ```js --- - name: loop register test hosts: webservers tasks: - name: Echo with loop shell: \"echo Hello {{ item }}!\" loop: - Kim - Park - Lee register: result - name: print result debug: var: result['results'][0]['rc'] ``` 실습 - webservers에 설치할 패키지: httpd, firewalld - webservers에 구동할 서비스: httpd, firewalld - dbservers에 설치할 패키지: mariadb-server, firewalld - dbservers에 구동할 서비스: mariadb, firewalld ```js $ cat group_vars/webservers svcpkg: - service: httpd package: httpd - service: firewalld package: firewalld $ cat group_vars/dbservers svcpkg: - service: mariadb package: mariadb-server - service: firewalld package: firewalld $ cat install_with_loop.yml --- - name: install packages and start services with each group vars hosts: webservers, dbservers become: true tasks: - name: Install package yum: name: \"{{ item.package }}\" state: latest loop: \"{{ svcpkg }}\" - name: Start service service: name: \"{{ item.service }}\" state: started enabled: true loop: \"{{ svcpkg }}\" ``` 조건문 - 조건을 설정하여 작업의 수행 여부를 결정 - 팩트 정보를 사용하여 조건을 확인하는 경우가 많음 - when 사용. 작업의 이름과 동일한 위치로 호출 ```js - name: when test yum: name: httpd state: latest when: ``` - 조건식 사용방법 - 연산자 - 산술비교 : ==, !=, >, =, is (not) defined - bool 타입의 변수 : (not) - 목록 내의 항목 존재여부 : in - 복수 조건 사용 - 논리합 : or - 논리곱 : and - 조건을 목록 형태로 작성 : 논리곱으로 적용됨 - 조건식 사용시 조건의 내용이 길어질 경우 다음 줄에 작성 가능 ```js when: > ( or ) and ( or ) when: > ( or > and ( or ) ``` - 조건식과 반복문 함께 사용 - 조건식에 item을 사용하여 loop에 지정된 항목으로 조건 검사 ```js - name: install package if enough space yum: name: package_name state: latest loop: \"{{ ansible_facts.mounts }}\" when: item.mount == \"/\" and item.size_available > 1000000000 ``` 실습 1 - 패키지 설치 : yum 모듈을 사용해서 패키지를 설치 - 조건 : OS가 redhat, centos, fedora 중 하나일 때 ```js $ cat when.yaml --- - name: Install package when true hosts: webservers become: true vars: os_list: - CentOS - RedHat - Fedora tasks: - name: yum install tree yum: name: tree state: latest when: ansible_distribution in os_list ``` 실습2 - 서비스 이름과 재시작여부를 포함하고 있는 변수를 사용하여 loop를 수행 - 조건 : 재시작여부 변수의 값에 따라 실행 여부 결정 ```js --- - name: when test 2 hosts: webservers become: true vars: svcs: - name: httpd restart: true - name: sshd restart: false tasks: - name: restart service service: name: \"{{ item.name }}\" state: restarted loop: \"{{ svcs }}\" when: item.restart ``` 실습3 - register 와 조건문을 함께 사용하여 command, shell 등의 모듈의 실행결과 판단 ```js --- - name: service running check hosts: webservers become: true tasks: - name: check httpd service command: /usr/bin/systemctl is-active httpd.service ignore_errors: true register: result - name: start httpd service: name: httpd state: started when: result.rc != 0 ``` 핸들러 (Handler) - notify / handler 세트로 동작 - notify : 모듈 실행 시 changed 결과가 나올 경우 핸들러에 실행 통지 - handler : 실행할 내용을 명시 - 핸들러 동작 특성 - notify가 있는 위치에서 핸들러를 실행하는 것이 아님 - notify는 핸들러를 사용할 것을 통지만 하고, 핸들러는 모든 task가 완료된 후에 실행 - 핸들러는 여러 차례 호출된다고 하더라도 한 번만 실행 - 핸들러가 여러 개 있고 여러 핸들러가 실행될 경우, 핸들러의 notify 순서와 무관하게 handler에 명시된 순서대로 실행 - 예시 - 일반적인 프로세스 - 웹 서비스 설치 - 웹 서비스 컨텐츠 파일 복사 - 웹 서비스 설정 파일 복사 - 웹 서비스 재실행 - 핸들러 사용시 프로세스 - 웹 서비스 설치 - 웹 서비스 컨텐츠 파일 복사 - 웹 서비스 설정 파일 복사 - 웹 서비스 재실행 (설정 파일이 변경되면) ```js --- - name: Web service hosts: webservers become: true tasks: - name: install httpd yum: name: httpd state: latest - name: copy contents copy: dest: /var/www/html/index.html content: \"Hello World\" - name: copy config file copy: src: ./httpd.conf dest: /etc/httpd/conf/httpd.conf notify: - restart httpd handlers: - name: restart httpd service: name: httpd state: restarted ``` ```js --- - name: Web service hosts: webservers become: true tasks: - name: install httpd yum: name: httpd state: latest - name: copy contents copy: dest: /var/www/html/index.html content: \"Hello World 3\" notify: echo hello - name: copy config copy: content: \"Hello World 3\" dest: /tmp/httpd.conf notify: - restart httpd handlers: - name: restart httpd service: name: httpd state: restarted - name: echo hello debug: msg: \"Hello\" ``` 작업 오류 처리 에러 - 발생하면 즉각 중지 (뒤의 프로세스들은 실행하지 않음) ignore_errors - 에러 발생시 중지하지 않고 다음 작업을 실행하도록 진행 - 작업 내부에 사용 force handlers - 플레이 내부에 사용 (tasks 내부 아님!!) ; true, false - true로 설정시, 작업의 오류로 인해 플레이가 중지되더라도 트리거 된 핸들러는 실행하고 종료 - 작업 오류 시 즉지 중지됨 ( 트리거 된 핸들러는 실행한다는 점이 ignore_error와 다름) ```js --- - name: Web service hosts: webservers become: true force_handlers: true tasks: - name: copy contents copy: dest: /var/www/html/index.html content: \"Hello World 6\" notify: echo hello - name: error yum: name: abcdefjhg state: latest - name: copy config copy: content: \"Hello World 6\" dest: /tmp/httpd.conf notify: - restart httpd handlers: - name: restart httpd service: name: httpd state: restarted - name: echo hello debug: msg: \"Hello\" ``` changed_when - 작업의 changed 여부를 직접 지정 - 조건을 만족할 경우 결과를 changed로 전달 - 조건을 만족하지 않을 경우 결과를 ok로 전달 ```js --- - name: changed_when test hosts: webservers tasks: - name: copy file copy: content: \"Hello World 1\" dest: /tmp/helloworld changed_when: false ``` failed_when - 작업의 failed 여부를 직접 지정 - 조건을 만족할 경우 결과를 failed로 전달 ```js --- - name: failed when test hosts: webservers tasks: - name: sed command 1 command: /usr/bin/sed -n '/root/p' /etc/passwd - name: sed command 2 command: /usr/bin/sed -n '/abcdefg/p' /etc/passwd ``` ```js --- - name: failed when test hosts: webservers tasks: - name: sed command 1 command: /usr/bin/sed -n '/root/p' /etc/passwd - name: sed command 2 command: /usr/bin/sed -n '/abcdefg/p' /etc/passwd register: result failed_when: result.stdout == \"\" ``` 블록 처리 블록 (Block) - 처리가 되는 단위로 묶음 - 예시 - when의 조건을 사용할 경우 ```js --- - name: block test hosts: webservers tasks: - name: install package block: - yum: name: httpd state: latest - name: start service service: name: httpd state: restarted when: ansible_facts.distribution == \"CentOS\" ``` - block / rescue / always 구조에서 사용 - block : 실행할 내용 - rescue : block 실행 중 오류 발생 시 실행할 내용 - always : 무조건 실행할 내용 ```js --- - name: block rescue always test hosts: webservers tasks: - name: Block block: - name: echo hello 1 debug: msg: \"hello 1\" rescue: - name: echo hello 2 debug: msg: \"hello 2\" always: - name: echo hello 3 debug: msg: \"hello 3\" ``` ```js --- - name: block rescue always test hosts: webservers tasks: - name: Block block: - name: echo hello 1 debug: msg: \"hello 1\" - name: failed task fail: rescue: - name: echo hello 2 debug: msg: \"hello 2\" always: - name: echo hello 3 debug: msg: \"hello 3\" ``` ",
    "url": "/docs/daily-learning-log/20210409.html",
    "relUrl": "/docs/daily-learning-log/20210409.html"
  },"77": {
    "doc": "2021-04-09",
    "title": "2021-04-09",
    "content": " ",
    "url": "/docs/daily-learning-log/20210409.html",
    "relUrl": "/docs/daily-learning-log/20210409.html"
  },"78": {
    "doc": "2021-04-20",
    "title": "Docker ",
    "content": "apt가 너무 느릴 때 변경해보자 /etc/apt/sources.list archive.ubuntu.com/ubuntu --> http://mirror.kakao.com/ubuntu/ arhive.ubuntu.com security.ubuntu.com --> ftp.daum.net ",
    "url": "/docs/daily-learning-log/20210420.html",
    "relUrl": "/docs/daily-learning-log/20210420.html"
  },"79": {
    "doc": "2021-04-20",
    "title": "ubuntu에 apache Docker image",
    "content": "```sh mkdir ubuntu-apache cd ubuntu-apache docker run -it ubuntu bash apt update apt install -y apache2 vi index.html ",
    "url": "/docs/daily-learning-log/20210420.html",
    "relUrl": "/docs/daily-learning-log/20210420.html"
  },"80": {
    "doc": "2021-04-20",
    "title": "\n        hello apache with ubuntu base image\n",
    "content": "~/ubuntu-apache$ cat Dockerfile FROM ubuntu:focal RUN apt update RUN DEBIAM_FRONTEND=noninteractive apt install tzdata ENV TZ Asia/Seoul RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone RUN dpkg-reconfigure --frontend noninteractive tzdata RUN apt install -y apache2 ADD index.html /var/www/html/index.html ENV A 100 ENTRYPOINT [\"/usr/sbin/apache2ctl\"] CMD [\"-D\",\"FOREGROUND\"] EXPOSE 80 VOLUME /var/www/html docker run -d -p 80:80 ubuntu-apache:v1 . ``` 레이어가 캐쉬로 저장됨 이전 dockerfile의 레이어와 같으면 캐쉬로 쓰고, 바뀐 부분만 레이어 교체 실행한다고 봐도 될 듯? 매번 새로운 업데이트 버전을 깔고 싶은데, 캐쉬때문에 업데이트를 안함 --no-cache 옵션을 넣으면 모든 레이어를 새로 빌드 ",
    "url": "/docs/daily-learning-log/20210420.html",
    "relUrl": "/docs/daily-learning-log/20210420.html"
  },"81": {
    "doc": "2021-04-20",
    "title": "c언어 컴파일 이미지 만들기 ",
    "content": "```sh mkdir c-hello cd c-hello vi hello.c #include int main() { printf(\"Hello C World!\\n\"); return 0; } sudo apt install gcc gcc hello.c -o hello ./hello 결과 : Hello C World! vi Dockerfile FROM ubuntu:focal ADD hello /hello CMD [\"/hello\"] docker build -t chello . docker run chello ``` ",
    "url": "/docs/daily-learning-log/20210420.html",
    "relUrl": "/docs/daily-learning-log/20210420.html"
  },"82": {
    "doc": "2021-04-20",
    "title": "컴파일 한 실행파일을 docker build 하는 것에 대하여 1 ",
    "content": "c언어 실행파일 작은거 하나를 위해서 ubuntu 올리는거 넘나 손실 Dockerfile에 FROM을 안 쓸 수가 없음 (빌드가 아예 안돼~) 아무것도 없는 이미지(scratch)를 사용한다. ```sh vi Dockerfile FROM scratch ADD hello /hello CMD [\"/hello\"] docker build -t chello . ``` docker images를 통해 아까꺼랑 비교해보면, 우분투 넣었을 때에는 72.9MB sratch 넣었을 때에는 16.7kB 근데, docker run chello하면 실행이 안됨 ldd hello 명령어 쳐서 나온 결과로 필요한 경로 확인해서 (필요한 경로 = 이미지 내부 파일 경로) ```sh mkdir -p lib/x86_64-linux-gnu mkdir lib64 cp /lib/x86_64-linux-gnu/libc.so.6 lib/x86_64-linux-gnu/ cp /lib64/ld-linux-x86-64.so.2 lib64/ vi Dockerfile FROM scratch ADD hello /hello ADD lib /lib ADD lib64 /lib64 CMD [\"/hello\"] docker build -t chello . docker run chello ``` ",
    "url": "/docs/daily-learning-log/20210420.html",
    "relUrl": "/docs/daily-learning-log/20210420.html"
  },"83": {
    "doc": "2021-04-20",
    "title": "컴파일 한 실행파일을 docker build 하는 것에 대하여 2",
    "content": "라이브러리 지정하는 것 넘나 귀찮 아예 컴파일을 라이브러리 가져와서 응용프로그램에 때려넣는 방법도 있음 ```sh gcc hello.c --static -o hello-static file hello-static ldd hello-static ls -lh hello hello-static 크기 비교 해보면, 라이브러리가 더 들어가서 그런지 static 컴파일이 훨씬 더 큼 vi Dockerfile FROM scratch ADD hello-static /hello-static CMD [\"/hello-static\"] docker build -t cstatichello . docker run cstatichello ``` ",
    "url": "/docs/daily-learning-log/20210420.html",
    "relUrl": "/docs/daily-learning-log/20210420.html"
  },"84": {
    "doc": "2021-04-20",
    "title": "2021-04-20",
    "content": " ",
    "url": "/docs/daily-learning-log/20210420.html",
    "relUrl": "/docs/daily-learning-log/20210420.html"
  },"85": {
    "doc": "2021-04-21",
    "title": "Docker ",
    "content": " ",
    "url": "/docs/daily-learning-log/20210421.html",
    "relUrl": "/docs/daily-learning-log/20210421.html"
  },"86": {
    "doc": "2021-04-21",
    "title": "Docker에서 Go language 써보기",
    "content": "```sh sudo apt install golang mkdir go-hello && cd go-hello vi hello.go package main import \"fmt\" func main() { fmt.Println(\"Hello Go!\") } go run hello.go go build -o hello hello.go ./hello >>Hello Go! file hello >>statically linked # golang은 기본이 static build!!! vi Dockerfile FROM scratch COPY hello /hello CMD [\"/hello\"] docker build -t gohello . docker run gohello >>Hello Go! ``` TDD : 테스트 주도 개발 . 작성한 코드가 잘 실행되는지 테스트 할 코드를 작성하는 것 Dockerfile에서 RUN 명령을 이용해서 테스트 코드를 실행하는 용도로 쓸 수 있음 Dockfile에서 golang build까지 하기 . golang을 build, 실행하는 Dockerfile 예시 ```sh vi Dockerfile FROM golang ADD main.go /root WORKDIR /root RUN go build -o /root/mainAPP /root/main.go CMD [\"./mainApp\"] ``` 하지만, golang image 자체가 너무 커서 용량 효율이 좋지 못함 따라서 빌드하는거 따로, 실행하는거 따로 만듦 예시 ```sh FROM golang ADD main.go /root WORKDIR /root RUN go build -o /root/mainApp /root/main.go #FROM alpine:latest FROM scratch WORKDIR /root COPY --from=0 /root/mainApp . CMD [\"./mainApp\"] ``` Dockerfile에서 c컴파일실행 멀티스테이지로 만들기 실습 . ```sh vagrant@docker-engine:~/c-hello$ vi Dockerfile FROM gcc:9 ADD hello.c /root WORKDIR /root RUN gcc hello.c --static -o hello-static FROM scratch WORKDIR /root COPY --from=0 /root/hello-static . CMD [\"./hello-static\"] docker build -t cmultihello . docker run cmultihello ``` Dockerfile에서 go컴파일실행 멀티스테이지로 만들기 실습 . ```sh vagrant@docker-engine:~/go-hello$vi Dockerfile FROM golang ADD hello.go /root WORKDIR /root RUN go build -o /root/hello /root/hello.go FROM scratch WORKDIR /root COPY --from=0 /root/hello . CMD [\"./hello\"] docker build -t gmultihello . docker run gmultihello ``` docker image 프룬으로 none인 댕글이미지 지울 수 있음 멀티스테이지로 하면 맨 위부터 0번 컨테이너가 생김 그래서 --from=0은 0번 컨테이너에서 내용을 가져온다는 의미 근데 주로 ``` FROM golang as gobuilder ``` 이렇게 해놓고 ``` --from=gobuilder ``` 이런식으로 내용 가져오기 가능 ``` docker container stop $(docker container ls –aq) // 일괄 stop docker container rm $(docker container ls –aq) // 일괄 rm ``` ",
    "url": "/docs/daily-learning-log/20210421.html",
    "relUrl": "/docs/daily-learning-log/20210421.html"
  },"87": {
    "doc": "2021-04-21",
    "title": " .dockerignore ",
    "content": "https://docs.docker.com/engine/reference/builder/#dockerignore-file ADD나 COPY 할 때 제외할 파일을 지정함 >> ex. 로그, 임시, 민감한 인증/정보 파일, 패키지 ``` vi .dockerignore Dockerfile logs/ temp/ *.go ``` ",
    "url": "/docs/daily-learning-log/20210421.html",
    "relUrl": "/docs/daily-learning-log/20210421.html"
  },"88": {
    "doc": "2021-04-21",
    "title": " window에서 원격 연결로 docker 사용해보기 ",
    "content": "window powershell 관리자권한 실행 ```sh choco install docker-cli ``` docker 엔진에서 ```sh systemctl status docker sudo vi /etc/systemd/systme/multi-user.target.wants/docker.service # 13번째 줄 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock -H tcp://0.0.0.0:2375 sudo systemctl daemon-reload sudo systemctl restart docker systemctl status docker -l ``` window powershell 관리자권한에서 ```sh docker -H tcp://192.168.200.10:2375 ps setx DOCKER_HOST \"tcp://192.168.200.10:2375\" docker ps # docker 엔진과 똑같이 사용 가능 ``` ",
    "url": "/docs/daily-learning-log/20210421.html",
    "relUrl": "/docs/daily-learning-log/20210421.html"
  },"89": {
    "doc": "2021-04-21",
    "title": " Mac에서 원격 연결로 docker 사용해보기 ",
    "content": "``` wget https://download.docker.com/mac/static/stable/x86_64/docker-20.10.6.tgz tar xf docker-20.10.6.tgz sudo cp docker/docker /usr/local/bin ``` ",
    "url": "/docs/daily-learning-log/20210421.html",
    "relUrl": "/docs/daily-learning-log/20210421.html"
  },"90": {
    "doc": "2021-04-21",
    "title": " Docker compose ",
    "content": "docker compose 설치 . https://docs.docker.com/compose/install/#install-compose-on-linux-systems 위의 링크에 접속하면 각 os에 따른 설치 방법 확인 가능 아래는 window 환경에서 설치 방법 ```sh sudo curl -L \"https://github.com/docker/compose/releases/download/1.29.1/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose ``` docker compose 사용해서 wordpress 올려보기 . ```sh mkdir wp-compose cd wp-compose vi docker-compose.yml version: '3.1' services: wordpress: image: wordpress restart: always ports: - 8080:80 environment: WORDPRESS_DB_HOST: db WORDPRESS_DB_USER: wpadmin WORDPRESS_DB_PASSWORD: qwer1234 WORDPRESS_DB_NAME: wp volumes: - wordpress:/var/www/html networks: - wp-net db: image: mysql:5.7 restart: always environment: MYSQL_DATABASE: wp MYSQL_USER: wpadmin MYSQL_PASSWORD: qwer1234 MYSQL_ROOT_PASSWORD: qwer1234 volumes: - db:/var/lib/mysql networks: - wp-net volumes: wordpress: db: networks: wp-net: docker-compose up -d docker-compose ls docker ps docker volume ls docker network ls docker-compose down ``` 크롬 시크릿모드에서 http://192.168.200.10:8080 vi 편집기에 복붙 예쁘게 하려면 :set paste docker-compose.yml의 각 의미 ```yaml version: '3.1' services: # docker run wordpress: image: wordpress restart: always ports: # -p - 80:80 environment: # -e WORDPRESS_DB_HOST: db WORDPRESS_DB_USER: wpadmin WORDPRESS_DB_PASSWORD: qwer1234 WORDPRESS_DB_NAME: wp volumes: # -v - wordpress:/var/www/html networks: # --network - wp-net db: image: mysql:5.7 restart: always environment: MYSQL_DATABASE: wp MYSQL_USER: wpadmin MYSQL_PASSWORD: qwer1234 MYSQL_ROOT_PASSWORD: qwer1234 volumes: - db:/var/lib/mysql networks: - wp-net volumes: # docker volume create wordpress: # docker volume create wordpress db: # docker volume create db networks: # docker network create wp-net: # docker network create wp-net ``` Docker compose scaling . docker-compose up -d 상태에서 ``` docker-compose scale =10 ``` ",
    "url": "/docs/daily-learning-log/20210421.html",
    "relUrl": "/docs/daily-learning-log/20210421.html"
  },"91": {
    "doc": "2021-04-21",
    "title": "2021-04-21",
    "content": " ",
    "url": "/docs/daily-learning-log/20210421.html",
    "relUrl": "/docs/daily-learning-log/20210421.html"
  },"92": {
    "doc": "2021-04-22",
    "title": "Docker ",
    "content": " ",
    "url": "/docs/daily-learning-log/20210422.html",
    "relUrl": "/docs/daily-learning-log/20210422.html"
  },"93": {
    "doc": "2021-04-22",
    "title": "Docker registry",
    "content": "docker image 저장소 - Public Registry : 누구나 pull, 인증받은 사용자 push - Private Registry : 인증받은 사용자 pull/push docker hub 구독 여부에 따라 횟수가 다름 Docker local registry에 push하는 image name . ```sh localhost:5000/:Docker hub에 push하는 image name . ```sh docker.io//: # docker.io는 생략 가능 ``` github에 push하는 image name . ```sh github.io//: ``` google cloud registry에 push하는 image name . ```sh k8s.gcr.io/: ``` Amazon ECR . ```sh .dkr.ecr..amazonaws.com/: ``` Docker local registry에 이미지 올리기 . ```sh docker tag 이미지 localhost:5000/이미지:태그 docker push localhost:5000/이미지:태그 docker pull localhost:5000/이미지:태그 ``` Repository image 확인 . ```sh curl localhost:5000/v2/_catalog ``` 태그 목록 확인 ```sh curl localhost:5000/v2//tags/list ``` ",
    "url": "/docs/daily-learning-log/20210422.html",
    "relUrl": "/docs/daily-learning-log/20210422.html"
  },"94": {
    "doc": "2021-04-22",
    "title": "Harbor",
    "content": "Harbor 설치 . https://goharbor.io/ >> 버전 약어 중 rc = Release Candidate (배포 후보) harbor offline은 다운로드 파일에 component image들이 이미 포함된 것 ```sh mkdir harbor cd harbor wget https://github.com/goharbor/harbor/releases/download/v2.2.1/harbor-online-installer-v2.2.1.tgz tar xf harbor-online-installer-v2.2.1.tgz cd habor/ cp harbor.yml.tmpl harbor.yml vi harbor.yml hostname을 도커엔진 IP로 변경, https관련 내용들은 주석처리 # Configuration file of Harbor # The IP address or hostname to access admin UI and registry service. # DO NOT use localhost or 127.0.0.1, because Harbor needs to be accessed by external clients. hostname: 192.168.200.10 # http related config http: # port for http, default is 80. If https enabled, this port will redirect to https port port: 80 # https related config #https: # https port for harbor, default is 443 #port: 443 # The path of cert and key files for nginx #certificate: /your/certificate/path #private_key: /your/private/key/path docker info #Server 맨 아래쪽에 Insecure Registries #docker engine이랑 docker registry는 http로 통신함 #80포트로 통신을 한다는 뜻 # sudo vi /etc/docker/daemon.json { \"insecure-registries\" : [\"192.168.200.10\"] } sudo systemctl restart docker sudo ./install.sh #/harbor/harbor에서 해야 함 sudo docker-compose ps ``` 크롬 시크릿모드에서 http://192.168.200.10 ID:admin PW : Harbor12345 ``` docker login -u admin -p Harbor12345 192.168.200.10 docker tag ubuntu 192.168.200.10/library/ubuntu docker push 192.168.200.10/library/ubuntu #harbor에 미리 생성되어 있던 library라는 repository에 ubuntu 이미지를 올림 ``` 새로 올린 이미지를 크롬에서 확인(pull command복사버튼)하면 ```sh 192.168.200.10/library/ubuntu:latest #위는 태그명으로 표현한 것이고, 아래는 해쉬로 표시한 것 192.168.200.10/library/ubuntu@sha256:5403064f94b617f7975a19ba4d1a1299fd584397f6ee4393d0e16744ed11aab1 #일반적으로 이미지 가져오고 할 때, 제대로 잘 가져왔는지 해쉬값을 비교해서 확인함 ``` ",
    "url": "/docs/daily-learning-log/20210422.html",
    "relUrl": "/docs/daily-learning-log/20210422.html"
  },"95": {
    "doc": "2021-04-22",
    "title": "Kubernetes ",
    "content": "- 개발/테스트 용 - Docker for Desktop - Minikube - 프로덕션 : 설치형 - kops : EC2에 설치 - kubeadm - kubespray - 프로덕션 : 관리형 - EKS : 비용 발생 - AKS - GKE ",
    "url": "/docs/daily-learning-log/20210422.html",
    "relUrl": "/docs/daily-learning-log/20210422.html"
  },"96": {
    "doc": "2021-04-22",
    "title": "시스템의 역할",
    "content": "참조 https://kubernetes.io/ko/docs/concepts/overview/components/ Coltrol Plane, node 모두 각각의 시스템 (물리적 혹은 인스턴스) - Control plane : 쿠버네티스 클러스터 전체를 제어하는 노드 : 구) Master Node - Control plane은 꼭 3개 이상의 cluster로 제공되어야 함(복제 필수) - Control plane의 etcd : 상태정보를 비롯한 모든 정보들을 저장 - Node : 컨테이너를 제공 : 구) minions, worker node - node의 kubelet : 컨테이너 제공 - node의 k-proxy : 컨테이너의 네트워크 제공 우리가 구성한 VM은 Control plane이자 node 둘 다 기능을 하게끔 구성할 예정 쿠버네티스의 pod가 도커의 컨테이너랑 비슷한 개념 ",
    "url": "/docs/daily-learning-log/20210422.html",
    "relUrl": "/docs/daily-learning-log/20210422.html"
  },"97": {
    "doc": "2021-04-22",
    "title": "kubeadm으로 Kubernetes 설치",
    "content": "참조 https://kubernetes.io/ko/docs/setup/production-environment/tools/kubeadm/install-kubeadm/ ```sh sudo apt-get update sudo apt-get install -y apt-transport-https ca-cerificates curl sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg echo \"deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main\" | sudo tee /etc/apt/sources.list.d/kubernetes.list sudo apt-get update sudo apt-get install -y kubelet=1.19.10-00 kubeadm=1.19.10-00 kubectl=1.19.10-00 sudo apt-mark hold kubelet kubeadm kubectl sudo kubeadm init --apiserver-advertise-address=192.168.200.10 --pod-network-cidr=192.168.0.0/16 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config kubeadm join 192.168.200.10:6443 --token lgjg8u.64ge20rbkubeadm join 192.168.200.10:6443 --token izgpsf.36wn2ba5urxz0dq2 --discovery-token-ca-cert-hash sha256:dff4a90db8a9952d0a57dfe1c818a6435efed4c5b275f9214f912cb4667e5006 kubectl create -f https://docs.projectcalico.org/manifests/tigera-operator.yaml kubectl create -f https://docs.projectcalico.org/manifests/custom-resources.yaml kubectl get nodes kubectl get pods -A ``` 추천 책 : 쿠버네티스 인 액션 (어려움!!!) ",
    "url": "/docs/daily-learning-log/20210422.html",
    "relUrl": "/docs/daily-learning-log/20210422.html"
  },"98": {
    "doc": "2021-04-22",
    "title": "공부방법에 대하여",
    "content": "네트워크에서 중요한 것 routed protocol : 순수한 네트워크 통신 : 매우 중요 Ethernet, IP, ARP/RARP, ICMP, TCP, UDP, SCTP, HTTP, FTP, SSH, DNS, DHCP, SSL routing protocol : 네트워크 장비에 대한 것 라우터 : RIP, EIGRP, OSPF, BGP, IS-IS 스위치 : STP, VLAN 책 : 마스터링 TCP/IP ",
    "url": "/docs/daily-learning-log/20210422.html",
    "relUrl": "/docs/daily-learning-log/20210422.html"
  },"99": {
    "doc": "2021-04-22",
    "title": "2021-04-22",
    "content": " ",
    "url": "/docs/daily-learning-log/20210422.html",
    "relUrl": "/docs/daily-learning-log/20210422.html"
  },"100": {
    "doc": "2021-04-23",
    "title": "Kubernetes",
    "content": " ",
    "url": "/docs/daily-learning-log/20210423.html",
    "relUrl": "/docs/daily-learning-log/20210423.html"
  },"101": {
    "doc": "2021-04-23",
    "title": "Vagrantfile로 kubenetes환경 구성하기",
    "content": "- Kubelet, Kubeadm, Kubectl 버전 : 나중에 AWS의 EKS 사용할 건데, EKS의 쿠베 버전기본값인 1.18.18로 설치 windowpowershell에서 ```sh mkdir kubernetes cd kubernetes vagrant init vi Vagrantfile ``` ```sh # -*- mode: ruby -*- # vi: set ft=ruby : Vagrant.configure(\"2\") do |config| config.vm.define \"kube-master1\" do |ubuntu| ubuntu.vm.box = \"ubuntu/focal64\" ubuntu.vm.hostname = \"kube-master1\" ubuntu.vm.network \"private_network\", ip: \"192.168.200.11\" ubuntu.vm.provider \"virtualbox\" do |vb| vb.name = \"kube-master1\" vb.cpus = 2 vb.memory = 2048 end end config.vm.define \"kube-node1\" do |ubuntu| ubuntu.vm.box = \"ubuntu/focal64\" ubuntu.vm.hostname = \"kube-node1\" ubuntu.vm.network \"private_network\", ip: \"192.168.200.21\" ubuntu.vm.provider \"virtualbox\" do |vb| vb.name = \"kube-node1\" vb.cpus = 2 vb.memory = 2048 end end config.vm.define \"kube-node2\" do |ubuntu| ubuntu.vm.box = \"ubuntu/focal64\" ubuntu.vm.hostname = \"kube-node2\" ubuntu.vm.network \"private_network\", ip: \"192.168.200.22\" ubuntu.vm.provider \"virtualbox\" do |vb| vb.name = \"kube-node2\" vb.cpus = 2 vb.memory = 2048 end end config.vm.define \"kube-node3\" do |ubuntu| ubuntu.vm.box = \"ubuntu/focal64\" ubuntu.vm.hostname = \"kube-node3\" ubuntu.vm.network \"private_network\", ip: \"192.168.200.23\" ubuntu.vm.provider \"virtualbox\" do |vb| vb.name = \"kube-node3\" vb.cpus = 2 vb.memory = 2048 end end config.vm.provision \"shell\", inline: /dev/null sudo apt update sudo apt install -y docker-ce docker-ce-cli containerd.io sudo usermod -aG docker vagrant # Install Kubelet, Kubeadm, Kubectl sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg echo \"deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main\" \\ | sudo tee /etc/apt/sources.list.d/kubernetes.list sudo apt update sudo apt install -y kubelet=1.18.18-00 kubeadm=1.18.18-00 kubectl=1.18.18-00 sudo apt-mark hold kubelet kubeadm kubectl SHELL end ``` ```sh vagrant up #만약 kube-node3 구성 중에 에러가 났다면? vagrant destroy -f kube-node3 vagrant up kube-node3 vagrant ssh kube-master1 kubeadm version ip a s #node1 접속 ssh vagrant@192.168.200.21 yes password : vagrant exit #설치 계속 sudo kubeadm init --apiserver-advertise-address=192.168.200.11 --pod-network-cidr=192.168.0.0/16 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config #컨테이너 네트워크 애드온 설치 kubectl create -f https://docs.projectcalico.org/manifests/tigera-operator.yaml kubectl create -f https://docs.projectcalico.org/manifests/custom-resources.yaml #설치확인 kubectl get nodes kubectl get pods -A watch -n1 -d kubectl get pods -A # ready 될 때까지 기다림 #node에서 kubeadm join : node는 이것만 하면 됨!!!!!! ssh vagrant@192.168.200.21~23 sudo kubeadm join 192.168.200.11:6443 --token 5unqe6.eml8ncxxu6fyxsno \\ --discovery-token-ca-cert-hash sha256:0cc33936db2862ecf2a4826f6f5923537b7cb13e9b675f60cbebd9fd7c2d0fde #kubeadm join할 token, hash 확인 (kubeadm init했을 때 join명령어 복사 안했을 때) kubeadm token list kubectl cluster-info openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | \\ openssl dgst -sha256 -hex | sed 's/^.* //' ``` 컨테이너 생성해보기 ```sh kubectl run web1 --image=httpd #컨테이너가 생성되는것, 이 컨테이너에 대한 yaml파일이 생성됨 kubectl get pod web1 -o yaml #yaml파일 확인 kubectl get pods #생성된 컨테이너 확인 (Pod 속성이 컨테이너임) ``` 쿠버네티스 리소스는 YAML 파일 형태로 정의, 기본 구성은 아래와 같음 ```yaml apiVersion: kind: metadata: name: spec: status : #이 부분은 read-only ``` kube에서 쓰는 api resources 목록 확인 ```sh kubectl api-resources #여기서 보면, 위 yaml에 표기되어있던 kind:Pod는 api group이 없는 resource : 코어 그룹이기 때문 kubectl api-versions #group/version으로 표시됨 #제일 밑에 v1으로만 나와있는거 (그룹이 없는거) : 코어 그룹의 버전임 ``` 원하는 resoure의 version 검색하기 (KIND로 검색) ```sh kubectl api-resources | grep ReplicaSet #3번째 항목인 그룹 확인 (ReplicaSet은 apps그룹) kubectl api-versions | grep ^apps kubectl api-resources | grep Service #그룹이 없는 경우는 코어그룹이므로 kubectl api-versions | tail -1 kubectl api-resources | grep Ingress #그룹이 extensions와 networking.k8s.io 두 개로 나오는데, 지금은 extension안씀 kubectl api-versions | grep ^extensions kubectl api-versions | grep ^networking.k8s.io #버전이 v1, v1beta1 이렇게 두 개로 나오는데 더 최신은 v1 ``` 특정 KIND 정보 검색하기 ```sh kubectl explain pod kubectl explain pod #이름 미완성이어도 검색됨 kubectl explain replicasets kubectl explain pods.kind #정보 중 특정 항목만 검색가능 kubectl explain pods.metadata kubectl explain pods.metadata.name kubectl explain pods.spec #참고로 pod는 spec에 containers가 꼭 정의되어야 함 #containers -required- #[]는 리스트를 의미, 즉 컨테이너가 여러 대 정의될 수 있음 kubectl explain pods.spec.containers kubectl explain pods.spec.containers --recursive #recursive 옵션으로 개요를 볼 수 있음 ``` yaml파일 작성해서 컨테이너 생성해보기 ```sh vi web2-pod.yaml apiVersion: v1 kind: Pod metadata: name: web2 spec: containers: - name: web2 image: httpd kubectl create -f web2-pod.yaml kubectl get pods kubectl delete -f web2-pod.yaml kubectl get pods vi web3-pod.yaml apiVersion: v1 kind: Pod metadata: name: web3 spec: containers: - name: web3a image: httpd - name: web3b image: c1t1d0s7/myweb #port가 겹치는 것을 하면 에러 남!!!!! kubectl create -f web3-pod.yaml kubectl get pods kubectl delete -f web3-pod.yaml ``` vi edit setting ```sh vi ~/.vimrc syntax on autocmd FileType yaml setlocal ts=2 sts=2 sw=2 expandtab autoindent ``` API Version . - Stable - Beta - 잘 테스트 됨 / 검증됨 (오류가 적은 편) - 미리 고지 후 기능 변경이 있을 수 있으며, 방법이나 대응을 알려줌 - Mission Critical - Mission Critical이라는 것은 down time이 발생할 수 있음 - Alpha - 개발 중, 오류가 있을 수 있음, 기능 X (기본 비활성) - 기능 변경이 갑작스럽게 있을 수 있음 Alpha -> Beta -> Stable ",
    "url": "/docs/daily-learning-log/20210423.html",
    "relUrl": "/docs/daily-learning-log/20210423.html"
  },"102": {
    "doc": "2021-04-23",
    "title": "2021-04-23",
    "content": " ",
    "url": "/docs/daily-learning-log/20210423.html",
    "relUrl": "/docs/daily-learning-log/20210423.html"
  },"103": {
    "doc": "2021-04-26",
    "title": "Kubernetes",
    "content": " ",
    "url": "/docs/daily-learning-log/20210426.html",
    "relUrl": "/docs/daily-learning-log/20210426.html"
  },"104": {
    "doc": "2021-04-26",
    "title": "kuberspray로 kubernetes 환경 설정하기",
    "content": "참고 주소 https://github.com/kubernetes-sigs/kubespray https://kubernetes.io/ko/docs/setup/production-environment/tools/kubespray/ ```sh #kubespray pull git clone --branch release-2.14 https://github.com/kubernetes-sigs/kubespray.git cd kubespray #install requirements sudo apt install python3-pip sudo pip3 install -r requirements.txt #ssh key ssh-keygen # keygen 암호 입력 때 그냥 엔터 쳐야 암호 없이 접근 가능 ssh-copy-id vagrant@192.168.201.11 # 암호를 입력하라고 뜰 때, vagrant 기본 설정인 vagrant 입력 ssh-copy-id vagrant@192.168.201.21 ssh-copy-id vagrant@192.168.201.22 ssh-copy-id vagrant@192.168.201.23 # inventory cp -r inventory/sample inventory/mycluster vi inventory/mycluster/inventory.ini [all] k8s-m1 ansible_host=192.168.201.11 ip=192.168.201.11 ansible_connection=local k8s-w1 ansible_host=192.168.201.21 ip=192.168.201.21 k8s-w2 ansible_host=192.168.201.22 ip=192.168.201.22 k8s-w3 ansible_host=192.168.201.23 ip=192.168.201.23 [kube-master] k8s-m1 [etcd] k8s-m1 [kube-node] k8s-w1 k8s-w2 k8s-w3 [calico-rr] [k8s-cluster:children] kube-master kube-node calico-rr # inventory graph로 확인 ansible-inventory -i inventory/mycluster/inventory.ini --graph # 통신 확인 ansible all -i inventory/mycluster/inventory.ini -m ping # playbook ansible-playbook -i inventory/mycluster/inventory.ini cl uster.yml -b # 쿠버네티스 배포/플레이북 실행 # kubeconfig 파일 복사 mkdir $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config #### kubectl 자동완성 기능 kubectl completion bash | sudo tee /etc/bash_completion.d/kubectl exec bash ``` pod의 구조 . - pod 기본 정보 - Pod : workload를 제어할 수 있는 가장 작은 단위 - Pod를 Replica로 복제(pod 자체가 복제되는 것, 안에 container2개 있었으면 똑같이 2개로) - 안에 있는 container를 제어할 수 있는 것은 아님 - pod 안의 containers는 같은 네트워크를 제공받는다. volume도 마찬가지 - container마다 이미지는 다를 수 있지 - pod 안에 web과 db를 같이 놓는 경우 - anti pattern임 : 실행될 지 몰라도, 하면 안되는 구조 - 같은 네트워크와 volume을 공유하기 때문에 격리가 안됨 - 이런 경우를 하나의 pod에 2개의 main application이 들어갔다고 함 - pod는 main app과 side car(보조)로 구성해야 옳다 - ex. web, puller : puller가 다른데서 정보를 가져와서 공유 volume에 저장하는 역할을 하고 web이 그 정보를 가져다 쓴다 - ex. web, log : log는 web에서 발생한 log를 따로 다른 곳에 저장하는 역할을 함 ",
    "url": "/docs/daily-learning-log/20210426.html",
    "relUrl": "/docs/daily-learning-log/20210426.html"
  },"105": {
    "doc": "2021-04-26",
    "title": "pod 실습",
    "content": "```sh mkdir pod vi pod.yaml apiVersion: v1 kind: Pod metadata: name: myapp-pod spec: containers: - name: myapp image: ghcr.io/c1t1d0s7/go-myweb ports: - containerPort: 8080 protocol: TCP kubectl create -f pod.yaml kubectl explain pod.spec ``` Labels . 참고 주소 https://kubernetes.io/ko/docs/concepts/overview/working-with-objects/labels/ - metadata에 선언 - 기능 - 검색 - 리소스 간 연결 ```sh vi pod.yaml apiVersion: v1 kind: Pod metadata: name: myapp-pod labels: app: myapp env: development spec: containers: - name: myapp image: ghcr.io/c1t1d0s7/go-myweb ports: - containerPort: 8080 protocol: TCP ``` ```sh kubectl run web2 --image httpd kubectl get pods --show-labels # run으로 pod 생성하면 기본 label로 rum=이 붙음 # 반면, yaml로 생성했을 시 yaml에 label 내용이 없으면 label이 kubectl label pod web2 app=myapp --overwrite # overwrite 옵션이 있어야 원래 있던 값에 덮어 씌우기 가능 kubectl label pod web2 app='' --overwrite # 빈 값으로 대체 kubectl label pod web2 app- # 해당 키 삭제 ``` label 셀렉터 . label을 기준으로 조건에 해당하는 pod를 검색할 수 있음 - 일치성 - Key =Value - Key == Value - Key != Value - 집합성 - Key in (Value) - Key notin (Value) - Key - !Key ```sh kubectl get pods -l 'app=myapp' # app=myapp인 것 찾기 kubectl get pods -l 'app in (myapp)' # app의 value가 (myapp)집합에 속하는 것 찾기 kubectl get pods -l 'env in (development)' # env의 value가 (development)집합에 속하는 것 찾기 kubectl get pods -l 'env in (development,production)' # env의 value가 (development, production)집합에 속하는 것 찾기 kubectl get pods -l 'env' # 키 값에 env가 있는 것 찾기 kubectl get pods -l '!env' # 키 값에 env가 없는 것 찾기 ``` annotation . 참고 주소 https://kubernetes.io/ko/docs/concepts/overview/working-with-objects/annotations/ - metadata에 선언 - 책에서는 주석이라고 표현하지만 #주석이랑은 좀 다름 - 검색 용도도 아니고, 리소스 연결을 위한 것도 아님 - 구성 자체는 label과 같다 - label이 식별의 의미라면, annotation은 단순 정보 - API 또는 라이브러리를 통해 해당 값을 참조할 수 있다 ```sh kubectl annotate pod web2 header=jang --overwrite # annotation 수정 kubectl describe pod web2 | head # annotation 확인 kubectl annotate pod web1 header- # annotation 삭제 vi pod.yaml apiVersion: v1 kind: Pod metadata: name: myapp-pod labels: app: myapp env: development annotations: header: jang spec: containers: - name: myapp image: ghcr.io/c1t1d0s7/go-myweb ports: - containerPort: 8080 protocol: TCP kubectl create -f pod.yaml kubectl describe po myapp-pod | head ``` Namespace . 참고 주소 https://kubernetes.io/ko/docs/concepts/overview/working-with-objects/namespaces/ ```sh kubectl get namespaces kubectl get ns kubectl get pods kubectl get pods -n default kubectl run web1 --image httpd --namespace kube-system kubectl get po -n kube-system kubectl delete pod web1 -n kube-system vi pod.yaml apiVersion: v1 kind: Pod metadata: name: myapp-pod namespace: kube-system labels: app: myapp env: development annotations: header: jang spec: containers: - name: myapp image: ghcr.io/c1t1d0s7/go-myweb ports: - containerPort: 8080 protocol: TCP # yaml에 namgespace 지정하면 알아서 해당 ns에 생성, 제거됨 kubectl create namespace quality-assurance kubectl get ns kubectl delete namespace quality-assurance # ns에 resource가 남아있는 경우 지워지지 않음 vi ns.yaml apiVersion: v1 kind: Namespace metadata: name: quality-assurance kubectl create -f ns.yaml kubectl get ns kubectl delete -f ns.yaml ``` ",
    "url": "/docs/daily-learning-log/20210426.html",
    "relUrl": "/docs/daily-learning-log/20210426.html"
  },"106": {
    "doc": "2021-04-26",
    "title": "Pod life cycle",
    "content": "참고 주소 https://kubernetes.io/ko/docs/concepts/workloads/pods/pod-lifecycle/ - pod 단계 - Pending - Running - Succeeded - Failed - Unknown - Terminating - 컨테이너 상태 - Waiting - Running - Terminated ",
    "url": "/docs/daily-learning-log/20210426.html",
    "relUrl": "/docs/daily-learning-log/20210426.html"
  },"107": {
    "doc": "2021-04-26",
    "title": "Replication Controller",
    "content": "참고 주소 https://kubernetes.io/ko/docs/concepts/workloads/controllers/replicationcontroller/ - 줄여서 RC - 파드 제어 컨트롤러 중 하나 - 디플로이먼트 - 레플리카셋 - 스테이트풀셋 - 데몬셋 - 잡 - 크론잡 - 레플리케이션 컨트롤러 << - etc(지금 중요한 것은 아니라 뺌) - 지정된 수의 파드 레플리카 실행을 보장 - 최초의 쿠버네티스 컨트롤러이지만, 레플리카셋으로 대체되면서 사용이 줄었음 - rc의 .spec.template에는 metadata와 spec밖에 없음 : 어차피 apiVersion, kind는 v1, pod로 정해져있기 때문 - 복제해서 사용할 pod의 spec이 .spec.template.spec에 들어가는 것 ",
    "url": "/docs/daily-learning-log/20210426.html",
    "relUrl": "/docs/daily-learning-log/20210426.html"
  },"108": {
    "doc": "2021-04-26",
    "title": "중요!!!!!!!!!!!!!!!!!!!!",
    "content": "- template에 들어가는 label이 pod에 들어갈 label이고, 따라서 rc의 selector는 자동으로 그 label과 같은 것이 들어가야함 : selector가 자신이 제어할 label을 지정하는 것이기 때문 - rc의 label과 pod의 label은 다른 것 - label을 기준으로 관리하기 때문에, 원래 관리하던 pod의 label이 바뀌면 하나를 더 생성 : 관리하고 있는 숫자에서 하나가 빠졌다고 생각하기 때문 - 마찬가지로, 관리하고 있는 pod label을 가지고 있는 수가 desire보다 크면 삭제시킴 ```sh apiVersion: v1 kind: ReplicationController metadata: name: nginx labels: app: nginx spec: replicas: 3 selector: app: nginx template: metadata: name: nginx labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 ``` ",
    "url": "/docs/daily-learning-log/20210426.html",
    "relUrl": "/docs/daily-learning-log/20210426.html"
  },"109": {
    "doc": "2021-04-26",
    "title": "2021-04-26",
    "content": " ",
    "url": "/docs/daily-learning-log/20210426.html",
    "relUrl": "/docs/daily-learning-log/20210426.html"
  },"110": {
    "doc": "2021-04-27",
    "title": "Kubernetes",
    "content": " ",
    "url": "/docs/daily-learning-log/20210427.html",
    "relUrl": "/docs/daily-learning-log/20210427.html"
  },"111": {
    "doc": "2021-04-27",
    "title": "Kubernetes object 관리",
    "content": "- Imperative: 절차, 명령형 - kubectl create - kubectl delete - kubectl run - kubectl edit - kubectl replace - kubectl patch rs myapp-rs1 -p '{\"spec\": {\"replicas\":1}}' - Declarative: 선언형 - kubectl apply ",
    "url": "/docs/daily-learning-log/20210427.html",
    "relUrl": "/docs/daily-learning-log/20210427.html"
  },"112": {
    "doc": "2021-04-27",
    "title": "Kubernetes Controller",
    "content": "ReplicationController . - 어제 배움 ```sh apiVersion: v1 kind: ReplicationControllers metadata: name: myweb-rc labels: app: myweb spec: replicas: 3 selector: app: myweb tier: frontend template: metadata: labels: app: myweb tier: frontend team: devops spec: containers: - name: myweb image: ghcr.io/c1t1d0s7/go-myweb ``` ReplicaSet . - spec.selector.matchLabels : 일치성 관련 선언 (key=value로 선언) - spec.selector.matchExpressions : 집합성 관련 선언 - key : 키 - operator : in, Notin, Exists, DoesNotExist - values : 값 - Exists, DoesNotExist일 때에는 비어야함 (그 두개는 key를 매칭하는 표현) ```sh apiVersion: apps/v1 kind: ReplicaSet metadata: name: myweb-rs labels: app: myweb spec: replicas: 3 selector: matchLabels: app: myweb template: metadata: labels: app: myweb spec: containers: - name: myweb image: ghcr.io/c1t1d0s7/go-myweb ``` ```sh apiVersion: apps/v1 kind: ReplicaSet metadata: name: myapp-rs2 labels: app: myapp spec: replicas: 2 selector: matchExpressions: - key: app operator: In values: - myapp template: metadata: labels: app: myapp spec: containers: - name: myapp image: ghcr.io/c1t1d0s7/go-myweb ports: - containerPort: 8080 protocol: TCP ``` DaemonSet . 각 노드마다 파드를 하나씩 배치 ```sh apiVersion: apps/v1 kind: DaemonSet metadata: name: myweb-ds labels: app: myweb spec: selector: matchLabels: app: myweb template: metadata: labels: app: myweb spec: containers: - name: myweb image: ghcr.io/c1t1d0s7/go-myweb ports: - containerPort: 8080 ``` 일부 노드에만 배치 ```sh kubectl expain ds..spec.template.spec.nodeSelector ``` ```sh apiVersion: apps/v1 kind: DaemonSet metadata: name: myweb-ds labels: app: myweb spec: selector: matchLabels: app: myweb template: metadata: labels: app: myweb spec: nodeSelector: test: worker containers: - name: myweb image: ghcr.io/c1t1d0s7/go-myweb ports: - containerPort: 8080 ``` Jobs . ```sh kubectl explain job.spec.template.spec.restartPolicy #컨테이너의 재시작 정책 # Always (기본값) - Job 리소스에서는 허용되지 않음 # OnFailure # Never ``` ```sh apiVersion: batch/v1 kind: Job metadata: name: myweb-job spec: completions: 4 parallelism: 2 template: spec: restartPolicy: OnFailure containers: - name: sixty image: busybox command: [\"sleep\", \"20\"] ``` CronJob . ```sh kubectl explain cj.spec.successfulJobsHistoryLimit # 성공한 작업(파드) 히스토리 개수(default 3) kubectl explain cj.spec.failedJobsHistoryLimit # 실패한 작업(파드) 히스토리 개수(default 1) ``` ```sh apiVersion: batch/v1beta1 kind: CronJob metadata: name: myapp-cj spec: jobTemplate: spec: template: spec: restartPolicy: OnFailure containers: - name: sixty image: busybox command: [\"sleep\",\"20\"] schedule: \"* * * * *\" ``` Service . ```sh apiVersion: v1 kind: Service metadata: name: myapp-svc spec: selector: app: myapp ports: - protocol: TCP port: 80 # 서비스 포트 targetPort: 8080 # Pod의 노출 포트 ``` ```sh kubectl run test -it --image ghcr.io/c1t1d0s7/network-multitool --rm host myapp-svc.default.svc.cluster.local host myapp-svc.default.svc host myapp-svc.default host myapp-svc ``` FQDN . 형식 : ... - RESOURCE_TYPE: svc - DOMAIN: cluster.local DB는 stateless이기 때문에 RC, RS, DS, job, CJ으로 생성하면 안됨 ",
    "url": "/docs/daily-learning-log/20210427.html",
    "relUrl": "/docs/daily-learning-log/20210427.html"
  },"113": {
    "doc": "2021-04-27",
    "title": "2021-04-27",
    "content": " ",
    "url": "/docs/daily-learning-log/20210427.html",
    "relUrl": "/docs/daily-learning-log/20210427.html"
  },"114": {
    "doc": "2021-04-28",
    "title": "Kubernetes",
    "content": " ",
    "url": "/docs/daily-learning-log/20210428.html",
    "relUrl": "/docs/daily-learning-log/20210428.html"
  },"115": {
    "doc": "2021-04-28",
    "title": "Service",
    "content": "프록시, 로드밸런서 - ClusterIP: 쿠버네티스 클러스터 내부 내부 - NodePort: 쿠버네티스 클러스터 외부 노출 -> 내부 - LoadBalancer: 쿠버네티스 클러스터 외부 노출 -> 내부 - ExternalName: 쿠버네티스 클러스터 내부 -> 외부 service create 후 시험시 사용하는 테스트 image ```sh kubectl run test -it --image ghcr.io/c1t1d0s7/network-multitool --rm curl ``` ClusterIP . - service를 통해 특정 label을 가진 pod 세트를 원하는 포트로 노출 - 쿠버네티스는 이 서비스에 ClusterIP를 할당 - .spec.clusterIP field로 고유한 clusterIP를 설정할 수도 있다. ```sh apiVersion: v1 kind: Service metadata: name: myapp-svc spec: selector: app: myapp ports: - protocol: TCP port: 80 # 서비스 포트 targetPort: 8080 # Pod의 노출 포트 ``` 멀티포트 . - 하나의 서비스로 둘 이상의 포트를 노출할 때 사용 ```sh apiVersion: v1 kind: Service metadata: name: myapp-svc spec: selector: app: myapp ports: - name: http protocol: TCP port: 80 targetPort: 8080 - name: https protocol: TCP port: 443 targetPort: 8443 ``` 세션 어피니티(Session Affinity) . 클라이언트의 세션을 고정함 ```sh apiVersion: v1 kind: Service metadata: name: myapp-svc-ses spec: sessionAffinity: ClientIP selector: app: myapp ports: - protocol: TCP port: 80 targetPort: 8080 ``` ```sh vi /etc/resolv.conf nameserver 169.254.25.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5 ``` nameserver: DNS 서버 - 169.254.25.10 -> (nodelocaldns : DNS Cache Server) - Client -> nodelocaldns -> coredns - nodelocaldns 구성이 없으면 kube-system에 coredns 서비스의 IP 설정 Headless Service . - selector를 정의하는 경우 : endpoint record가 생성되고 DNS 구성을 수정하여 pod의 IP 리턴 - selector를 정의하지 않는 경우 : endpoint record가 생성되지 않고 DNS는 다음 중 하나를 구성 - ExternalName 서비스에 대한 CNAME record - 서비스의 이름을 공유하는 모든 endpoint record ```sh apiVersion: v1 kind: Service metadata: name: myapp-svc-headless spec: clusterIP: None selector: app: myapp ports: - protocol: TCP port: 80 targetPort: 8080 ``` ```sh kubectl run test -it --image ghcr.io/c1t1d0s7/network-multitool --rm host myapp-svc-headless myapp-svc-headless.default.svc.cluster.local has address 10.233.84.68 myapp-svc-headless.default.svc.cluster.local has address 10.233.120.26 myapp-svc-headless.default.svc.cluster.local has address 10.233.94.45 ``` StatefulSet 컨트롤러 + Headless Service 같이 사용. 파드마다 FQDN를 부여함 NodePort . - node의 특정 포트를 열어두고, 이 포트로 보내지는 트래픽을 서비스로 포워딩 - port default : 30000-32767 ClusterIP + NodePort ```sh apiVersion: v1 kind: Service metadata: name: myapp-svc-nodeport spec: type: NodePort selector: app: myapp ports: - protocol: TCP port: 80 targetPort: 8080 ``` LoadBalancer . MetalLB 구성 . 참조 주소 https://metallb.universe.tf/ MetalLB 작동 모드 - L2: L2 Ethrenet 네트워크 만 있으면 작동 (라우터 X) - BGP: 라우터 필요 ```sh # kubespray 폴더에서 vi ~/kubespray/inventory/mycluster/group_vars/k8s-cluster/addons.yml metallb_enabled: true metallb_ip_range: - \"192.168.201.200-192.168.201.220\" metallb_protocol: \"layer2\" # 수정 vi ~/kubespray/inventory/mycluster/group_vars/k8s-cluster/k8s-cluster.ym kube_proxy_strict_arp: true # 수정 ansible-playbook -i inventory/mycluster/inventory.ini cluster.yml -b # 설치 ``` ```sh kubectl get ns # 확인1 kubectl get all -n metallb-system # 확인2 # pod/controller : 로드밸런서를 pod에 구현해놓음 ``` ```sh # rs 폴더에서 kubectl create -f rs.yaml # svc 폴더에서 code svc7.yaml apiVersion: v1 kind: Service metadata: name: myapp-svc-lb spec: type: LoadBalancer selector: app: myapp ports: - protocol: TCP port: 80 targetPort: 8080 kubectl create -f svc7.yaml kubectl get all # chrome에서 192.168.201.200 192.168.201.21:31136 # 포트는 kubectl get all에서 myapp-svc-lb 포트포워딩 확인 #둘이 같은 결과가 나옴 # LB를 통해 대표 IP인 192.168.201.22가 192.168.201.21~3:31136을 바라보게 하기 때문 ``` ExternalName . - pod에 있는 app이 외부에 계속 접근을 하는 경우 바뀔 때마다 새로 빌드를 해줘야 하는 불편함 - pod(app) -> SVC(gapi) -> api.google.com/monitoring : 이런 식으로 중간에 넣는 svc ```sh apiVersion: v1 kind: Service metadata: name: gping spec: type: ExternalName externalName: www.google.com # gping.default.svc.cluster.local # --> www.google.com ``` ```sh kubectl run test -it --image ghcr.io/c1t1d0s7/network-multitool --rm host -v myapp-svc-lb # A record : ip -> name host -v gping # C record : name -> name ``` Endpoint . - 주로 서비스 생성 시 서비스이름과 똑같은 이름으로 자동 생성되지만, 직접 만들어서 사용하는 경우도 있음 - 레이블셀렉터에 의해 선택된 파드의 목록을 가지고 있음 ```sh kubectl get ep ``` Ingress . - L7 LoadBalancer - http기반의 주소를 가지고 분산시켜줌 - 들어오는 것들에 대한 정책 - 반대는 egress - 인그레스 리소스가 작동하기 위해 인그레스 컨트롤러가 필요 - 가장 일반적인 것은 NGINX 인그레스 컨트롤러 - metal lb는 m1, w1, w2, w3 모두 접속이 되지만 ingress는 m1은 안됨 ```sh # kubespray에서 code inventory/mycluster/group_vars/k8s-cluster/addons.yml ingress_nginx_enabled: true # 수정 ansible-playbook -i inventory/mycluster/inventory.ini cluster.yml -b # 설치 ``` ```sh kubectl get ns # namespace 생성 확인 kubectl get all -n ingress-nginx # ingress-nginx 확인 kubectl get all -n ingress-nginx -o wide kubectl get all -n metallb-system -o wide # 위의 두 개 비교해서 m1이 있고 없고를 확인 ``` ```sh # ing 폴더 생성해서 code ing.yaml --- apiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: name: myapp-ing spec: rules: #http://www.example.com -> myapp-svc:80 - host: www.example.com http: paths: - path: / backend: serviceName: myapp-svc servicePort: 80 ### a.exam.com ### b.exam.com # 위의 두 개는 호스트를 검사 ### c.exam.com/help ### c.exam.com/qna # 위의 두 개는 경로를 검사 --- apiVersion: v1 kind: Service metadata: name: myapp-svc spec: selector: app: myapp ports: - protocol: TCP port: 80 targetPort: 8080 --- apiVersion: apps/v1 kind: ReplicaSet metadata: name: myapp-rs labels: app: myapp spec: replicas: 2 selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - name: myapp image: ghcr.io/c1t1d0s7/go-myweb ports: - containerPort: 8080 ``` ```sh curl http://192.168.201.21 # 404 가 나옴 # path는 맞는데 host가 틀렸기 때문. ip로 적었기 때문 # ing.yaml에서 호스트를 url로 줬으니까!!! # 해결방법 1 : /etc/hosts 파일에 ip와 url을 묶어줌 sudo vi /etc/hosts 192.168.201.21 www.example.com #맨 위에 추가 # window에도 hosts파일 수정 # c:\\Windows\\System32\\drivers\\hosts # 해결방법 2 : curl option curl http://www.example.com --resolv www.example.com:80:192.168.201.21 # url을 80번 포트의 해당 ip로 바꾸는 옵션 curl http://www.example.com # 이거는 실제 사이트(외부)가 나옴 ``` deprecated . 유지보수가 중단되어, 사용이 권장되지 않는, 곧 없어질 all delete . ```sh kubectl delete all --all ``` #### 4/28 숙제 1. 다른 네임스페이스에 있는 서비스에 접근해보기 - devel 네임스페이스에 mysql 파드 (서비스 구성) - default 네임스페이스에 test 파드 (어떤 주소로 접근?) 2. Ingress 멀티 백엔드 구성 예시 ``` apiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: name: myapp-ing spec: rules: #http://www.example.com -> myapp-svc:80 - host: foo.example.com http: paths: - path: /a backend: serviceName: myapp-svc-a servicePort: 80 - path: /b backend: serviceName: myapp-svc-b servicePort: 80 - host: bar.example.com ... ``` 3. Wordpress / Mysql 구성 - Wordpress: RS - Mysql: Pod - Wordpress Service: LB, Ingress - Mysql Service: ClusterIP ",
    "url": "/docs/daily-learning-log/20210428.html",
    "relUrl": "/docs/daily-learning-log/20210428.html"
  },"116": {
    "doc": "2021-04-28",
    "title": "2021-04-28",
    "content": " ",
    "url": "/docs/daily-learning-log/20210428.html",
    "relUrl": "/docs/daily-learning-log/20210428.html"
  },"117": {
    "doc": "2021-04-29",
    "title": "Kubernetes",
    "content": "어제 과제 . 1. 다른 네임스페이스에 있는 서비스에 접근해보기 - devel 네임스페이스에 mysql 파드 (서비스 구성) - default 네임스페이스에 test 파드 (어떤 주소로 접근?) ```sh apiVersion: v1 kind: Pod metadata: name: db-pod namespace: devel labels: app: db spec: containers: - name: db image: mysql:5.7 ports: - containerPort: 3306 protocol: TCP env: - name: MYSQL_ROOT_PASSWORD value: qwer1234 --- apiVersion: v1 kind: Service metadata: name: db-svc namespace: devel spec: selector: app: db ports: - protocol: TCP port: 3306 targetPort: 3306 ``` ```sh kubectl run test --image=ghcr.io/c1t1d0s7/network-multitool --rm -it > host -v db-svc.devel > mysql -h db-svc.devel -u root -p ``` ### pod set는 항상 하나의 worknode에서 구성됨 pod가 w1, w2 따로 있을 수 없음 ",
    "url": "/docs/daily-learning-log/20210429.html",
    "relUrl": "/docs/daily-learning-log/20210429.html"
  },"118": {
    "doc": "2021-04-29",
    "title": "Volume",
    "content": "참고 주소 > https://kubernetes.io/ko/docs/concepts/storage/volumes/ - PV : Presistent Volume : 관리자용 - Volume 구축에 필요한 기본 구성요소사항 지정 - PVC : PV Claim : 개발자용 - 개발자는 네트워크, 인프라에 익숙하지 않다 - pvc 이름, pv 이름만 정의 - NFS storage - 용량은 크지만 속도에 민감하진 않음 - iSCSI - 용량은 작지만 속도가 빠름 - 구성 2 : 정적 프로비저닝 - 관리자가 pv를 만들어놓고, 개발자의 pvc 요청에 맞게 연결 pod - pvc - pv - NFS pod - pvc - pv - iSCSI - pvc를 사용하지 않게 되면, 나중에 다시 사용하기 위해서는 pvc만 만드는 것으로는 안되고, pv까지 모두 새로 만들어야 함 - 구성 3 : 동적 프로비저닝 - pv를 미리 만들어놓지 않고, 동적으로 배포한다는 의미 - SC : Storage Class : 관리가 storage에 할당해놓는 클래스 - 관리자가 SC를 만들어놓고, pvc가 SC에 요청을 하면 pv가 만들어 짐 Volume 유형 . - 로컬 볼륨 : emptyDir, gitRepo, hostPath - 네트워크 볼륨 : cephfs, cinder, fc, iscsi, nfs, rbd - 클라우드 볼륨 : awsElasticBlockStore, azureDisk, azureFile, gcePersistentDisk - 정적/동적 프로비저닝 볼륨 : pvc - 특수 유형 : configMap, secret emptyDIR . - 가장 기본적 - 빈 디스크에 데이터 저장 - container가 실행 중일 때 Container끼리 데이터를 공유하기 위해 사용 - 가장 일반적 사용 예시는 Contents manager container가 외부에서 데이터를 가져와서 저장하고, web server container가 저장된 데이터를 가져와서 사용 ```sh # vol 폴더에서 code emptydir.yaml apiVersion: v1 kind: Pod metadata: name: myapp-vol spec: containers: - image: ghcr.io/c1t1d0s7/go-myweb:alpine name: myweb volumeMounts: - mountPath: /testvol name: cache-volume - image: mysql:5.7 #원래는 이렇게 주요 앱 두개를 동시에 올리면 안되지만 테스트용 name: mydb volumeMounts: - mountPath: /testvol name: cache-volume env: - name: MYSQL_ROOT_PASSWORD value: qwer1234 volumes: - name: cache-volume emptyDir: {} ``` ```sh kubectl create -f emptydir.yaml kubectl get po kubectl exec -it myapp-vol -c myweb sh ls cd /testvol/ ls touch a b c ls exit kubectl exec -it myapp-vol -c mydb sh ls cd /testvol/ ls # a b c 가 존재 ``` gitRepo(Deprecated) . - 사용 중지됨 - emptyDIR에 git clone이 추가된 느낌 ```sh apiVersion: v1 kind: Pod metadata: name: myapp-git spec: containers: - image: ghcr.io/c1t1d0s7/go-myweb:alpine name: myweb volumeMounts: - mountPath: /kube name: kubespray volumes: - name: kubespray gitRepo: repository: https://github.com/kubernetes-sigs/kubespray.git ``` ### kubectl exec 쓸 때, container 안에서 쓸 명령어에 옵션을 kubectl은 본인의 옵션인가? 하고 생각하게 되서 error가 뜰 수 있다. 따라서, 옵션이 있는 경우에는 옵션 앞에 -- 를 붙여줘야한다 ex. kubectl exec myapp-git -- ls InitContainers . - gitRepo 대신 사용 - 파드가 생성될 때 가장 먼저 실행되는 컨테이너 - 초기화 컨테이너는 파드가 생성될 때 딱 한번 실행되고 종료됨 - 초기화 컨테이너가 종료되고 컨테이너가 실행됨 ```sh code initcontainer.yaml apiVersion: v1 kind: Pod metadata: name: myapp-git spec: initContainers: - image: ghcr.io/c1t1d0s7/network-multitool name: git command: [\"git\",\"clone\",\"https://github.com/kubernetes-sigs/kubespray.git\",\"/kube\"] volumeMounts: - mountPath: /kube name: kubespray containers: - image: ghcr.io/c1t1d0s7/go-myweb:alpine name: myweb volumeMounts: - mountPath: /kube name: kubespray volumes: - name: kubespray emptyDir: {} ``` ```sh kubectl exec myapp-git -- ls -l /kube ``` hostPath . 참고 주소 > https://kubernetes.io/ko/docs/concepts/storage/volumes/#hostpath - 호스트 노드의 파일이나 디렉토리를 파드에 마운트 - type - Directory : 주어진 경로에 디렉토리가 없으면 마운트 되지 않음 - DirectoryOrCreate : 디렉토리 없으면 kubelet이 권한 0755로 빈 디렉토리 생성 - File : 파일 없으면 마운트 실패 - FileOrCreate : 파일 없으면 kubelet이 권한 0644로 빈 디렉토리 생성 - Socket : UNIX socket - CharDevice : 문자 디바이스 - BlockDevice : 블록 디바이스 ```sh code hostpath.yaml apiVersion: v1 kind: Pod metadata: name: myweb-pod spec: containers: - image: httpd name: httpd volumeMounts: - mountPath: /usr/local/apache2/htdocs name: web-contents ports: - protocol: TCP containerPort: 80 volumes: - name: web-contents hostPath: path: /web-contents type: DirectoryOrCreate ``` ```sh hostctl get pods -o wide # 어떤 노드가 호스트로 있는지 확인해서 실제로 디렉토리가 생성됐는지 확인 ssh 192.168.201.21 \"ls -ld /web-contents\" ``` ```sh code hostpath.yaml apiVersion: v1 kind: Pod metadata: name: myweb-pod labels: app: myweb spec: initContainers: # /web폴더에 빈 볼륨 생성되고 git clone - image: alpine/git name: git-cloner args: - \"clone\" - \"https://github.com/StartBootstrap/startbootstrap-sb-admin-2.git\" - \"/web\" volumeMounts: - mountPath: /web name: web-contents containers: # 위에서 생성된 볼륨이 마운트 돼서 해당 폴더의 index.html을 쓰게 됨 - image: httpd name: httpd volumeMounts: - mountPath: /usr/local/apache2/htdocs name: web-contents ports: - protocol: TCP containerPort: 80 volumes: - name: web-contents hostPath: path: /web-contents type: DirectoryOrCreate --- apiVersion: v1 # 로드발란서를 이용해서 노출 kind: Service metadata: name: myweb-svc spec: type: LoadBalancer selector: app: myweb ports: - protocol: TCP port: 80 targetPort: 80 ``` ```sh kubectl create -f hostpath.yaml # chrome 시크릿창에서 192.168.201.200 ``` NFS . NFS 구성 . NFS 스토리지 서버 : k8s-m1 ```sh sudo apt update sudo apt install nfs-kernel-server sudo vi /etc/exports /nfs-volume *(rw,sync,no_subtree_check) # 추가 sudo mkdir /nfs-volume sudo chmod -R 777 /nfs-volume sudo exportfs -arv ansible all -i kubespray/inventory/mycluster/inventory.ini -m apt -a 'name=nfs-common state=present' -b # nfs client에도 nfs-common을 설치해야 사용 가능 ``` ```sh apiVersion: v1 kind: Pod metadata: name: myweb-pod-nfs labels: app: myweb spec: initContainers: - name: git-cloner image: alpine/git args: - \"clone\" - \"https://github.com/StartBootstrap/startbootstrap-sb-admin-2.git\" - \"/web\" volumeMounts: - name: web-contents mountPath: /web containers: - image: httpd name: httpd volumeMounts: - mountPath: /usr/local/apache2/htdocs name: web-contents ports: - protocol: TCP containerPort: 80 volumes: - name: web-contents nfs: path: /nfs-volume server: 192.168.201.11 --- apiVersion: v1 kind: Service metadata: name: myweb-svc spec: type: LoadBalancer selector: app: myweb ports: - protocol: TCP port: 80 targetPort: 80 ``` nfs 레플리카셋 써보기 ```sh apiVersion: apps/v1 kind: ReplicaSet metadata: name: myweb-rs-nfs labels: app: myweb spec: replicas: 2 selector: matchLabels: app: myweb template: metadata: labels: app: myweb spec: # 아래 주석 처리 된 내용들은, 앞의 실습에서 git-clone을 한 상태인데, 또 하면 에러가 나기 때문에 주석처리함 # 이 부분을 조건문으로 바꾸는 식으로 수정해서 사용하는 것이 안정성이 높다 #initContainers: #- name: git-cloner # image: alpine/git # args: # - \"clone\" # - \"https://github.com/StartBootstrap/startbootstrap-sb-admin-2.git\" # - \"/web\" # volumeMounts: # - name: web-contents # mountPath: /web containers: - image: httpd name: httpd volumeMounts: - mountPath: /usr/local/apache2/htdocs name: web-contents ports: - protocol: TCP containerPort: 80 volumes: - name: web-contents nfs: path: /nfs-volume server: 192.168.201.11 --- apiVersion: v1 kind: Service metadata: name: myweb-svc spec: type: LoadBalancer selector: app: myweb ports: - protocol: TCP port: 80 targetPort: 80 ``` 로컬볼륨은 간단한 테스트용 원래는 네트워크/클라우드 스토리지를 사용해야함 Static Provisioning . 참고 주소 > https://kubernetes.io/ko/docs/concepts/storage/persistent-volumes/ pod - pvc - pv - volume PV, PVC 라이프사이클 . 1. 프로비저닝 : PV 생성 - 정적 - 동적 2. 바인딩 : PV - PVC 연결 - PV와 PVC는 무조건 1:1 연결 - 두 개의 pod가 같은 storage를 연결하고 싶으면 PVC도 2개 PV도 2개 있어야 함 3. 사용 중(using) 4. 반환(회수, reclaiming) : PVC를 삭제시 - 반환 정책 - Retain : 보존 : PV 유지하지만 PVC 다시 연결 불가 : 데이터 삭제되지 않음 - 수동으로 반환해야함. 불편. 그래서 Delete가 default - Delete : 삭제 : PV 삭제 : 데이터 삭제됨 - Recycle : 재활용 : PV 유지하며 PVC 다시 연결 가능 : 데이터 삭제됨 - 스토리지 세팅이 다 달라서 다시 연결할 때 또 바꿔줘야함 : 의미가 없다 - 그래서, Deprecated (사용중지 상태) 접근 모드 . - ReadWriteOnce(RWO) -- 하나의 파드에서 볼륨을 읽기-쓰기로 마운트할 수 있다 - ReadOnlyMany(ROX) -- 여러 파드에서 볼륨을 읽기 전용으로 마운트할 수 있다 - ReadWriteMan(RWX) -- 여러 파드에서 볼륨을 읽기-쓰기로 마운트할 수 있다 스토리지에 따라 가능한 접근 모드가 정해져 있다. 주로 - 블록스토리지는 once - 공유 목적의 블록 스토리지는 다 가능 PV resource . ```sh apiVersion: v1 kind: PersistentVolume metadata: name: pv0003 spec: capacity: storage: 5Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle : # ex. nfs XXX ``` PVC resource . ```sh apiVersion: v1 kind: PersistentVolumeClaim metadata: name: myclaim spec: accessModes: - ReadWriteOnce # PVC의 접근모드는 연결하려는 PV에 선언된 것들 중에만 선언 가능 resources: requests: storage: 8Gi ## 레이블 셀렉터 예시 selector: matchLabels: release: \"stable\" ## PV 이름 지정 예시 volumeName: pv0003 ``` PVC와 PV를 연결하는 방법 - label selector - Volume name : PV 이름 pod에서 클레임 선택 . pod에서 PVC를 선택해줘야 한다는 뜻 ```sh spec: volumes: - name: abc persistentVolumeClaim: claimName: myclaim ``` PV, PVC kubectl로 상태 확인 명령 . ```sh kubectl get pv,pvc ``` #### pvc를 먼저 삭제해야 pc 삭제 가능 : deleted라고 뜨지만, 상태를 보면 삭제되지 않고 계속 terminating 상태임 pod, pv, pvc, svc 예제 . ```sh apiVersion: apps/v1 kind: ReplicaSet metadata: name: myweb-rs-nfs labels: app: myweb spec: replicas: 2 selector: matchLabels: app: myweb template: metadata: labels: app: myweb spec: containers: - image: httpd name: httpd volumeMounts: - mountPath: /usr/local/apache2/htdocs name: web-contents ports: - protocol: TCP containerPort: 80 volumes: - name: web-contents persistentVolumeClaim: claimName: myweb-pvc --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: myweb-pvc spec: accessModes: - ReadWriteMany resources: requests: storage: 5Gi volumeName: myweb-pv --- apiVersion: v1 kind: PersistentVolume metadata: name: myweb-pv spec: capacity: storage: 5Gi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain nfs: server: 192.168.201.11 path: /nfs-volume --- apiVersion: v1 kind: Service metadata: name: myweb-svc spec: type: LoadBalancer selector: app: myweb ports: - protocol: TCP port: 80 targetPort: 80 ``` #### enp0s3 인터페이스에 IP가 없을 때 실제 인터페이스의 mac 주소 확인 (VirtualBox) ``` vi /etc/netplan/50-cloud-init.yaml network: ethernets: enp0s3: dhcp4: true match: macaddress: XX:XX:XX:XX:XX:XX set-name: enp0s3 version: 2 ``` ```sh /run/systemd/network/10-netplan-enp0s3.link /run/systemd/network/10-netplan-enp0s3.network sudo netplan apply ``` 과제 . --- ### 과제: Wordpress / Mysql 구성 - Wordpress - ReplicaSet: 2 - NFS 스토리지 연결(Static Provision) - Service: LoadBalancer - MySQL - Pod - hostPath 스토리지 연결 - Service: ClusterIP 5월 3일 제출 - yaml 파일 - PDF 파일(이름 확인) ",
    "url": "/docs/daily-learning-log/20210429.html",
    "relUrl": "/docs/daily-learning-log/20210429.html"
  },"119": {
    "doc": "2021-04-29",
    "title": "2021-04-29",
    "content": " ",
    "url": "/docs/daily-learning-log/20210429.html",
    "relUrl": "/docs/daily-learning-log/20210429.html"
  },"120": {
    "doc": "2021-05-03",
    "title": "Kubernetes",
    "content": "과제 관련 - nfs . - nfs에 server, client가 있고, client에서 server에 접근할 때 계정을 nobody(nogroup에 속한)로 인식한다. - 즉, client의 root 사용자가 server의 nfs 경로에 접근하더라도 server 입장에서는 nobody라는 사용자가 접근한다고 인식한다. - 이 때, nfs 설정에서 no_root_squash 옵션을 설정하면 사용자를 nobody로 뭉개서 생각하는 것이 아닌 client에서 접근한 사용자 그대로 인식함 - nfs 경로 'sudo chmod -R 777 /nfs-volume'이 잘 적용됐다면 해당 옵션 없이도 아무나 접근이 가능했을 것 ",
    "url": "/docs/daily-learning-log/20210503.html",
    "relUrl": "/docs/daily-learning-log/20210503.html"
  },"121": {
    "doc": "2021-05-03",
    "title": "Dynamic Provisioning",
    "content": "Rook - Ceph . 참고 주소 https://ceph.io/ https://github.com/rook/rook.git Integrated Storage: 통합 스토리지 - Block : RBD(RADOS Block Device) - File : CephFS - Object : 일반적으로 다른 방법으로 사용하기 때문에 사용x https://rook.io/docs/rook/v1.6/ceph-quickstart.html kubespray에 적용 . kubespray vagrantfile 수정 ```sh # 추가되는 내용 unless File.exist?('./.disk/ceph1.vdi') vb.customize ['createmedium', 'disk', '--filename', './.disk/ceph1.vdi', '--size', 10240] end vb.customize ['storageattach', :id, '--storagectl', 'SCSI', '--port', 2, '--device', 0, '--type', 'hdd', '--medium', './.disk/ceph1.vdi'] ``` ```sh # window powershell에서 vagrant reload ``` ```sh # VM에서 ansible -i ~/kubespray/inventory/mycluster/inventory.ini kube-node -a 'lsblk -f' git clone --single-branch --branch v1.6.1 https://github.com/rook/rook.git ########## Deploy Operator cd rook/cluster/examples/kubernetes/ceph kubectl create -f crds.yaml -f common.yaml -f operator.yaml # rook-ceph namespace 생성 확인 kubectl get ns kubectl get all -n rook-ceph ########## Create ceph cluster kubectl create -f cluster.yaml # worker node가 하나인 경우에는 # kubectl create -f cluster-test.yaml # pod 생성 확인 - 시간이 꽤 걸리기 때문에 watch 띄워놓고 대기 watch -n1 -d kubectl get pod -n rook-ceph # 필수 설치 항목 - 해당 항목들 구동 시작 확인 후 다음 단계로 # rook-ceph-crashcollector-k8s-w1 # rook-ceph-crashcollector-k8s-w2 # rook-ceph-crashcollector-k8s-w3 # rook-ceph-mgr-a # rook-ceph-mon-a # rook-ceph-mon-b # rook-ceph-mon-c # rook-ceph-operator # rook-ceph-osd-0 # rook-ceph-osd-1 # rook-ceph-osd-2 ########## Install toolbox kubectl create -f toolbox.yaml kubectl exec -n rook-ceph -it deployment/rook-ceph-tools -- ceph status # check !! # HEALTH_OK : O # HEALTH_WARN : O # HEALTH_ERR: X ########## Configure Block Storage kubectl create -f csi/rbd/storageclass.yaml ########## Configure File Storage kubectl create -f filesystem.yaml kubectl -n rook-ceph get pod -l app=rook-ceph-mds # check !! # rook-ceph-mds-myfs-a # rook-ceph-mds-myfs-b kubectl create -f csi/cephfs/storageclass.yaml ## Check Storage Class kubectl get storageclass # check !! # rook-ceph-block # rook-cephfs ``` yaml로 구성할 때 provisioner : 일종의 Driver, 정해져있음 종류는 아래 참조 주소 참고 https://kubernetes.io/ko/docs/concepts/storage/storage-classes/ ```sh kubectl get sc kubectl get sc rook-ceph-block -o yaml ``` sc로 pv를 만들고 동적 프로비저닝 - rook-ceph-block - 블록 스토리지 - RWO - ROX - rook-cephfs - 파일 스토리지 - RWO - RWX - ROX ```sh kubectl exec -n rook-ceph -it deployment/rook-ceph-tools -- ceph df # storage가 mirror(일종의 백업)되기 때문에 최대 용량이 10G씩이라고 보면 됨. 이게 기본적으로 8.5G 정도 사용 가능 ``` > 레이드가 뭔지 설규환강사님 강의하셨던거 복습해보기 myapp dynamic provisioning . ``` code myapp-pod.yaml apiVersion: v1 kind: Pod metadata: name: myapp-pod labels: app: myapp spec: containers: - image: ghcr.io/c1t1d0s7/go-myweb:alpine name: myapp ports: - containerPort: 8080 name: web volumeMounts: - name: ceph-vol mountPath: /ceph-vol volumes: - name: ceph-vol persistentVolumeClaim: claimName: myapp-pvc code myapp-pvc.yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: myapp-pvc spec: accessModes: - ReadWriteOnce resources: requests: storage: 5Gi storageClassName: rook-ceph-block ``` mysql rook-ceph-block db 연동 오류 이유 . ```sh df -hT # 파일시스템 종류 확인 kubectl exec -it myapp-pod sh # 정상 구동된 pod에서 연동한 경로 확인해보기 ``` blockstorage(ex. ext4 file system)을 만들면 자동으로 특정 폴더(lost+found)가 생성됨 fsch(file system check) : booting 할 때 자동으로 진행, 수동도 가능 /etc/fstab에 booting시 fsch 여부, 순서 나와있음 ls -l 에서 권한 다음에 나오는 숫자는 hard link 갯수 갑작스런 종료로 인해 hard link가 깨지는 경우가 있음 이 때 fsch를 하게 되고, lost+found 폴더에 깨진 파일을 복구시켜줌 pvc로 db를 연동시키면 항상 db 초기화를 해야하는데, 해당 폴더에 뭔가가 있으면 구성 초기화를 하지 않는다. mysql pod 생성 때 lost+found 폴더 무시 옵션을 붙여야 함 ```sh args: [\"mysqld\", \"--ignore-db-dir=lost+found\"] ``` > 참고로, mariadb는 그런 옵션 없이도 잘 됨 mysql dynamic provisioning . ``` code mysql-pod.yaml apiVersion: v1 kind: Pod metadata: name: mysql-pod labels: app: mysql spec: containers: - image: mysql:5.7 name: mysql args: [\"mysqld\", \"--ignore-db-dir=lost+found\"] # ext4 파일 시스템의 lost+found 디렉토리 때문에 초기화 하지 못함 env: - name: MYSQL_ROOT_PASSWORD value: qwer1234 ports: - containerPort: 3306 name: mysql volumeMounts: - name: db-vol mountPath: /var/lib/mysql volumes: - name: db-vol persistentVolumeClaim: claimName: mysql-pvc code mysql-pvc.yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: mysql-pvc spec: accessModes: - ReadWriteOnce resources: requests: storage: 2Gi storageClassName: rook-ceph-block ``` mariadb dynamic provisioning . ``` code mariadb-pod.yaml apiVersion: v1 kind: Pod metadata: name: mariadb-pod labels: app: mariadb spec: containers: - image: mariadb name: mariadb env: - name: MYSQL_ROOT_PASSWORD value: qwer1234 ports: - containerPort: 3306 name: mariadb volumeMounts: - name: db-vol mountPath: /var/lib/mysql volumes: - name: db-vol persistentVolumeClaim: claimName: mariadb-pvc code mariadb-pvc.yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: mariadb-pvc spec: accessModes: - ReadWriteOnce resources: requests: storage: 2Gi storageClassName: rook-ceph-block ``` database 구성에 대하여 . block storage 형식의 database는 기본적으로 lock manager이라는 것이 있음 동시에 db를 수정할 수 없게 하는 것 그래서 RWX를 지원하지 않는다. 근데 굳이 file storage 안 쓰고 block storage를 써야하는 이유는 속도 때문 block storage가 훨씬 빠르다 그래서 Database는 주로 block storage로 구성 web 같은 경우는 file storage를 써도 속도 문제가 발생하지 않기 때문에 file storage를 사용 file storage의 주 목적은 공유! pvc를 지우지 않는 이상 데이터는 유지됨 pod랑 pvc만 올려놨다가 pod를 지우고 다시 생성해도 데이터는 그대로 유지 즉, pod와 volume의 life cycle을 분리시키는 것 > 온프레미스에서는 rook을 쓰는게 아닌 이상 동적 프로비저닝이 불가 > 책에서는 rook 안쓰고 AWS에서 실습함 p.428 default storage class . ```sh ########## set default storage class kubectl edit sc rook-cephfs metadata: annotations: storageclass.kubernetes.io/is-default-class: \"true\" # annotations(참조) 추가 ########## 적용 # pvc에서 storageClassName: \"\" # 혹은 아예 지정을 안하면 default storage class를 사용하겠다는 뜻 # 어떤 메뉴얼은 \"\"이고 어떤 메뉴얼은 지정을 하지 말라고 하는데 # 실습 때에는 지정하지 않은 경우에만 생성이 됐음 ``` ",
    "url": "/docs/daily-learning-log/20210503.html",
    "relUrl": "/docs/daily-learning-log/20210503.html"
  },"122": {
    "doc": "2021-05-03",
    "title": "2021-05-03",
    "content": " ",
    "url": "/docs/daily-learning-log/20210503.html",
    "relUrl": "/docs/daily-learning-log/20210503.html"
  },"123": {
    "doc": "2021-05-04",
    "title": "Kubernetes",
    "content": " ",
    "url": "/docs/daily-learning-log/20210504.html",
    "relUrl": "/docs/daily-learning-log/20210504.html"
  },"124": {
    "doc": "2021-05-04",
    "title": "Probe",
    "content": "참고 주소 > https://kubernetes.io/ko/docs/concepts/workloads/pods/pod-lifecycle/ 컨테이너에서 kubelet에 의해 주기적으로 수행되는 진단 - Probe의 종류 - livenessProbe : 컨테이너 동작 여부 - readinessProbe : 컨테이너 요청 ready 여부 - startupProbe : 컨테이너 내 App 시작 여부 - 컨테이너 진단 핸들러 종류 - ExecAction : 컨테이너 내에서 지정 명령어 실행 : 상태코드 0으로 종료 시 진단 성공으로 간주 - TCPSocketAction : 컨테이너 IP 주소에 대한 TCP 검사 : 특정 Port가 열린 경우 성공으로 간주 - HTTPGetAction : 컨테이너 IP 주소에 대한 HTTP get 요청 수행 : HTTP 응답 코드가 200~399이면 성공으로 간주 - Probe 결과 종류 - Success : 성공 - Failure : 실패 - Unknown : 진단 실패 : 액션 수행 x livenessProbe 예시 . ```sh # liveness probe 예시 1 apiVersion: v1 kind: Pod metadata: name: liveness-pod spec: containers: - name: httpd image: httpd ports: - name: http containerPort: 80 protocol: TCP livenessProbe: httpGet: path: / port: 80 # liveness probe 예시 2 apiVersion: v1 kind: Pod metadata: name: liveness3-pod spec: containers: - name: db image: mysql:5.7 env: - name: MYSQL_ROOT_PASSWORD value: qwer1234 ports: - name: mysql containerPort: 3306 protocol: TCP livenessProbe: tcpSocket: port: 3306 # liveness probe 예시 3 apiVersion: v1 kind: Pod metadata: name: liveness4-pod spec: containers: - name: db image: mysql:5.7 env: - name: MYSQL_ROOT_PASSWORD value: qwer1234 ports: - name: mysql containerPort: 3306 protocol: TCP livenessProbe: exec: command: - \"mysqladmin\" - \"ping\" - \"-uroot\" - \"-p${MYSQL_ROOT_PASSWORD}\" ``` readinessProbe 예시 . ```sh # readiness probe 예시 1 apiVersion: v1 kind: Service metadata: name: ready-svc spec: selector: app: ready ports: - protocol: TCP port: 80 targetPort: 8080 --- apiVersion: apps/v1 kind: ReplicaSet metadata: name: ready2 labels: app: ready spec: replicas: 2 selector: matchLabels: app: ready template: metadata: labels: app: ready spec: containers: - name: web image: ghcr.io/c1t1d0s7/go-myweb:alpine ports: - containerPort: 8080 protocol: TCP readinessProbe: exec: command: - \"ls\" - \"/tmp/ready\" # monitoring watch kubectl get po,svc,ep kubectl run test -it --rm --image ghcr.io/c1t1d0s7/network-multitool bash watch curl http://ready-svc ``` ```sh kubectl exec -- touch /tmp/ready kubectl exec -- rm /tmp/ready ``` startupProbe 예시 . ```sh apiVersion: apps/v1 kind: ReplicaSet metadata: name: start labels: app: start spec: replicas: 2 selector: matchLabels: app: start template: metadata: labels: app: start spec: containers: - name: web image: ghcr.io/c1t1d0s7/go-myweb:alpine ports: - containerPort: 8080 protocol: TCP startupProbe: httpGet: path: /health port: 8080 readinessProbe: exec: command: - \"ls\" - \"/tmp/ready\" --- apiVersion: v1 kind: Service metadata: name: start-svc spec: selector: app: start ports: - protocol: TCP port: 80 targetPort: 8080 ``` ",
    "url": "/docs/daily-learning-log/20210504.html",
    "relUrl": "/docs/daily-learning-log/20210504.html"
  },"125": {
    "doc": "2021-05-04",
    "title": "Deployment",
    "content": "참조 주소 > https://kubernetes.io/ko/docs/concepts/workloads/controllers/deployment/ pod와 replicaset을 조절 : 선언적 업데이트 모든 deployment의 롤아웃 기록은 시스템에 남아있기 때문에 언제든지 롤백 가능 Deployment 예시 . ```sh apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment labels: app: nginx spec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80 ``` 롤아웃 방법 예시 . ```sh kubectl apply kubectl edit kubectl patch kubectl replace kubectl set image deploy nginx-deployment nginx=nginx:1.19 # kubectl set image = ``` 히스토리에 코멘트 남기기 . - 명령어 ```sh kubectl --record ``` - annotation ```sh metadata: annotations: kubernetes.io/change-cause: \"XXX\" ``` 롤아웃 확인 명령어 . ```sh kubectl rollout history kubectl rollout status -w ``` 롤백 예시 . ```sh kubectl rollout undo --to-revision=X ``` Six Strategies for Application Deployment . 참조 주소 https://thenewstack.io/deployment-strategies/ - Recreate: Version A is terminated then version B is rolled out. - Ramped (also known as rolling-update or incremental): Version B is slowly rolled out and replacing version A. - Blue/Green: Version B is released alongside version A, then the traffic is switched to version B. - Canary: Version B is released to a subset of users, then proceed to a full rollout. - A/B testing: Version B is released to a subset of users under specific condition. - Shadow: Version B receives real-world traffic alongside version A and doesn’t impact the response. > kubernetes에는 Recreate와 Ramped만 구현되어 있다. ",
    "url": "/docs/daily-learning-log/20210504.html",
    "relUrl": "/docs/daily-learning-log/20210504.html"
  },"126": {
    "doc": "2021-05-04",
    "title": "StatefulSet",
    "content": "```sh apiVersion: apps/v1 kind: StatefulSet metadata: name: myapp-sts spec: selector: matchLabels: app: myapp serviceName: myapp-svc-headless replicas: 1 template: metadata: labels: app: myapp spec: containers: - name: myapp image: ghcr.io/c1t1d0s7/go-myweb ports: - containerPort: 8080 --- apiVersion: v1 kind: Service metadata: name: myapp-svc-headless spec: selector: app: myapp clusterIP: None ports: - name: http port: 80 targetPort: 8080 ``` ```sh kubectl scale sts myapp-sts --replicas=3 ``` stateful만 상태 저장, 나머지 두 개는 stateless임 하나가 죽으면 다시 만들 때 똑같은 이름으로 만든다 뭐 하나가 죽으면 다 죽을 때까지 새로운 것을 만들지 않는다 svc는 무조건 헤드리스 bash명령 쓸 수 있게 나오고 여러 가지 설정을 함 pod마다 다른 storage를 가지고 있어서 데이터 불균형 발생 애초에 얘는 pod마다 상태를 가지게 하는게 목표인 애라 그게 당연함 sharding db 복제 - multi master ",
    "url": "/docs/daily-learning-log/20210504.html",
    "relUrl": "/docs/daily-learning-log/20210504.html"
  },"127": {
    "doc": "2021-05-04",
    "title": "2021-05-04",
    "content": " ",
    "url": "/docs/daily-learning-log/20210504.html",
    "relUrl": "/docs/daily-learning-log/20210504.html"
  },"128": {
    "doc": "2021-05-06",
    "title": "Kubernetes",
    "content": " ",
    "url": "/docs/daily-learning-log/20210506.html",
    "relUrl": "/docs/daily-learning-log/20210506.html"
  },"129": {
    "doc": "2021-05-06",
    "title": "StatefulSet",
    "content": "참고 주소 > https://kubernetes.io/ko/docs/concepts/workloads/controllers/statefulset/ - 특징 - deployment와 scaling을 관리 - pod의 순서 및 고유성 보장 - 고유한 파드 이름 : Controller-N ",
    "url": "/docs/daily-learning-log/20210506.html",
    "relUrl": "/docs/daily-learning-log/20210506.html"
  },"130": {
    "doc": "2021-05-06",
    "title": "App Customization",
    "content": "Docker와 비교 . Docker의 CMD -> Kubernetes args Docker의 ENTRYPOINT -> Kubernetes command 예시 . ```sh apiVersion: apps/v1 kind: ReplicaSet metadata: name: myapp labels: app: myapp spec: replicas: 3 selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - name: myapp image: ghcr.io/c1t1d0s7/go-myweb args: - \"-port=8888\" env: - name: MESSAGE value: \"HELLO MESSAGE!!!\" ports: - containerPort: 8888 protocol: TCP ``` ConfigMap . 참고 주소 > https://kubernetes.io/docs/concepts/configuration/configmap/ - 특징 - key: value 형태 - 기밀이 아닌 데이터 저장 : 암호화 x - 포함하는 데이터 - 환경 변수 : .spec.containers.env.valueFrom - key : 변수명 - value : 변수값 - Volume : .spec.volumes.configMap : .spec.volumes.secret - 설정 파일을 제공하기 위함 - key : 파일명 - value : 파일내용 - ConfigMap과 Secret의 차이점 - ConfigMap은 평문이고 Secret은 BASE64 인코딩(암호화x) - Secret은 암호화키, 패스워드 인증서 참고주소 > https://www.vaultproject.io/ Configmap 예시 . ```sh kubectl create cm myconfig1 --from-literal=key1=value1 kubectl create cm myconfig2 --from-literal=key2=value2 --from-literal=key22=value22 kubectl create cm myconfig3 --from-file=message.txt kubectl create cm myconfig4 --from-file=msg=message.txt # 구성 예시 1 apiVersion: v1 kind: ConfigMap metadata: name: myconfig5 data: key5: value5 key55: value55 --- apiVersion: v1 kind: Pod metadata: name: cmtest spec: containers: - name: web image: httpd env: - name: MESSAGE valueFrom: configMapKeyRef: key: msg name: myconfig4 volumeMounts: - name: mycon mountPath: /tmp volumes: - name: mycon configMap: name: myconfig4 # 구성 예시 2 apiVersion: v1 kind: ConfigMap metadata: name: myconfig6 data: svc-port: \"8888\" svc-msg: \"hello configmap!\" --- apiVersion: v1 kind: Service metadata: name: myapp spec: selector: app: myapp ports: - protocol: TCP port: 80 targetPort: web --- apiVersion: apps/v1 kind: ReplicaSet metadata: name: myapp labels: app: myapp spec: replicas: 1 selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - name: myapp image: ghcr.io/c1t1d0s7/go-myweb args: - \"-port=$(PORT)\" env: - name: PORT valueFrom: configMapKeyRef: name: myconfig6 key: svc-port - name: MESSAGE valueFrom: configMapKeyRef: name: myconfig6 key: svc-msg ports: - name: web containerPort: 8888 protocol: TCP ``` nginx Gzip 압축 기능 활성화 . ```sh # 요청 양식 # Accept-Encoding: gzip, deflate curl -H \"Accept-Encoding: gzip, deflate\" http://nginx-svc -v # 응답 양식 # Content-Encoding: gzip curl -H \"Accept-Encoding: gzip\" http://nginx-svc -I ``` nginx Gzip 사용 예시 . ```sh apiVersion: apps/v1 kind: ReplicaSet metadata: name: nginx labels: app: nginx spec: replicas: 1 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx ports: - name: web containerPort: 80 protocol: TCP volumeMounts: - name: nginx-gzip-cfg mountPath: /etc/nginx/conf.d volumes: - name: nginx-gzip-cfg configMap: name: nginx-gzip --- apiVersion: v1 kind: ConfigMap metadata: name: nginx-gzip data: nginx-gzip.conf: | server { listen 80; server_name localhost; gzip on; gzip_types text/plain application/xml; location / { root /usr/share/nginx/html; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } } --- apiVersion: v1 kind: Service metadata: name: nginx-svc spec: selector: app: nginx ports: - protocol: TCP port: 80 targetPort: web ``` ",
    "url": "/docs/daily-learning-log/20210506.html",
    "relUrl": "/docs/daily-learning-log/20210506.html"
  },"131": {
    "doc": "2021-05-06",
    "title": "2021-05-06",
    "content": " ",
    "url": "/docs/daily-learning-log/20210506.html",
    "relUrl": "/docs/daily-learning-log/20210506.html"
  },"132": {
    "doc": "2021-05-07",
    "title": "Kubernetes",
    "content": " ",
    "url": "/docs/daily-learning-log/20210507.html",
    "relUrl": "/docs/daily-learning-log/20210507.html"
  },"133": {
    "doc": "2021-05-07",
    "title": "minikube 배포",
    "content": "```sh # 방법 1 minikube start --cpus 2 --memory 2048 --driver virtualbox -- kubernetes-version 1.18.18 # 방법 2 minikube config set cpus 2 minikube config set memory 2048 minikube config set driver virtualbox minikube config set kubernetes-version 1.18.18 minikube config view # minikube run minikube start # minikube run & node 개수 지정 minikube start --nodes=3 # metallb minikube service list minikube addons list minikube ip 192.168.99.102 minikube addons configure metallb -- Enter Load Balancer Start IP: 192.168.99.200 -- Enter Load Balancer End IP: 192.168.99.220 minikube addons enable metallb # ingress minikube addons enable ingress # node 확장 minikube node add # node 확인 minikube node list ``` Secret . BASE64로 인코딩 ConfigMap 디스크에 저장 Secret 메모리에만 저장 - Data Type - docker-registry (kubernetes.io/dockerconfigjson) - 컨테이너 레지스트리 인증 정보 1. 이미지 pull (ex. nginx, httpd, go-myweb) 2. 이미지에 docker tag 붙이기 3. docker 로그인 4. 이미지 push 5. Docker hub Private 저장소 6. pod, rs, deploy resource 생성 7. docker-registry secret 생성 ```sh kubectl create secret docker-registry --docker-username= --docker-password='' --docker-email= ``` 8. pod, rs, deploy resource 생성 ```sh spec: imagePullSecrets: - name: ``` - generic (Opaque) - 일반적인 데이터 ```sh kubectl create secret generic secret1 --from-literal=key1=value1 echo \"P@ssw0rd\" > pwd.txt kubectl create secret generic secret2 --from-file=pwd.txt ``` - tls (kubernetes.io/tls) - TLS 인증서, TLS 키 ```sh mkdir tls openssl genrsa -out tls/my.key 2048 openssl req -new -x509 -key tls/my.key -out tls/my.crt -days 365 -subj /CN=my.abc.com kubectl create secret tls mytls --cert=tls/my.crt --key=tls/my.key ``` - Service Account - API에 인증하기 위한 토큰 Secret env, volume 예시 . ```sh apiVersion: v1 kind: Pod metadata: name: web2 spec: containers: - name: web image: httpd env: - name: MESSAGE1 valueFrom: secretKeyRef: name: mysec key: key1 - name: MESSAGE2 valueFrom: secretKeyRef: name: mysec key: key2 # kubectl create secret mysec \\ # --from-literal=key1=value1 \\ # --from-listeral=key2=value2 # MESSAGE1=value1 # MESSAGE2=value2 volumeMounts: - name: secret-vol mountPath: /tmp # key: 파일명 # value: 파일내용 # /tmp/key1: value1 # /tmp/key2: value2 volumes: - name: secret-vol secret: secretName: mysec ``` Secret yaml 예시 . ```sh apiVersion: v1 kind: Secret metadata: name: type: data: : ``` 인코딩 방법 . ```sh echo \"P@ssw0rd\" | base64 ``` 디코딩 방법 . ```sh echo \"UEBzc3cwcmQK\" | base64 --decode ``` nginx에 tls 적용 . ```sh cat nginx-tls.conf server { listen 80; listen 443 ssl; server_name my.abc.com; ssl_certificate /etc/nginx/tls/tls.crt; ssl_certificate_key /etc/nginx/tls/tls.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers HIGH:!aNULL:!MD5; location / { root /usr/share/nginx/html; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } } ``` ```sh apiVersion: v1 kind: Pod metadata: name: nginx-tls labels: app: nginx-tls spec: containers: - name: nginx image: nginx volumeMounts: - name: nginx-tls-conf mountPath: /etc/nginx/conf.d - name: nginx-tls-cert mountPath: /etc/nginx/https ports: - name: http containerPort: 80 - name: https containerPort: 443 volumes: - name: nginx-tls-conf configMap: name: nginx-tls-conf - name: nginx-tls-cert secret: secretName: nginx-tls-cert --- apiVersion: v1 kind: ConfigMap metadata: name: nginx-tls-conf data: nginx-tls.conf: | server { listen 80; listen 443 ssl; server_name my.abc.com; ssl_certificate /etc/nginx/https/tls.crt; ssl_certificate_key /etc/nginx/https/tls.key; ssl_protocols TLSv1.2 TLSv1.3; ssl_ciphers HIGH:!aNULL:!MD5; location / { root /usr/share/nginx/html; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } } --- apiVersion: v1 kind: Secret metadata: name: nginx-tls-cert type: kubernetes.io/tls data: tls.crt: | ABC tls.key: | ABC --- apiVersion: v1 kind: Service metadata: name: nginx-svc spec: type: LoadBalancer selector: app: nginx-tls ports: - name: http port: 80 targetPort: 80 - name: https port: 443 targetPort: 443 ``` ```sh curl https://x.x.x.x -k -v ``` Ingress에 secret, tls termination . ```sh # ingress에 tls 형식 apiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: name: myapp-ing spec: tls: - hosts: - secretName: rules: - host: http: paths: - path: backend: serviceName: servicePort: ``` ```sh apiVersion: apps/v1 kind: Deployment metadata: name: nginx-term labels: app: nginx-term spec: replicas: 3 selector: matchLabels: app: nginx-term template: metadata: labels: app: nginx-term spec: containers: - name: nginx image: nginx ports: - name: http containerPort: 80 --- apiVersion: v1 kind: Secret metadata: name: nginx-term-cert type: kubernetes.io/tls data: tls.crt: | # 엄청 긴 인코딩 값 tls.key: | # 엄청 긴 인코딩 값 --- apiVersion: v1 kind: Service metadata: name: nginx-svc spec: type: ClusterIP selector: app: nginx-term ports: - name: http port: 80 targetPort: 80 --- apiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: name: nginx-term spec: tls: - hosts: - www.192-168-201-23.nip.io secretName: nginx-term-cert rules: - host: www.192-168-201-23.nip.io http: paths: - path: / backend: serviceName: nginx-svc servicePort: 80 ``` ```sh # 확인 방법 1 curl https://my.abc.com --resolv my.abc.com:443:192.168.201.21 -k -v # 확인 방법 2 sudo vi /etc/hosts 192.168.201.21 my.abc.com curl https://my.abc.com -k -v # 확인 방법 3 : 윈도우 c:\\windows\\system32\\derivers\\etc\\hosts # 관리자 권한으로 Wildcard DNS 서버 https://nip.io/ https://sslip.io host www.1-1-1-1.nip.io ``` ",
    "url": "/docs/daily-learning-log/20210507.html",
    "relUrl": "/docs/daily-learning-log/20210507.html"
  },"134": {
    "doc": "2021-05-07",
    "title": "2021-05-07",
    "content": " ",
    "url": "/docs/daily-learning-log/20210507.html",
    "relUrl": "/docs/daily-learning-log/20210507.html"
  },"135": {
    "doc": "2021-05-10",
    "title": "Kubernetes",
    "content": " ",
    "url": "/docs/daily-learning-log/20210510.html",
    "relUrl": "/docs/daily-learning-log/20210510.html"
  },"136": {
    "doc": "2021-05-10",
    "title": "Resource management",
    "content": "- resource - cpu - memory - huge page metrics-server . 단점: 실시간, cpu/memory 메트릭 수집 metrics-server 적용 . - kubespray ```sh vi inventory/mycluster/group_vars/k8s-cluster/addons.yml metrics_server_enabled: true ansible-playbook -i inventory/mycluster/inventory.ini cluster.yml --become ``` - minikube ```sh minikube addons enable metrics-server ``` 명령어 . ```sh kubectl top nodes kubectl top pods kubectl describe node ``` resource 정의 . ```sh spec: containers: - resources: requests: cpu: X memory: X limits: cpu: X memory: X ``` - limit만 설정하는 경우에는 request가 limit 양 만큼 설정됨 cpu 부하 테스트 . ```sh kubectl exec -it -- sha1sum /dev/zero ``` LimitRange . - default = 기본 limit - defaultRequest = 기본 request - default, defaultRequest는 Container type에만 선언 - max = 할당 최대값 - min = 할당 최소값 : max와 마찬가지로 설정 가능 ```sh apiVersion: v1 kind: LimitRange metadata: name: lim1 spec: limits: - type: Container default: cpu: 10m memory: 20M defaultRequest: cpu: 5m memory: 10M - type: Pod max: cpu: 1000m memory: 1G maxLimitRequestRatio: cpu: 2 memory: 2 - type: PersistentVolumeClaim min: storage: 1Gi max: storage: 5Gi ``` Resource Quota . 오브젝트의 개수 제한 ```sh apiVersion: v1 kind: ResourceQuota metadata: name: rq spec: hard: pods: 10 services: 5 services.loadbalancers: 1 services.nodeports: 2 configmaps: 5 secrets: 5 ``` Auto Scaling . - 기존에는 manual적으로 scaling을 했었음 ```sh kubectl scale ``` - 종류 - HPA - Horizontal Pod Autoscaler - scale out / in - 파드의 수를 조정 - VPA - Vertical Pod Autoscaler - scale up / down - 파드 요청/제한 조정 - CA - Cluster Autoscaler - Work Node scale out / in HPA(Horizontal Pod Autoscaler) . - 적용 범위 - ReplicaSet/ReplicationController - StatefulSet - Deployment - 적용 방식 - Pod -> cAdvisor(kubelet) -> Metrics Server -> HPA(scale out? in?) kubelet(cAdvisor) ; cAdvisor: Container Advisor - 적용시 계산 방식 - 원하는 레플리카 수 = ceil[현재 레플리카 수 * ( 현재 메트릭 값 / 원하는 메트릭 값 )] - 현재 메트릭 값 : current - 원하는 메트릭 값 : desired - api resource version - autoscaling/v1: CPU 메트릭 - autoscaling/v2beta2: CPU, Memory, Custom 메트릭 ```sh apiVersion: autoscaling/v1 kind: HorizontalPodAutoscaler metadata: name: hpa spec: maxReplicas: 10 minReplicas: 1 scaleTargetRef: apiVersion: apps/v1 kind: ReplicaSet name: rs1 targetCPUUtilizationPercentage: 70 ``` > 스케일 대상이 되는 컨트롤러는 반드시 request가 설정되어 있어야 함 cool-down timer/delay . scale in/down(축소)는 300s(5분)의 유예기간 후 적용됨 ",
    "url": "/docs/daily-learning-log/20210510.html",
    "relUrl": "/docs/daily-learning-log/20210510.html"
  },"137": {
    "doc": "2021-05-10",
    "title": "Scheduler",
    "content": "어떤 pod가 어떤 node에서 구동될 지 정하는 것 nodeName . 직접 지정 형식 .spec.nodename ```sh # pod 적용 예시 apiVersion: v1 kind: Pod metadata: name: nnpod spec: nodeName: k8s-w3 containers: - name: web image: nginx # ReplicaSet 적용 예시 apiVersion: apps/v1 kind: ReplicaSet metadata: name: nnrs spec: replicas: 2 selector: matchLabels: app: nnrs template: metadata: labels: app: nnrs spec: nodeName: k8s-w3 containers: - name: web image: nginx ``` nodeSelector . node의 label로 선택하기 - node에 label 붙이기 ```sh kubectl labels node k8s-w2 gpu=titan kubectl labels node k8s-w3 gpu=titan # 서로 다른 노드에 같은 label을 붙일 수도 있다 ! ``` ```sh # pod 적용 예시 apiVersion: v1 kind: Pod metadata: name: nspod spec: nodeSelector: gpu: titan containers: - name: web image: nginx # ReplicaSet 적용 예시 apiVersion: apps/v1 kind: ReplicaSet metadata: name: nsrs spec: replicas: 2 selector: matchLabels: app: nsrs template: metadata: labels: app: nsrs spec: nodeSelector: gpu: titan containers: - name: web image: nginx ``` cordon/drain . - cordon: 해당 노드 스케줄링 금지 - 노드 제거 - 노드 유지보수 - drain: 현재 실행되고 있는 파드 퇴거(Evict) - drain을 하면 자동 cordon이 됨 - --ignore-daemonsets - --delete-local-data > drain/cordon을 하고 난 후 해당 node를 다시 스케줄링 가능 상태로 만들려면 반드시 uncordon ! 명령어 . ```sh kubectl cordon kubectl uncordon kubectl drain ``` ",
    "url": "/docs/daily-learning-log/20210510.html",
    "relUrl": "/docs/daily-learning-log/20210510.html"
  },"138": {
    "doc": "2021-05-10",
    "title": "2021-05-10",
    "content": " ",
    "url": "/docs/daily-learning-log/20210510.html",
    "relUrl": "/docs/daily-learning-log/20210510.html"
  },"139": {
    "doc": "2021-05-11",
    "title": "Kubernetes",
    "content": " ",
    "url": "/docs/daily-learning-log/20210511.html",
    "relUrl": "/docs/daily-learning-log/20210511.html"
  },"140": {
    "doc": "2021-05-11",
    "title": "Scheduler",
    "content": "적용 순서 nodeName -> nodeSelector -> affinity -> taint Affinity . 참고주소 > https://kubernetes.io/ko/docs/concepts/scheduling-eviction/assign-pod-node/ .spec.affinity 에 정의 - 종류 - nodeAffinity : node pod : pod가 어떤 node에 속할지 결정 - preferredDuringSchedulingIgnoredDuringExecution : 선호(soft) - 해석 : 선호된다 / 스케줄링 되는 중(파드나 컨테이너가 만들어져서 배치되기 전) / 무시된다 / 파드가 실행되고 있는 중 - preference : Node Label Seletor - matchExpressions - matchFields - weight : 가중치 (1~100) - requiredDuringSchedulingIgnoredDuringExecution : 요구(hard) - 해석 : 요구된다 / 스케줄링 되는 중(파드나 컨테이너가 만들어져서 배치되기 전) / 무시된다 / 파드가 실행되고 있는 중 - nodeSelectorTerms : Node Label Seletor - matchExpressions - matchFields - weight : 가중치 (1~100 - podAffinity : node(pod+pod) : pod가 다른 특정 pod와 같이 있을지 따로 있을지 결정 - preferredDuringSchedulingIgnoredDuringExecution : 사용 추천 x - podAffinityTerm - labelSelector: Pod label selector - topologyKey : 배치 구조 : 노드의 실제 위치 - Node / Rack (온프레미스에서) / AZ (AWS에서) / Group (AWS에서) - kubernetes.io/hostname (분류 기준) ```sh kubectl get nodes -L 'kubernetes.io/hostname' ``` - weight - requiredDuringSchedulingIgnoredDuringExecution - labelSelector - matchExpressions - matchFields - topologyKey - podAntiAffinity : node(pod)-node(pod) - 중요 !! 같은 기능을 하는 app이 하나의 node에 같이 들어있다가 해당 node가 다운되면 그 app들이 전부 다 다운됨 > 같은 기능을 하는 app끼리 서로 배척하자(따로있자) : anti > 다른 기능을 하는 app끼리 서로 선호하자 : affinity (podAffinity) > 가장 이상적인건 세트처럼! 각각 다른 노드에 a,b,c / a,b,c 이런식으로! nodeAffinity 예시 . ```sh apiVersion: apps/v1 kind: ReplicaSet metadata: name: noaff spec: replicas: 2 selector: matchLabels: app: noaff template: metadata: labels: app: noaff spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: gpu operator: In values: - \"titan\" preferredDuringSchedulingIgnoredDuringExecution: - preference: matchExpressions: - key: gpu operator: In values: - \"3090\" weight: 100 containers: - name: web image: nginx ``` pod(Anti)Affinity 예시 . ```sh apiVersion: apps/v1 kind: ReplicaSet metadata: name: antiaff-cache labels: app: antiaff spec: replicas: 2 selector: matchLabels: app: antiaff tier: cache template: metadata: labels: app: antiaff tier: cache spec: affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: tier operator: In values: - \"frontend\" topologyKey: \"kubernetes.io/hostname\" podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: tier operator: In values: - \"cache\" topologyKey: \"kubernetes.io/hostname\" containers: - name: web image: nginx --- apiVersion: apps/v1 kind: ReplicaSet metadata: name: antiaff-frontend labels: app: antiaff spec: replicas: 2 selector: matchLabels: app: antiaff tier: frontend template: metadata: labels: app: antiaff tier: frontend spec: affinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: tier operator: In values: - \"frontend\" topologyKey: \"kubernetes.io/hostname\" containers: - name: web image: nginx ``` Taint/Toleration . nodename, nodeselector, nodeaffinity의 경우 선택권이 pod에 있는 것과 달리 Taint/Toleration은 노드가 파드를 선택 (이전에는 모두 파드가 노드를 선택하는 거였음) - Taint : 노드가 파드를 제외 : 이 조건이 없으면 그 pod는 실행하지 않겠다! - 파드에 toleration이 설정된 것 중에 선택 - key - value 형식 : label가 같은 형식이지만 label에 설정하는 것은 아님 - 이게 생각보다 강제적인 것은 아님 일종의 우선순위 개념 ? : 실습하면서, 올바른 toleration을 지정했음에도 불구하고 다른 node에 생성된 경우가 많았음 - 예를 들어, 해당 node의 memory가 꽉 차있거나 하면 당연스레 다른 node에 할당됨 - effect - NoSchedule: 반드시 스케줄링 X (요청: hard) - PreferNoSchedule: 가능하면 스케줄링 X (선호: soft) - NoExecute: 실행 X node에 Taint 적용 예시 . ```sh kubectl taint node k8s-w3 gpu=titan:noSchedule # gpu=titan 톨러레이션이 없으면 스케줄하지 않겠다! ``` Control-plane(master) node의 Taint . node-role.kubernetes.io/master:NoSchedule - 해석 - key : node-role.kubernetes.io/master - value : 없음 : 없음은 곧 all을 의미 - effect : NoSchedule ```sh kubectl describe nodes k8s-m1 kubectl describe nodes k8s-m1 | grep Taints # Taints 항목에 node-role.kubernetes.io/master:NoSchedule가 있다!! ``` pod에 toleration 적용 예시 . ```sh # master에 pod 올리고 싶을 때 toleration 설정 apiVersion: v1 kind: Pod metadata: name: toleration-pod spec: containers: - name: web image: nginx tolerations: - key: \"node-role.kubernetes.io/master\" operator: Exists effect: \"NoSchedule\" # 설정한 taint에 맞춰 toleration 설정 apiVersion: v1 kind: Pod metadata: name: toleration-pod spec: containers: - name: web image: nginx tolerations: - key: \"gpu\" operator: Equal value: \"titan\" effect: \"NoSchedule\" ``` Static pod . kubernetes가 관리하는 파드가 아님 - control plane에서 존재하는 것들 중 systemd 서비스로 존재하는 kubelet과 etcd (systemctl status에서 active된 애들)만 빼고 나머지들은 toleration이 없어도 master에서 실행되고 있다. - 마찬가지로 nginx-proxy는 각각의 worker node에 자동으로 실행되고 있다. - 특징 - kind : Pod - 이름 : PodName-NodeName - master에 있는 static pod 종류 - kube-apiserver-k8s-m1 - kube-controller-manager-k8s-m1 - kube-scheduler-k8s-m1 > kubelet은 주기적으로 /etc/kubernetes/manifests 디렉토리에 있는 yaml(kind:Pod) 파일을 읽어서 실행시킨다! ```sh cd /etc/kubernetes/manifests/ ls kube-apiserver.yaml kube-controller-manager.yaml kube-scheduler.yaml # 이 위치에서 yaml 생성해서 test pod 만들면 자동으로 test-k8s-m1 이렇게 이름이 생기고 k8s-m1에서 구동됨 # worker node에서 하더라도 똑같이! ``` kubelet 서비스가 docker 서비스에 컨테이너 만들어라 뭐해라 요청하는 것 VM을 실행하면 enabled로 설정해놓은 서비스들이 자동으로 실행됨 그 중에는 docker, kubelet도 포함 각 노드들(마스터 포함)에 있는 kubelet 서비스가 각 컨테이너들을 실행시켜야 kubernetes를 구성하는 cluster의 요소들(static pod)이 다 구동되는 것 kubernetes cluster 구성할 때 우리가 kubeadm 으로 init하는데, 이게 static pod 파일을 구성하는 것임 모든 키와 매칭시키는 방법 . ```sh spec: tolerations: - operator: Exists effect: \"NoSchedule\" ``` 모든 taint를 무시하는 방법 . ```sh spec: tolerations: - operator: Exists ``` ",
    "url": "/docs/daily-learning-log/20210511.html",
    "relUrl": "/docs/daily-learning-log/20210511.html"
  },"141": {
    "doc": "2021-05-11",
    "title": "API 접근",
    "content": "- resource - Role - ClusterRole - RoleBinding - ClusterRoleBinding - ServiceAccount - CSR(Certificate Signing Request) 참고주소 > 인증: https://kubernetes.io/docs/reference/access-authn-authz/authentication/ > 인가: https://kubernetes.io/docs/reference/access-authn-authz/authorization/ > 어드미션 컨트롤: https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/ > RBAC: https://kubernetes.io/docs/reference/access-authn-authz/rbac/ 용어정리 . - Identification(ID): 식별 - Authentication: 인증 - 인증서(x.509), 토큰 - 방법: 패스워드, 인증서, OTP, 생체인증, 토큰 ... - Credential: 자격증명 - Authorization: 인가, 권한부여 Multi Factor Authentication(MFA) : Authy 추천(여러 기기 동기화 사용 가능) kubernetes에서 다루는 인증 . - 인증을 위한 식별 방법 두 가지 - Service Account : 서비스 계정 - resource가 존재 (kubectl api-resources) - 원래 용도는 사용자가 사용하는 것이 아님 : 서비스가 사용하는 것 - 다만, 사용자가 원하면 사용할 수 있음 - User Account : 사용자 계정 - resource가 없다 : kubernetes가 관리하지 않는다 - 사용자가 사용하기 위한 목적 : 서비스가 사용하지 않는다 - AWS의 IAM과 연동된다 - 인증 방법 - x.509 인증서 - 토큰(Service Account가 사용하는 방식) - 인가 방법 - ABAC : 사용 x - Attribute-based access-control : 속성 기반 - 변경하게 되면 control plane의 api를 재시작해야함 = 다운타임발생 = 그래서 사용 x - RBAC - Role-based access control : 역할 기반 - Role : 역할 (특정 namespace 한정) - ClusterRole : 역할 (cluster 전체) - RoleBinding : Role과 Account를 연결 (Service, user 둘 다 가능) - ClusterRoleBinding : ClusterRole과 Account를 연결 - Admission-Control (승인 제어) - 유효성 검사 - 오브젝트 리소스 생성, 삭제 - 오브젝트 수정 - 우리가 간단하게 pod를 정의하는 yaml를 만들어서 올리면, admission-control이 알아서 지정하지 않은 부분들에 대한 내용을 추가해줌 - 수정된 것들은 etcd에 저장됨 RBAC: Role Based Access Control . 서비스(pod) - Service Account - RoleBinding - Role 서비스(pod) - Service Account - ClusterRoleBinding - ClusterRole 사용자 - RoleBinding - Role 사용자 - ClusterRoleBinding - ClusterRole Role이나 ClusterRole에 API에 요청할 수 있는 verb들을 지정해놓고 Rolebinding을 통해 특정 Account가 해당 verb를 사용할 수 있는 권한을 부여 예를 들어 pod에 Service Account를 지정해놓고 여러가지 verb를 부여하면, 해당 Pod는 API에 해당 verb로 요청을 할 수 있음 pod 생성시 따로 sa를 지정하지 않으면 권한이 부여되지 않은 default sa가 적용됨 Role/ClusterRole . ```sh apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: pod-reader rules: - apiGroups: nonResourceURLs: resources: resourceNames: verbs: ``` - verbs 종류 - get: 개별 리소스 확인(kubectl get ) - list: 여러 리소스 확인(kubectl get ) - watch: 리소스 실시간 확인(--watch) - create: 리소스 생성 - update: 리소스 변경 - patch: 리소스 일부 변경 - delete: 개별 리소스 삭제 - deletecollection: 여러 리소스 삭제 RoleBinding/ClusterRoleBinding . ```sh apiVersion: kind: metadata: roleRef: apiGroup: kind: name: subjects: - apiGroup: kind: name: namespace: ``` Service Account . ```sh apiVersion: v1 kind: ServiceAccount metadata: name: ``` ",
    "url": "/docs/daily-learning-log/20210511.html",
    "relUrl": "/docs/daily-learning-log/20210511.html"
  },"142": {
    "doc": "2021-05-11",
    "title": "2021-05-11",
    "content": " ",
    "url": "/docs/daily-learning-log/20210511.html",
    "relUrl": "/docs/daily-learning-log/20210511.html"
  },"143": {
    "doc": "2021-05-12",
    "title": "Kubernetes",
    "content": " ",
    "url": "/docs/daily-learning-log/20210512.html",
    "relUrl": "/docs/daily-learning-log/20210512.html"
  },"144": {
    "doc": "2021-05-12",
    "title": "API 접근",
    "content": "- API server IP 주소 확인하기 ```sh kubectl cluster-info # 결과 Kubernetes master is running at https://192.168.201.11:6443 To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. ``` - 인증서 보기 인증서 위치 : /etc/kubernetes/ssl ```sh openssl x509 -in ca.crt -text -noout # kubernetes와 kubernetes : root ca이기 때문에 자체서명임 openssl x509 -in apiserver.crt -text -noout # kubernetes와 kubernetes-apiserver ``` 인증서를 보면 기한이 있음 : 주기적으로 다음 kube버전으로 업데이트가 필요함(기한 만료되면 멈춤) 예를 들면 현재 1.18을 쓰다가 1년이 되기 전에 1.19로 업데이트를 해야 자동으로 인증서도 업데이트가 돼서 문제가 생기지 않음 - kubeconfig 파일 내용 확인 ```sh kubectl config view ``` - config 파일 구조 ```sh apiVersion: v1 kind: Config preferences: {} clusters: - cluster: certificate-authority-data: # 인코딩된 데이터 server: https://192.168.201.11:6443 name: cluster.local users: - name: kubernetes-admin user: client-certificate-data: # 인코딩된 데이터 client-key-data: # 인코딩된 데이터 contexts: - context: cluster: cluster.local user: kubernetes-admin name: kubernetes-admin@cluster.local current-context: kubernetes-admin@cluster.local ``` - 클러스터 목록 확인 ```sh kubectl config get-clusters ``` - 클러스터 생성 ```sh kubectl config set-cluster test --server=https://1.2.3.4:6443 kubectl config set-cluster test --certificate-authority=/etc/kubernetes/ssl/ca.crt ``` RBAC . Service Account를 이용한 사용자 인증 구현 . 1. NS : development 2. SA : devops 3. Role : dev-fc - development NS에 모든 권한 4. RoleBinding : devops와 dev-fc 연결 5. ClusterRole : cluster-read - cluster 전체 읽기 6. ClusterRoleBinding : devops와 clust-read 연결 7. kubeconfig(~/.kube/config) : kubectl이 항상 이 config를 참조함 - cluster - account - context(클러스터-계정) 1. NS 생성 development라는 이름의 Name Space 생성 ```sh apiVersion: v1 kind: Namespace metadata: name: development ``` 2. SA 생성 devops라는 Service Account 생성 ```sh apiVersion: v1 kind: ServiceAccount metadata: name: devops namespace: development ``` 3. Role 생성 dev-fc라는 Role 생성 - namespace : development ; role은 특정 ns 한정이기 때문에 지정해줘야 함 - core ApiGroup - all resources - all verbs ```sh apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: dev-fc namespace: development rules: - apiGroups: - \"\" resources: - \"*\" verbs: - \"*\" ``` 4. RoleBinding - namespace : development - dec-fc(Role)과 devops(Service Account) binding ```sh apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: devops-dev-fc namespace: development roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: dev-fc subjects: - apiGroup: \"\" kind: ServiceAccount name: devops namespace: development ``` 5. ClusterRole cluster 전체 읽기 권한의 Role : view라는 이름으로 이미 존재하므로 따로 생성할 필요 x ```sh kubectl get clusterRole # 이 명령어로 확인 가능 ``` 6. ClusterRoleBinding - 일반 role은 namespace를 지정하지만 cluster role은 전체 cluster에 대한 권한이므로 지정 x - devops(Service Account)와 view(Cluster Role) binding ```sh apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: devops-view roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: view subjects: - apiGroup: \"\" kind: ServiceAccount name: devops namespace: development ``` 7. kubeconfig - 사용자 생성(SA) ```sh # 사용자 생성시 필요한 토큰 정보 확인 kubectl get sa -n development devops kubectl describe secrets -n development devops-token-XXXXX # 위의 결과값을 아래에서 token에 입력 kubectl config set-credentials devops --token=XXX ``` - 사용자 생성(사용자;x.509) ```sh kubectl config set-credentials kadmin --client-certificate= --client-key= --embed-certs ``` - 컨텍스트 목록 확인 ```sh kubectl config get-contexts ``` - 현재 컨텍스트 ```sh kubectl config current-context ``` - 컨텍스트 생성 ```sh kubectl config set-context devops@test --cluster=test --user=devops --namespace=development ``` - 컨텍스트 변경 및 확인 ```sh kubectl config use-context devops@test kubectl config get-contexts kubectl config current-context ``` - 컨텍스트 이름 변경 ```sh kubectl config rename-context ``` > 이번 실습에서 만들어낸 devops 사용자는 development namespace에서 권한을 apigroup은 \"\"(core)이고 verbs는 all로 가져서 코어그룹에 한해서 모든 verb를 사용할 수 있다. > cluster role은 view로 설정했기 때문에 다른 namespace에 대해서는 read할만한 것들만 가능 사용자를 생성하면 secret이 자동 생성되고 거기에 token이 있다. ```sh kubectl get secret -n development #결과 default-token-9k44j devops-token-pbtrn ``` 사용자 계정을 이용한 사용자 인증 구현(with x.509) . 1. CSR 2. ClusterRole : admin 3. ClusterRoleBinding : kadmin-admin 4. kubeconfig - 일반적인 시나리오 - CA : ca 인증서 / ca 키 - Client 1. client key 생성 2. client CSR 생성/요청 (Certificate Signing Request: 인증서 서명 요청) - CA는 client CSR + CA 인증서/키를 이용하여 client 인증서 생성 3. client 인증서 받음 - x.509 키 생성 ```sh openssl genrsa -out kadmin.key 2048 ``` - CSR 생성 ```sh openssl req -new -key kadmin.key -out kadmin.csr -subj \"/CN=kadmin\" # base64로 인코딩 cat kadmin.csr | base64 ``` - CSR 리소스 생성 ```sh code csr.yaml apiVersion: certificates.k8s.io/v1beta1 kind: CertificateSigningRequest metadata: name: kadmin spec: request: | # 들여쓰기 잘하자 signerName: kubernetes.io/kube-apiserver-client usages: - client auth kubectl create -f csr.yaml # 만약 위의 실습부터 쭉 이어왔다면 실행되지 않을 것 : devops 사용자라서 # kubectl config use-context kubernetes-admin@cluster.local 필요 ``` - CSR 확인 ```sh kubectl get csr # pending상태일 것 : 승인 필요 ``` - CSR 승인 : 서명된 인증서 발급 ```sh kubectl certificate approve kadmin ``` - CSR 다시 확인 ```sh kubectl get csr # approve, issued 상태가 됨 ``` - CSR 인증서 발행 ```sh kubectl get csr kadmin -o yaml # csr.status.certificate 항목에 있는 게 인증서임! kubectl get csr kadmin -o jsonpath='{.status.certificate}' # 인증서 내용만 빠르게 보는 방법 kubectl get csr kadmin -o jsonpath='{.status.certificate}' | base64 -d # 인증서 내용 디코딩해서 보는 방법 kubectl get csr kadmin -o jsonpath='{.status.certificate}' | base64 -d > kadmin.crt # 인증서 디코딩한 내용 kadmin.crt 파일에 저장하기 ``` 원격 클라이언트 적용 방법 . ```sh # 윈도우 파워쉘 관리자권한 choco install kubernetes-cli --version=1.19.5 [--allowdowngrade] # kubernetes-cli가 이미 설치된 게 아니면 [--allowdowngrade] 생략 가능 kubectl version # 버전 확인 # VM에서 cp ~/.kube/config /vagrant # 윈도우 환경에서 c:\\Users\\jeunv\\vagrant\\k8s\\config ----copy---> c:\\Users\\jeunv\\.kube\\config ``` > window에서 연결해서 쓰면 결국 powershell을 쓰는 것이기 때문에 자동완성 기능이 없음 vm을 사용하지 않고 window 환경에서 쿠버네티스를 돌린다? git bash나 window에서 지원하는 linux쉘을 다운로드해서 사용함 하이퍼v를 사용하기 때문에 현재 실습 환경에는 맞지 않음 ",
    "url": "/docs/daily-learning-log/20210512.html",
    "relUrl": "/docs/daily-learning-log/20210512.html"
  },"145": {
    "doc": "2021-05-12",
    "title": "Helm",
    "content": "kubectl이 설치되어 있고 config파일이 있는 환경에서 쓸 수 있는 패키지 매니저 Helm 설치 . snap이라는 패키지 관리자는 거의 모든 linux 환경에서 쓰는 건데 안정적이지 않아서 사용하지 않을 것 script를 이용하여 설치 참고주소 > https://helm.sh/ko/docs/intro/install/ ```sh curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 chmod +x get_helm.sh ./get_helm.sh helm version # 우리는 helm3 사용 ``` - completion (자동완성) ```sh helm completion bash | sudo tee /etc/bash_completion.d/helm exec bash ``` Helm 개요 . - 차트 : 헬름 패키지 - 저장소 : 차트를 모아두고 공유하는 장소 - 릴리스 : 쿠버네티스 클러스터에서 구동되는 차트의 인스턴스 혹은 설치된 차트 - 찾기 ```sh helm search hub wordpress # hub에서 wordpress를 찾는다는 의미 helm search hub mysql ``` - repo 추가 ```sh helm repo add stable https://charts.helm.sh/stable # 안정적인걸 관습적으로 stable이라고 하는데 꼭 stable일 필요는 없다 ``` - repo 삭제 ```sh helm repo remove stable ``` - repo 확인 ```sh helm repo list ``` - repo에서 찾기 ```sh helm search repo mysql # 결과에서 stable/로 시작하는 것들은 내가 repo를 stable로 지정했기 때문 ``` > 주로 다 deprecated 되어있음 : 가능하면 artifact hub를 써라! - 차트 설치 = 릴리즈 만들기 : value 변경 없이 ```sh helm install / helm install happy-panda stable/mariadb ``` - 차트 설치 = 릴리즈 만들기 : value 변경 : customize ```sh vi values.yaml # 이름 이무거나 상관 없음 # 덮어쓰고자 하는 내용만 차트의 values.yaml 참고해서 똑같이 작성 service: type: LoadBalancer helm install happy-panda stable/mariadb -f values.yaml ``` > value가 적용되는 부분에서 많은 문제가 발생할 수 있음 : 이 경우 아예 실행이 잘 안 될 수도 있음 > 그런 문제가 생길 경우 upgrade나 rollback에 문제가 생길 수 있으며 > 이런 경우에는 수동으로 수정을 해야함 - 릴리즈 삭제 ```sh helm uninstall helm uninstall happy-panda ``` > helm2랑 helm3랑 구조적으로 달라서 명령어도 차이가 나기 때문에 자료를 찾아서 사용할 때에는 그게 2인지 3인지 잘 보고 써야함 > helm 2는 문제가 많으므로 3을 권장함 - 설치된 릴리즈 목록 확인 ```sh helm list ``` - 가동 resource 확인 : 릴리즈가 설치되면 거기에 포함된 resource들이 자동으로 구동됨 ```sh kubectl get all kubectl get configmap kubectl get secret helm status happy-panda ``` - helm show - all : chart + readme + values - chart : 차트 정보(패키지 정보) ex. 버전, etc : 차트가 저장되어 있는 곳(repo)의 해당 차드의 Chart.yaml - readme : README.md - values : 사용자가 설정할 수 있는 값들 ```sh helm show all stable/mysql helm show chart stable/mysql helm show readme stable/mysql helm show values stable/mysql ``` - 차트 구조 - Chart.yaml - README.md - values.yaml - /templates - helm upgrade ```sh helm upgrade -f / helm upgrade -f value.yaml happy-panda stable/mariadb # Revision이 2로 바뀜 : upgrade 할 때마다 올라가는 듯 ``` - helm history ```sh helm history happy-panda ``` - helm rollback ```sh helm rollback helm rollback happy-panda 1 ``` - 차트 만들기 ```sh helm create helm create abc # 차트이름과 같은 폴더가 생기고 그 안에는 reference가 자동 생성됨 ``` - 차트 패키징 ```sh helm package helm package abc # abc-0.1.0.tgz 파일이 생성됨 : 이 파일을 repo에 올리면 됨 ``` - local에 있는 차트 설치 ```sh helm install helm install newabc ./abc-0.1.0.tgz ``` > kubectl 명령어 칠 때, 자동완성 편하게 하려면 kubectl -n 형식이 좋음 ",
    "url": "/docs/daily-learning-log/20210512.html",
    "relUrl": "/docs/daily-learning-log/20210512.html"
  },"146": {
    "doc": "2021-05-12",
    "title": "2021-05-12",
    "content": " ",
    "url": "/docs/daily-learning-log/20210512.html",
    "relUrl": "/docs/daily-learning-log/20210512.html"
  },"147": {
    "doc": "2021-05-13",
    "title": "Kubernetes",
    "content": " ",
    "url": "/docs/daily-learning-log/20210513.html",
    "relUrl": "/docs/daily-learning-log/20210513.html"
  },"148": {
    "doc": "2021-05-13",
    "title": "kubernetes version skew(차이)",
    "content": "각 버전은 1년간 지원 : 1년 지나기 전에 업데이트 해야 보안상 안전 참고주소 > https://kubernetes.io/ko/docs/setup/release/version-skew-policy/ > https://github.com/kubernetes/kubernetes - 업그레이드 목록 - kube-apiserver ; +1 - kubelet ; -2 - kube-controller-manager ; -1 - kube-scheduler ; -1 - kube-cloud-controller-manager ; -1 - kubectl ; +-1 순차적 업데이트 원리 . 동시에 업데이트 해버리면 cluster가 멈추게 되므로 순차적인 업데이트 필요 순차적으로 업데이트 하는 와중에는 클러스터 내에서도 버전 차이가 발생하게 됨 docs의 skew-policy에서 지원되는 버전 차이에 대한 내용을 명시함 이 차이를 확인하고, 순차적으로 업데이트 진행 즉, 현재 3개의 component가 1.20이며 1.21로 업데이트하고 한다면 docs의 skew 중 1.21과 1.20이 호환된다는 것을 확인한 뒤 각 component들을 순차적으로 업데이트 - skew에 따라 정해지는 업데이트 순서 ; ansible이 자동으로 해줌 ; 내용만 이해하자 ! 1. kube-apiserver 2. kube-contoller-manager, kube-scheduler, kube-cloud-controller-manager 3. kubelet 4. kube-proxy 5. kubectl 업그레이드 . 참고주소 > https://kubespray.io/#/docs/upgrades 프로메테우스 실습 하려고 하는데 resource를 많이 차지하니까 - 노드 하나 제거 - 나머지 노드들 resource(cpu,memory) 늘려주고 - master도 worker로 사용할 수 있도록 변경 ```sh # delete node : ~/kubespray 에서! ansible-playbook -i inventory/mycluster/inventory.ini remove-node.yml -b -e \"node=k8s-w3\" # 잘 제거 됐는지 확인 kubectl get nodes # inventory.ini file 수정 all, node에서 k8s-w3 주석처리 node에 k8s-m1 추가 # 업그레이드 하면 k8s-m1의 Taint가 자동으로 해제되어 있을 것 # graceful update 실행 : node를 cordon해야하는데 master는 1개뿐이라 cordon하면 멈춰버려서 안됐던 것 ! # 따라서 unsafe upgrade 해야함 ansible-playbook -i inventory/mycluster/inventory.ini upgrade-cluster.yml -b -e kube_version=v1.19.10 # 에러떴음 ! 아래는 에러 없애는 과정 cp inventory/mycluster/inventory.ini ~ cd rm -rf kubespray/ git clone -b release-2.15 https://github.com/kubernetes-sigs/kubespray.git cd kubespray/ cp -r inventory/sample inventory/mycluster cp ~/inventory.ini inventory/mycluster/ # update 다시 실행 ansible-playbook -i inventory/mycluster/inventory.ini upgrade-cluster.yml -b -e kube_version=v1.19.10 # unsafe upgrade ansible-playbook -i inventory/mycluster/inventory.ini cluster.yml -b -e kube_version=v1.19.10 -e upgrade_cluster_setup=true # update 잘 됐는지 확인 kubectl get nodes # w3 VM halt : window에서 vagrant halt k8s-w3 # 잘 중단됐는지 확인 vagrant status # vagrantfile 수정 vagrant file에서 w3부분 주석처리 m1, w1, w2 resource 수정 : memory 3060 w3의 disk를 m1으로 옮김 # VM 재부팅 vagrant reload ``` ",
    "url": "/docs/daily-learning-log/20210513.html",
    "relUrl": "/docs/daily-learning-log/20210513.html"
  },"149": {
    "doc": "2021-05-13",
    "title": "Prometheus",
    "content": "monitoring tool - Infrastructure - BM, VM, Container : CPU, Memory, Disk, Network - Kubernetes cluster - Application - APM : Application Performance Monitor - http 요청/응답 : RTT - http 응답 시간 - http 응답 코드 - 쿠버네티스에서 모니터링 - Heapster + influxdb : 메트릭 저장 ; 프로젝트가 중단되었음 - metrics-server : cpu, memory 실시간 모니터링만 가능 - Prometheus - Thanos, coretex를 이용하여 long term도 가능 Prometheus Architecture . 참고주소 > https://prometheus.io/docs/introduction/overview/ node에 pod 형태로 배포 측정 값들을 Retrieval(회수) service discovery : kubernetes의 api server한테 질의해서 측정대상 확인 길게 실행하는 것들은 그 자체를 pull해서 데이터를 수집 금방 실행되고 없어지는 것들은 pushgateway에 가지고 있다가 pull해서 데이터 수집 TSDB : Time Series DB : 시계열 데이터베이스 ; 시간대 별로 그래프가 그려져야하는 것들을 다룸 PromQL : prometheus 전용 query language 참고주소 > https://github.com/prometheus/prometheus Prometheus 설치 . 참고주소 > https://github.com/prometheus-operator/prometheus-operator prometheus 설치할 때에는 prometheus-operator로 설치 ! rook-ceph 설치할 때도 똑같았음. operator가 먼저 생성되고 operator가 구성요소들을 순차적으로 생성 원래 쿠버네티스는 선언형이라서 순서를 지정해서 뭘 만들기가 힘듬 그래서 operator를 이용하여 순차적으로 진행할 수 있도록 하는 것 operator는 operator SDK로 만듬 참고주소 > https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack ```sh # prometheus repo 추가 helm repo add prometheus-community https://prometheus-community.github.io/helm-charts # repo update helm repo update # value.yaml 내용 확인 : 필요하면 수정 helm show values prometheus-community/kube-prometheus-stack > prom-value.yaml # prometheus 릴리즈 + 전용 namespace 구성 helm install monitor prometheus-community/kube-prometheus-stack --namespace prometheus --create-namespace # grafana를 loadbalancer로 upgrade rm prom-value.yaml # 아까 만든 prom-value.yaml 파일 지우고 다시 생성 vi prom-value.yaml grafana: service: type: LoadBalancer # upgrade helm upgrade -n prometheus -f prom-value.yaml monitor prometheus-community/kube-prometheus-stack # 접속 kubectl get all -n prometheus # grafana loadbalancer external-ip 확인 : 192.168.201.200 : chrome으로 접속 # id : admin # password : prom-operator # 맨 위에 home 버튼 누르면 general dashboard 선택 가능 ``` ECK operator 설치 . 참조주소 > https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-install-helm.html#k8s-install-helm ```sh helm repo add elastic https://helm.elastic.co helm repo update helm install eck elastic/eck-operator -n logging --create-namespace ``` Elasticsearch 설치 . 참조주소 > https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-deploy-elasticsearch.html ```sh apiVersion: elasticsearch.k8s.elastic.co/v1 kind: Elasticsearch metadata: name: elasticsearch namespace: logging spec: version: 7.12.1 nodeSets: - name: default count: 1 config: node.store.allow_mmap: false ``` > elasticsearch는 custom resource : crd를 이용하여 새로운 resource를 만든 것 Kibana . 참조 주소 > https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-deploy-kibana.html ```sh apiVersion: kibana.k8s.elastic.co/v1 kind: Kibana metadata: name: kibana namespace: logging spec: version: 7.12.1 count: 1 elasticsearchRef: name: elasticsearch http: service: spec: type: LoadBalancer ``` Filebeat . 참조 주소 > https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-beat-quickstart.html ```sh apiVersion: beat.k8s.elastic.co/v1beta1 kind: Beat metadata: name: filebeat namespace: logging spec: type: filebeat version: 7.12.1 elasticsearchRef: name: elasticsearch config: filebeat.inputs: - type: container paths: - /var/log/containers/*.log daemonSet: podTemplate: spec: dnsPolicy: ClusterFirstWithHostNet hostNetwork: true securityContext: runAsUser: 0 containers: - name: filebeat volumeMounts: - name: varlogcontainers mountPath: /var/log/containers - name: varlogpods mountPath: /var/log/pods - name: varlibdockercontainers mountPath: /var/lib/docker/containers volumes: - name: varlogcontainers hostPath: path: /var/log/containers - name: varlogpods hostPath: path: /var/log/pods - name: varlibdockercontainers hostPath: path: /var/lib/docker/containers ``` Elastic ID/PW . ID : elastic ```sh kubectl get secret -n logging elasticsearch-es-elastic-user -o yaml kubectl get secret -n logging elasticsearch-es-elastic-user -o jsonpath='{.data.elastic}' | base64 -d ``` address : https://x.x.x.x:5601/ - 메뉴 Analytics -> Discover - Create index patten 버튼 - step1: - index pattern name: \"filebeat-*\" - step2: - Time field: @timestamp - 메뉴 Analytics -> Discover ",
    "url": "/docs/daily-learning-log/20210513.html",
    "relUrl": "/docs/daily-learning-log/20210513.html"
  },"150": {
    "doc": "2021-05-13",
    "title": "EKS",
    "content": "- EKS - 관리형 쿠버네티스 : 사용자는 workernode만 관리 - AWS EKS : cluster 1개 시간당 $0.1 - Azure AKS - Google GKE - Oracle OKE - 설치형 쿠버네티스 : 사용자가 모두 관리 (master도) - kops - kubespray - kubeadm ",
    "url": "/docs/daily-learning-log/20210513.html",
    "relUrl": "/docs/daily-learning-log/20210513.html"
  },"151": {
    "doc": "2021-05-13",
    "title": "AWS EKS",
    "content": "시작하는 방법 2가지 1. 콘솔 : EKS가 사용할 AWS상의 role을 따로 만들어줘야함 : 복잡! 2. eksctl eksctl로 AWS EKS 구성 . 참조 주소 > https://eksctl.io/ ```sh # awscli 설치 choco install awscli # aws-iam-authenticator 설치 choco install aws-iam-authenticator # ekscli 설치 choco install eksctl # kubectl 설치 choco install kubectl # aws 자격증명 설정 aws configure accesskey secretkey region: ap-northeast-2 # eks 클러스터 생성 eksctl create cluster \\ --name mycluster \\ --region ap-northeast-2 \\ --version 1.18 \\ --nodegroup-name mynodegroup \\ --nodes 3 \\ --managed # eks 클러스터 삭제 eksctl delete cluster mycluster ``` ",
    "url": "/docs/daily-learning-log/20210513.html",
    "relUrl": "/docs/daily-learning-log/20210513.html"
  },"152": {
    "doc": "2021-05-13",
    "title": "2021-05-13",
    "content": " ",
    "url": "/docs/daily-learning-log/20210513.html",
    "relUrl": "/docs/daily-learning-log/20210513.html"
  },"153": {
    "doc": "2021-05-14",
    "title": "Kubernetes",
    "content": " ",
    "url": "/docs/daily-learning-log/20210514.html",
    "relUrl": "/docs/daily-learning-log/20210514.html"
  },"154": {
    "doc": "2021-05-14",
    "title": "AWS EKS",
    "content": "node는 public에 배치하면 안됨!!!!! 무조건 private 기능 - Create, get, list and delete clusters - Create, drain and delete nodegroups - Scale a nodegroup - Update a cluster - Use custom AMIs - Configure VPC Networking - Configure access to API endpoints - Support for GPU nodegroups - Spot instances and mixed instances - IAM Management and Add-on Policies - List cluster Cloudformation stacks - Install coredns - Write kubeconfig file for a cluster ```sh eksctl create cluster \\ --name mycluster \\ --region ap-northeast-2 \\ --version 1.18 \\ --nodegroup-name mynodegroup \\ --nodes 3 \\ --managed eksctl get cluster eksctl get nodegroup --cluster mycluster ``` eks 예제 . ```sh apiVersion: eksctl.io/v1alpha5 kind: ClusterConfig metadata: name: mycluster region: us-east-1 version: \"1.18\" #AZ availabilityZones: [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\", \"us-east-1d\"] # IAM OIDC & Service Account iam: withOIDC: true serviceAccounts: - metadata: name: aws-load-balancer-controller namespace: kube-system wellKnownPolicies: awsLoadBalancerController: true # Unmanaged Node Groups nodeGroups: # On-Demand Instance / Public Network / SSH - name: ng-1 instanceType: t2.small desiredCapacity: 1 availabilityZones: [\"us-east-1a\", \"us-east-1b\"] ssh: allow: true publicKeyPath: ./eks-key.pub # Spot Instances / Scaling / Private Network # IAM Policy: AutoScaler, ALB Ingress, CloudWatch, EBS - name: ng-spot-2 minSize: 1 desiredCapacity: 2 maxSize: 3 privateNetworking: true instancesDistribution: maxPrice: 0.01 instanceTypes: [\"t2.small\", \"t3.small\"] onDemandBaseCapacity: 0 onDemandPercentageAboveBaseCapacity: 0 spotInstancePools: 2 availabilityZones: [\"us-east-1c\", \"us-east-1d\"] iam: withAddonPolicies: autoScaler: true albIngress: true cloudWatch: true ebs: true # Mixed(On-Demand/Spot) Instances - name: ng-mixed-3 desiredCapacity: 2 instancesDistribution: maxPrice: 0.01 instanceTypes: [\"t2.small\", \"t3.small\"] onDemandBaseCapacity: 1 onDemandPercentageAboveBaseCapacity: 50 # Managed Node Groups managedNodeGroups: # On-Demand Instance - name: managed-ng-1 instanceType: t2.small desiredCapacity: 2 # Spot Instance - name: managed-ng-spot-2 instanceTypes: [\"t2.medium\", \"t3.medium\"] desiredCapacity: 1 spot: true # Fargate Profiles fargateProfiles: - name: fg-1 selectors: - namespace: dev labels: env: fargate # CloudWatch Logging cloudWatch: clusterLogging: enableTypes: [\"api\", \"scheduler\"] ``` ```sh cat myeks.yaml apiVersion: eksctl.io/v1alpha5 kind: ClusterConfig metadata: name: myeks region: ap-northeast-2 version: \"1.18\" # AZ availabilityZones: - ap-northeast-2a - ap-northeast-2b - ap-northeast-2c - ap-northeast-2d # IAM OIDC & Service Account iam: withOIDC: true serviceAccounts: - metadata: name: aws-load-balancer-controller namespace: kube-system wellKnownPolicies: awsLoadBalancerController: true - metadata: name: ebs-csi-controller-sa namespace: kube-system wellKnownPolicies: ebsCSIController: true - metadata: name: cluster-autoscaler namespace: kube-system wellKnownPolicies: autoScaler: true # Managed Node Groups managedNodeGroups: # On-Demand Instance - name: myng-1 instanceType: t3.medium minSize: 2 desiredCapacity: 3 maxSize: 4 privateNetworking: true #ssh: # allow: true # publicKeyPath: ./keypair/myeks.pub availabilityZones: - ap-northeast-2a - ap-northeast-2b - ap-northeast-2c - ap-northeast-2d iam: withAddonPolicies: autoScaler: true albIngress: true cloudWatch: true ebs: true # Fargate Profiles fargateProfiles: - name: fg-1 selectors: - namespace: dev labels: env: fargate # CloudWatch Logging cloudWatch: clusterLogging: enableTypes: - api - audit - authenticator - controllerManager - scheduler eksctl create cluster -f myeks.yaml eksctl create iamserviceaccount -f myeks.yaml --approve ``` Add-ons . Ingress Controller with ALB . 참조 주소 > https://docs.aws.amazon.com/eks/latest/userguide/aws-load-balancer-controller.html ```sh kubectl apply -k \"github.com/aws/eks-charts/stable/aws-load-balancer-controller//crds?ref=master\" helm upgrade -i aws-load-balancer-controller eks/aws-load-balancer-controller \\ --set clusterName=myeks \\ --set serviceAccount.create=false \\ --set serviceAccount.name=aws-load-balancer-controller \\ -n kube-system ``` EBS CSI Driver . 참조 주소 > https://docs.aws.amazon.com/eks/latest/userguide/ebs-csi.html ```sh helm repo add aws-ebs-csi-driver https://kubernetes-sigs.github.io/aws-ebs-csi-driver helm repo update helm upgrade -install aws-ebs-csi-driver aws-ebs-csi-driver/aws-ebs-csi-driver \\ --namespace kube-system \\ --set enableVolumeResizing=true \\ --set enableVolumeSnapshot=true \\ --set serviceAccount.controller.create=false \\ --set serviceAccount.controller.name=ebs-csi-controller-sa ``` Metrics Server . 참조 주소 > https://docs.amazonaws.cn/en_us/eks/latest/userguide/metrics-server.html ```sh kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml ``` Cluster Autoscaler . 참조 주소 > https://docs.aws.amazon.com/eks/latest/userguide/cluster-autoscaler.html ```sh curl -o cluster-autoscaler-autodiscover.yaml https://raw.githubusercontent.com/kubernetes/autoscaler/master/cluster-autoscaler/cloudprovider/aws/examples/cluster-autoscaler-autodiscover.yaml # cluster-autoscaler-autodiscover.yaml 파일 수정 command: - ./cluster-autoscaler - --v=4 - --stderrthreshold=info - --cloud-provider=aws - --skip-nodes-with-local-storage=false - --expander=least-waste - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/ # = myeks kubectl create -f cluster-autoscaler-autodiscover.yaml kubectl -n kube-system logs -f deployment.apps/cluster-autoscaler ``` CloudWatch Container Insights . 참조 주소 > https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Container-Insights-setup-EKS-quickstart.html ```sh ClusterName=myeks RegionName=ap-northeast-2 FluentBitHttpPort='2020' FluentBitReadFromHead='Off' [[ ${FluentBitReadFromHead} = 'On' ]] && FluentBitReadFromTail='Off'|| FluentBitReadFromTail='On' [[ -z ${FluentBitHttpPort} ]] && FluentBitHttpServer='Off' || FluentBitHttpServer='On' curl https://raw.githubusercontent.com/aws-samples/amazon-cloudwatch-container-insights/latest/k8s-deployment-manifest-templates/deployment-mode/daemonset/container-insights-monitoring/quickstart/cwagent-fluent-bit-quickstart.yaml | sed 's/{{cluster_name}}/'${ClusterName}'/;s/{{region_name}}/'${RegionName}'/;s/{{http_server_toggle}}/\"'${FluentBitHttpServer}'\"/;s/{{http_server_port}}/\"'${FluentBitHttpPort}'\"/;s/{{read_from_head}}/\"'${FluentBitReadFromHead}'\"/;s/{{read_from_tail}}/\"'${FluentBitReadFromTail}'\"/' | kubectl apply -f - kubectl get po -n amazon-cloudwatch # 결과 예시 NAME READY STATUS RESTARTS AGE cloudwatch-agent-gc5kc 1/1 Running 0 41m cloudwatch-agent-gqc42 1/1 Running 0 41m cloudwatch-agent-wqcgw 1/1 Running 0 41m fluent-bit-m8wph 1/1 Running 0 60m fluent-bit-ng45l 1/1 Running 0 60m fluent-bit-qvcgp 1/1 Running 0 60m ``` /aws/containerinsights//application /aws/containerinsights//dataplan /aws/containerinsights//host /aws/containerinsights//performance CloudWatch => Container Insights => 성능 모니터링 Resources . Service . ```sh apiVersion: apps/v1 kind: ReplicaSet metadata: name: myapp spec: replicas: 2 selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - name: myweb image: ghcr.io/c1t1d0s7/go-myweb ports: - containerPort: 8080 ``` ```sh apiVersion: v1 kind: Service metadata: name: mysvc spec: ports: - port: 80 targetPort: 8080 selector: app: myapp ``` https://aws.amazon.com/ko/elasticloadbalancing/features/ - CLB ```sh apiVersion: v1 kind: Service metadata: name: mysvc spec: type: LoadBalancer ports: - port: 80 targetPort: 8080 selector: app: myapp ``` - NLB (fargate pod는 반드시 nlb) ```sh apiVersion: v1 kind: Service metadata: name: mysvc annotations: service.beta.kubernetes.io/aws-load-balancer-type: nlb spec: type: LoadBalancer ports: - port: 80 targetPort: 8080 selector: app: myapp ``` - Internal LB ```sh apiVersion: v1 kind: Service metadata: name: mysvc annotations: service.beta.kubernetes.io/aws-load-balancer-type: nlb service.beta.kubernetes.io/aws-load-balancer-internal: \"true\" spec: type: LoadBalancer ports: - port: 80 targetPort: 8080 selector: app: myapp ``` Ingress . ```sh apiVersion: apps/v1 kind: ReplicaSet metadata: name: myapp spec: replicas: 2 selector: matchLabels: app: myapp template: metadata: labels: app: myapp spec: containers: - name: myweb image: ghcr.io/c1t1d0s7/go-myweb ports: - containerPort: 8080 ``` ```sh apiVersion: v1 kind: Service metadata: name: mysvc-np spec: type: NodePort ports: - port: 80 targetPort: 8080 nodePort: 30112 selector: app: myapp ``` ```sh apiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: name: myweb-ing #annotations: #kubernetes.io/ingress.class: alb #alb.ingress.kubernetes.io/scheme: internet-facing #alb.ingress.kubernetes.io/target-type: instance spec: rules: - http: paths: - path: backend: serviceName: mysvc-np servicePort: 80 ``` - kubernetes.io/ingress.class: alb - alb.ingress.kubernetes.io/scheme: internet-facing - internet-facing: 외부 연결 - internal(기본) - alb.ingress.kubernetes.io/target-type: instance - instance: EC2 nodeport - ip: Pod (Fargate) EBS CSI . ```sh kind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: ebs-sc annotations: storageclass.kubernetes.io/is-default-class: \"true\" provisioner: ebs.csi.aws.com volumeBindingMode: WaitForFirstConsumer reclaimPolicy: Delete parameters: csi.storage.k8s.io/fstype: ext4 type: gp3 ``` ```sh apiVersion: v1 kind: Pod metadata: name: myweb-pod labels: app: myweb-pod spec: containers: - name: web-server image: nginx:alpine volumeMounts: - name: web-content mountPath: /usr/share/nginx/html ports: - containerPort: 80 volumes: - name: web-content persistentVolumeClaim: claimName: myweb-pvc ``` ```sh apiVersion: v1 kind: PersistentVolumeClaim metadata: name: myweb-pvc spec: accessModes: - ReadWriteOnce resources: requests: storage: 1Gi storageClassName: ebs-sc ``` Cluster Autoscaler . ```sh apiVersion: apps/v1 kind: ReplicaSet metadata: name: myweb-rs spec: replicas: 2 selector: matchLabels: app: myweb-rs template: metadata: labels: app: myweb-rs spec: containers: - name: myweb image: ghcr.io/c1t1d0s7/go-myweb ports: - containerPort: 8080 resources: requests: memory: 512M limits: memory: 512M ``` Fargate . ```sh apiVersion: apps/v1 kind: ReplicaSet metadata: name: myweb-rs namespace: dev spec: replicas: 2 selector: matchLabels: app: myweb-rs template: metadata: labels: app: myweb-rs env: fargate spec: containers: - name: myweb image: ghcr.io/c1t1d0s7/go-myweb ports: - containerPort: 8080 ``` ```sh apiVersion: apps/v1 kind: ReplicaSet metadata: name: no-myweb-rs namespace: dev spec: replicas: 2 selector: matchLabels: app: myweb-rs template: metadata: labels: app: myweb-rs spec: containers: - name: myweb image: ghcr.io/c1t1d0s7/go-myweb ports: - containerPort: 8080 ``` RBAC (IAM계정) . - ClusterRole : view - IAM : eksview ```sh # ~/.aws/credentials 수정 [default] aws_access_key_id = A aws_secret_access_key = x [eksview] aws_access_key_id = A aws_secret_access_key = K aws configure list-profiles kubectl create clusterrolebinding eksview-read --clusterrole=view --user eksview kubectl get cm -n kube-system aws-auth kubectl get cm -n kube-system aws-auth -o yaml > aws-auth.yaml # aws-auth 파일 수정 data: mapUsers: | - userarn: arn:aws:iam::860981721775:user/eksview username: eksview groups: - view kubectl apply -f aws-auth.yaml # 사용자 전환 export AWS_PROFILE=eksview # 사용자 전환 - 윈도우 setx AWS_PROFILE eksview aws sts get-caller-identity ``` ",
    "url": "/docs/daily-learning-log/20210514.html",
    "relUrl": "/docs/daily-learning-log/20210514.html"
  },"155": {
    "doc": "2021-05-14",
    "title": "2021-05-14",
    "content": " ",
    "url": "/docs/daily-learning-log/20210514.html",
    "relUrl": "/docs/daily-learning-log/20210514.html"
  },"156": {
    "doc": "2021-05-17",
    "title": "Git",
    "content": "```sh # .git create git init # 가져오기 git clone # remote 보기, 만들기도 가능 뒤에 리모트 이름, 주소 작성 git remote # branch 확인 git branch # branch 만들기 git branch # branch 변경 git checkout # 가져오기 git fetch # fetch 뒤에, branch 여러 개면 병합하는 과정 필요 git merge # 가져오기 git pull ``` - Commit의 일반적인 규칙 - 기능 단위로 커밋 - 형식 단위로 커밋 - 여러가지를 같이 커밋 X ",
    "url": "/docs/daily-learning-log/20210517.html",
    "relUrl": "/docs/daily-learning-log/20210517.html"
  },"157": {
    "doc": "2021-05-17",
    "title": "2021-05-17",
    "content": " ",
    "url": "/docs/daily-learning-log/20210517.html",
    "relUrl": "/docs/daily-learning-log/20210517.html"
  },"158": {
    "doc": "2021-05-18",
    "title": "Git",
    "content": " ",
    "url": "/docs/daily-learning-log/20210518.html",
    "relUrl": "/docs/daily-learning-log/20210518.html"
  },"159": {
    "doc": "2021-05-18",
    "title": "tag",
    "content": "tag는 따로 push ```sh git push origin git push --tag : tag 전부 git clone -b : 특정 브랜치 지정 git rm -r --cached . git add. git commit -m \"커밋메세지\" git push origin {브랜치명} ``` ",
    "url": "/docs/daily-learning-log/20210518.html",
    "relUrl": "/docs/daily-learning-log/20210518.html"
  },"160": {
    "doc": "2021-05-18",
    "title": "CI/CD",
    "content": "Continuous Integration : 지속적 통합 - Jenkins, Circle CI, GitLab CI, Github Action, AWS CodeDeploy Continuous Deployment : 지속적 배포 Continuous Delivery : 지속적 제공 일반적으로 CI - Code 개발 -> Build -> Test -> Release Devops 관점에서 CI - Docker file 개발 -> Docker Build, Container Build -> Test -> Release > 굳이 따지면 Release는 Continuous Delivery 영역 Code -> Build -> Test -> Release -> Deploy Build : compile(실행파일 생성), packaging(tar), library/package 설치 - CI: Git, GitHub, Docker Hub - Git 저장소(프라이빗) - Application Django, Flask Web App - Dockerfile - Docker Hub Automated Build - Git 태그 기반으로, 컨테이너 태그 구성 - CD: ArgoCD - Git 저장소(프라이빗) - Kubernetes Manifest CI/CD 순서 1. App 개발 2. Dockerfile 3. git add/commit/push 4. docker build 5. docker push 6. Kubernetes Manifest 작성 / Helm Chart 작성 7. git add/commit/push 8. kubectl apply / helm install 참조 주소 > Docker Hub Automated Build : https://docs.docker.com/docker-hub/builds/ ",
    "url": "/docs/daily-learning-log/20210518.html",
    "relUrl": "/docs/daily-learning-log/20210518.html"
  },"161": {
    "doc": "2021-05-18",
    "title": "Argo CD",
    "content": "참조 주소 > https://argoproj.github.io/argo-cd/ ",
    "url": "/docs/daily-learning-log/20210518.html",
    "relUrl": "/docs/daily-learning-log/20210518.html"
  },"162": {
    "doc": "2021-05-18",
    "title": "2021-05-18",
    "content": " ",
    "url": "/docs/daily-learning-log/20210518.html",
    "relUrl": "/docs/daily-learning-log/20210518.html"
  },"163": {
    "doc": "2021-05-21",
    "title": "CI/CD - AWS",
    "content": "CodeCommit - Git CodeBuild - CI CodeDeploy - CD이지만, EKS에 배포하는 기능이 없음 CodePipeline - 위의 세 개 묶은 것 Cloud9 Elastic Container Registry - Docker hub와 비슷한 기능으로 쓸 것임 즉, AWS만으로 CI, CD 해보자 ! ",
    "url": "/docs/daily-learning-log/20210521.html",
    "relUrl": "/docs/daily-learning-log/20210521.html"
  },"164": {
    "doc": "2021-05-21",
    "title": "CodeCommit",
    "content": "IAM 사용자로 해야 함 내 보안자격증명에서 codecommit ssh 설정 create new repo git으로 시작하는 주소를 줌 - code 업로드 ",
    "url": "/docs/daily-learning-log/20210521.html",
    "relUrl": "/docs/daily-learning-log/20210521.html"
  },"165": {
    "doc": "2021-05-21",
    "title": "ECR",
    "content": "> Docker 설치되어있는 환경에서 ! aws console에서 ecr 레포생성 푸시명령보기 푸시 명령에 맞춰서 따라하기 ",
    "url": "/docs/daily-learning-log/20210521.html",
    "relUrl": "/docs/daily-learning-log/20210521.html"
  },"166": {
    "doc": "2021-05-21",
    "title": "CodeBuild",
    "content": "build 정의 : code commit git 저장소의 root 디렉토리에 buildspec.yml 파일 ",
    "url": "/docs/daily-learning-log/20210521.html",
    "relUrl": "/docs/daily-learning-log/20210521.html"
  },"167": {
    "doc": "2021-05-21",
    "title": "Pipeline",
    "content": "서비스 역할 생성하게 되는데, IAM에서 필요한 정책을 연결시켜줘야함 ",
    "url": "/docs/daily-learning-log/20210521.html",
    "relUrl": "/docs/daily-learning-log/20210521.html"
  },"168": {
    "doc": "2021-05-21",
    "title": "Github Action",
    "content": "build 정의 : reponame/.github/workflows/*.yml (파일명 상관없음) ```sh on : 트리거 jobs.deploy.steps.uses : 플러그인 //checkout = git clone ``` github action은 1달에 2000분 무료 Linux 기준임 // window는 시간에 x2를 해야함 // mac은 x10 window는 운영체제 사는 비용이고 mac은 하드웨어를 사는 비용때문에 비쌈 QEMU : 리눅스 가상화 현재 repo setting의 secret에서 변수 추가 - DOCKERHUB_USERNAME : docker 계정명 - DOCKERHUB_TOKEN : docker의 account setting에서 access token 발급받아서 넣기 gitlab CI가 제일 좋아여 ~ 과제할 때 그림은 draw.io로 그리고 문서에 넣을 때에는 svg로 (확대해도 안깨져) ",
    "url": "/docs/daily-learning-log/20210521.html",
    "relUrl": "/docs/daily-learning-log/20210521.html"
  },"169": {
    "doc": "2021-05-21",
    "title": "2021-05-21",
    "content": " ",
    "url": "/docs/daily-learning-log/20210521.html",
    "relUrl": "/docs/daily-learning-log/20210521.html"
  },"170": {
    "doc": "AWS EKS semi project",
    "title": "AWS EKS semi project",
    "content": "# Subject ## AWS EKS cluster, wordpress, mysql, CI/CD, monitoring, logging ### 계속 업데이트 중 project repository address > [https://github.com/joeunlog/nginx-ubuntu](https://github.com/joeunlog/nginx-ubuntu) - AWS EKS cluster 구성 - addone 설치 - Wordpress-mySQL 구성 - CI/CD - Github - Dockerhub - Dockerhun automated build - ArgoCD - Monitoring - AWS CloudWatch - Logging - AWS CloudWatch ",
    "url": "/docs/project/awseks-semiproject.html",
    "relUrl": "/docs/project/awseks-semiproject.html"
  },"171": {
    "doc": "Final project",
    "title": "Final project",
    "content": "# Subject ```sh $ virtualenv venv $ source /venv/Scripts/activate ``` django에서 model을 선언할 때, primary key를 따로 지정하지 않으면 id가 default로 생성된다. ```py id = models.AutoField(primary_key=True) ``` pip install django-markdownx ## terraform aws configure 설정 ```sh $ aws configure ``` ```sh $ choco install terraform # 원하는 폴더에서 $ terraform init $ terraform fmt $ terraform validate $ terraform apply $ terraform show $ terraform destroy ``` kubectl이 작동하지 않았음 : kubectl을 configure 해야함 ```sh # configure kubectl aws eks update-kubeconfig --region ap-northeast-2 --name wikikube-cluster # outputs.tf에 region, cluster_name 선언이 되어 있어야 함 ``` kubectl describe configmap -n kube-system aws-auth cluster 권한 설정을 위한 사용자 추가 ```sh kubectl edit -n kube-system configmap/aws-auth # 예시 apiVersion: v1 data: mapRoles: | - rolearn: username: groups: - - mapUsers: | - userarn: username: groups: - ``` ### addon 설치 #### addon - lb ```sh kubectl apply -k \"github.com/aws/eks-charts/stable/aws-load-balancer-controller//crds?ref=master\" helm repo add eks https://aws.github.io/eks-charts helm repo update helm upgrade -i aws-load-balancer-controller eks/aws-load-balancer-controller \\ --set clusterName=wikikube-cluster \\ --set serviceAccount.create=true \\ --set serviceAccount.name=aws-load-balancer-controller \\ --set image.tag=v2.1.3 \\ -n kube-system # deploy가 안돼서 rs를 describe 해보니 service account가 없었음 # Error: unable to create iamserviceaccount(s) without IAM OIDC provider enabled ``` > https://docs.aws.amazon.com/eks/latest/userguide/enable-iam-roles-for-service-accounts.html ```sh # OLDC provider 있는지 확인 aws eks describe-cluster --name wikikube-cluster --query \"cluster.identity.oidc.issuer\" --output text # output을 아래 command에 넣기 (https ~) aws iam list-open-id-connect-providers | grep https://oidc.eks.ap-northeast-2.amazonaws.com/id/E4F7031BF02A0829BC7235585646DCD6 # output이 없으면 새로운 oidc provider 생성 eksctl utils associate-iam-oidc-provider --cluster wikikube-cluster --approve ``` ```sh # 다시 service account 생성 시도하기 # eksctl create iamserviceaccount \\ # --name aws-load-balancer-controller \\ # --namespace kube-system \\ # --cluster test-eks-EV \\ # --attach-policy-arn arn:aws:iam::aws:policy/awsLoadBalancerController \\ # --approve \\ # --override-existing-serviceaccounts # oidc provider 만들고 시도했는데, override 부분에서 에러가 나는 것 같아서 해당 부분 지우고 시도하니까 sa는 생성됐음 # sa 생성했는데도 안돼서 설치할 때 sa 생성되도록 바꿈 -> 성공 !!!!!!!!!!!!!!!! helm upgrade -i aws-load-balancer-controller eks/aws-load-balancer-controller \\ --set clusterName=wikikube-cluster \\ --set serviceAccount.create=true \\ --set serviceAccount.name=aws-load-balancer-controller \\ --set image.tag=v2.1.3 \\ -n kube-system ``` #### addon - ebs csi driver ```sh helm repo add aws-ebs-csi-driver https://kubernetes-sigs.github.io/aws-ebs-csi-driver helm repo update # lb 설치할 때처럼 sa를 만들게 바꿈 -> 성공 !!!!!!!!!! helm upgrade -install aws-ebs-csi-driver aws-ebs-csi-driver/aws-ebs-csi-driver \\ --namespace kube-system \\ --set enableVolumeResizing=true \\ --set enableVolumeSnapshot=true \\ --set serviceAccount.controller.create=true \\ --set serviceAccount.controller.name=ebs-csi-controller-sa ``` #### addon - metrics server ```sh kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml ``` #### addon - cluster autoscaler ```sh curl -o cluster-autoscaler-autodiscover.yaml https://raw.githubusercontent.com/kubernetes/autoscaler/master/cluster-autoscaler/cloudprovider/aws/examples/cluster-autoscaler-autodiscover.yaml # edit cluster-autoscaler-autodiscover.yaml # 에 cluster name 입력 kubectl create -f cluster-autoscaler-autodiscover.yaml ``` #### addon - cloudwatch container insights ```sh $ ClusterName=wikikube-cluster $ RegionName=ap-northeast-2 $ FluentBitHttpPort='2020' $ FluentBitReadFromHead='Off' $ [[ ${FluentBitReadFromHead} = 'On' ]] && FluentBitReadFromTail='Off'|| FluentBitReadFromTail='On' $ [[ -z ${FluentBitHttpPort} ]] && FluentBitHttpServer='Off' || FluentBitHttpServer='On' $ curl https://raw.githubusercontent.com/aws-samples/amazon-cloudwatch-container-insights/latest/k8s-deployment-manifest-templates/deployment-mode/daemonset/container-insights-monitoring/quickstart/cwagent-fluent-bit-quickstart.yaml | sed 's/{{cluster_name}}/'${ClusterName}'/;s/{{region_name}}/'${RegionName}'/;s/{{http_server_toggle}}/\"'${FluentBitHttpServer}'\"/;s/{{http_server_port}}/\"'${FluentBitHttpPort}'\"/;s/{{read_from_head}}/\"'${FluentBitReadFromHead}'\"/;s/{{read_from_tail}}/\"'${FluentBitReadFromTail}'\"/' | kubectl apply -f - ``` #### RDS db django migrate ```sh kubectl run test -it --rm --image=ubuntu:focal apt update apt install python3 apt install mysql-client apt install vim apt install pip pip install django apt-get install libmysqlclient-dev apt-get install libssl-dev pip install mysqlclient django-admin startproject dbmigrate cd dbmigrate python3 manage.py startapp k8sdoc cd dbmigrate # setting.py edit vi setting.py DATABASES = { 'default': { 'ENGINE': 'django.db.backends.mysql', 'NAME': 'wikikube-db', 'USER': 'admin', 'PASSWORD': 'wikikube1214', 'HOST': 'wikikube-db-1.ckaj95iexfk8.ap-northeast-2.rds.amazonaws.com', # AWS RDS endpoint } } ``` ``` from django.db import models from django.db.models.deletion import CASCADE, SET_DEFAULT from django.contrib.auth.models import User ``` # django에서 지원하는 User model 사용 # Create your models here. ``` class User(models.Model): user_id = models.CharField(max_length=200, null=False, primary_key=True) user_name = models.CharField(max_length=200, null=False) user_password = models.CharField(max_length=200, null=False) user_dob = models.DateTimeField(default=\"\", null=False) user_create_date = models.DateTimeField(auto_now_add=True, null=False) def __str__(self): return self.user_name ``` ### 게시글에 대한 작성자확인이 필요할까? 모든 게시글은 admin이 작성할 것인데 ``` class Post(models.Model): title = models.CharField(max_length=100, null=False) category = models.CharField(max_length=100, null=False) content = models.TextField(max_length=5000, null=False) # writer_id = models.ForeignKey(User, on_delete=SET_DEFAULT, default=\"\") post_time = models.DateTimeField(auto_now_add=True) # def __str__(self): # return str(self.id) class Comment(models.Model): # 고유번호는 comment.id로 참조 : id = models.AutoField(primary_key=True) comment_content = models.CharField(max_length=500, null=False) com_board_url = models.CharField(max_length=500, null=False) user_id = models.ForeignKey(User, on_delete=CASCADE, null=False) post_id = models.ForeignKey(Post, on_delete=CASCADE, null=False) # 게시글 고유번호 com_create_date = models.DateTimeField(auto_now_add=True, null=False) # def __str__(self): # return str(self.id) class Bookmark(models.Model): book_user = models.ForeignKey(User, on_delete=CASCADE, null=False) post_id = models.ForeignKey(Post, on_delete=CASCADE, null=True) # 게시글 고유번호 ``` Route 53 콘솔을 엽니다. 탐색 창에서 호스팅 영역을 선택합니다. 도메인에 대한 호스팅 영역을 선택합니다. 도메인에 대한 Route 53 별칭 레코드를 선택합니다. 레코드 세트 편집 창의 유형에서 IPv4 주소를 선택합니다. 별칭이 예로 설정되어 있는지 확인합니다. 적절한 Elastic Load Balancing 도메인 이름이 Alias Target으로 설정되어 있는지 확인합니다. 레코드 세트 저장을 선택합니다. kubectl set image deployment/wikikube -n cd wikikube-pod=kianjay/wikikube:v1.1 --record kubectl set image deployment/wikikube wikikube-pod=kianjay/wikikube:v1.1 --record ",
    "url": "/docs/project/final-project.html",
    "relUrl": "/docs/project/final-project.html"
  },"172": {
    "doc": "Joeunvit Study log",
    "title": "Joeunvit Study log",
    "content": "#### python #### RDB #### VM #### Linux #### Web #### Network #### AWS #### Django #### Security #### Ansible #### Docker #### Kubernetes #### AWS EKS #### CI/CD ",
    "url": "/docs/",
    "relUrl": "/docs/"
  },"173": {
    "doc": "Daily-learning-log",
    "title": "Daily learning log index page",
    "content": " ",
    "url": "/docs/daily-learning-log/",
    "relUrl": "/docs/daily-learning-log/"
  },"174": {
    "doc": "Daily-learning-log",
    "title": "Daily-learning-log",
    "content": " ",
    "url": "/docs/daily-learning-log/",
    "relUrl": "/docs/daily-learning-log/"
  },"175": {
    "doc": "Python",
    "title": "Python study index page",
    "content": " ",
    "url": "/docs/python-study/",
    "relUrl": "/docs/python-study/"
  },"176": {
    "doc": "Python",
    "title": "Python",
    "content": " ",
    "url": "/docs/python-study/",
    "relUrl": "/docs/python-study/"
  },"177": {
    "doc": "PROJECT",
    "title": "Project index page",
    "content": " ",
    "url": "/docs/project/",
    "relUrl": "/docs/project/"
  },"178": {
    "doc": "PROJECT",
    "title": "PROJECT",
    "content": " ",
    "url": "/docs/project/",
    "relUrl": "/docs/project/"
  }
}
